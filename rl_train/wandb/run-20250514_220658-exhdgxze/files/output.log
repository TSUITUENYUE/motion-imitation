W&B logging initialized for project: go2-training

==================================================
Starting training for 10 iterations
Motion file: data/canter_new.npy
Log directory: logs/go2-paper-rewards-canter_new
Domain randomization: enabled
Curriculum learning: enabled
Time-dependent rewards: disabled
W&B logging enabled for project: go2-training
==================================================

################################################################################
                       [1m Learning iteration 0/10 [0m

                       Computation: 2171 steps/s (collection: 0.617s, learning 0.090s)
               Value function loss: 0.0692
                    Surrogate loss: -0.0162
             Mean action noise std: 1.00
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0165
Mean episode rew_end_effector_matching: 0.0003
        Mean episode rew_stability: 0.0002
--------------------------------------------------------------------------------
                   Total timesteps: 1536
                    Iteration time: 0.71s
                        Total time: 0.71s
                               ETA: 7.1s

Could not find git repository in /home/jeff/anaconda3/envs/genesis/lib/python3.10/site-packages/rsl_rl/__init__.py. Skipping.
################################################################################
                       [1m Learning iteration 1/10 [0m

                       Computation: 4896 steps/s (collection: 0.285s, learning 0.028s)
               Value function loss: 0.4977
                    Surrogate loss: -0.0116
             Mean action noise std: 1.00
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 3072
                    Iteration time: 0.31s
                        Total time: 1.02s
                               ETA: 4.6s

################################################################################
                       [1m Learning iteration 2/10 [0m

                       Computation: 4943 steps/s (collection: 0.281s, learning 0.030s)
               Value function loss: 0.3202
                    Surrogate loss: -0.0144
             Mean action noise std: 1.00
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 4608
                    Iteration time: 0.31s
                        Total time: 1.33s
                               ETA: 3.6s

################################################################################
                       [1m Learning iteration 3/10 [0m

                       Computation: 4957 steps/s (collection: 0.279s, learning 0.030s)
               Value function loss: 0.2664
                    Surrogate loss: -0.0183
             Mean action noise std: 1.00
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 6144
                    Iteration time: 0.31s
                        Total time: 1.64s
                               ETA: 2.9s

################################################################################
                       [1m Learning iteration 4/10 [0m

                       Computation: 4903 steps/s (collection: 0.283s, learning 0.031s)
               Value function loss: 0.2405
                    Surrogate loss: -0.0149
             Mean action noise std: 1.00
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 7680
                    Iteration time: 0.31s
                        Total time: 1.95s
                               ETA: 2.3s

################################################################################
                       [1m Learning iteration 5/10 [0m

                       Computation: 4721 steps/s (collection: 0.294s, learning 0.031s)
               Value function loss: 0.2257
                    Surrogate loss: -0.0165
             Mean action noise std: 1.01
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 9216
                    Iteration time: 0.33s
                        Total time: 2.28s
                               ETA: 1.9s

################################################################################
                       [1m Learning iteration 6/10 [0m

                       Computation: 5005 steps/s (collection: 0.278s, learning 0.029s)
               Value function loss: 0.1889
                    Surrogate loss: -0.0098
             Mean action noise std: 1.01
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 10752
                    Iteration time: 0.31s
                        Total time: 2.59s
                               ETA: 1.5s

################################################################################
                       [1m Learning iteration 7/10 [0m

                       Computation: 4986 steps/s (collection: 0.280s, learning 0.028s)
               Value function loss: 0.1513
                    Surrogate loss: -0.0117
             Mean action noise std: 1.01
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 12288
                    Iteration time: 0.31s
                        Total time: 2.90s
                               ETA: 1.1s

################################################################################
                       [1m Learning iteration 8/10 [0m

                       Computation: 4921 steps/s (collection: 0.282s, learning 0.030s)
               Value function loss: 0.1874
                    Surrogate loss: -0.0067
             Mean action noise std: 1.01
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 13824
                    Iteration time: 0.31s
                        Total time: 3.21s
                               ETA: 0.7s

################################################################################
                       [1m Learning iteration 9/10 [0m

                       Computation: 4696 steps/s (collection: 0.296s, learning 0.031s)
               Value function loss: 0.1376
                    Surrogate loss: -0.0139
             Mean action noise std: 1.01
                 Mean total reward: 0.80
               Mean episode length: 16.58
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0451
Mean episode rew_end_effector_matching: 0.0011
        Mean episode rew_stability: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 15360
                    Iteration time: 0.33s
                        Total time: 3.53s
                               ETA: 0.4s
