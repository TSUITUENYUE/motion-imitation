W&B logging initialized for project: go2-motion-imitation

==================================================
Starting training for 500 iterations
Motion file: data/canter.npy
Log directory: logs/go2-imitate-canter
W&B logging enabled for project: go2-motion-imitation
==================================================

################################################################################
                       [1m Learning iteration 0/500 [0m

                       Computation: 2027 steps/s (collection: 0.661s, learning 0.097s)
               Value function loss: 2.4327
                    Surrogate loss: -0.0099
             Mean action noise std: 1.00
                 Mean total reward: 0.61
               Mean episode length: 5.86
 Mean episode rew_tracking_lin_vel: 0.0029
 Mean episode rew_tracking_ang_vel: 0.0010
        Mean episode rew_lin_vel_z: -0.0017
      Mean episode rew_base_height: -0.0040
      Mean episode rew_action_rate: -0.0007
Mean episode rew_similar_to_default: -0.0017
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.0505
--------------------------------------------------------------------------------
                   Total timesteps: 1536
                    Iteration time: 0.76s
                        Total time: 0.76s
                               ETA: 378.8s

Could not find git repository in /home/jeff/anaconda3/envs/genesis/lib/python3.10/site-packages/rsl_rl/__init__.py. Skipping.
################################################################################
                       [1m Learning iteration 1/500 [0m

                       Computation: 8847 steps/s (collection: 0.143s, learning 0.030s)
               Value function loss: 4.0446
                    Surrogate loss: -0.0128
             Mean action noise std: 1.00
                 Mean total reward: 1.92
               Mean episode length: 10.48
 Mean episode rew_tracking_lin_vel: 0.0084
 Mean episode rew_tracking_ang_vel: 0.0041
        Mean episode rew_lin_vel_z: -0.0054
      Mean episode rew_base_height: -0.0040
      Mean episode rew_action_rate: -0.0038
Mean episode rew_similar_to_default: -0.0047
Mean episode rew_joint_pose_matching: 0.0170
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.3634
--------------------------------------------------------------------------------
                   Total timesteps: 3072
                    Iteration time: 0.17s
                        Total time: 0.93s
                               ETA: 232.3s

################################################################################
                       [1m Learning iteration 2/500 [0m

                       Computation: 9705 steps/s (collection: 0.124s, learning 0.034s)
               Value function loss: 4.7460
                    Surrogate loss: -0.0099
             Mean action noise std: 1.00
                 Mean total reward: 2.65
               Mean episode length: 13.08
 Mean episode rew_tracking_lin_vel: 0.0130
 Mean episode rew_tracking_ang_vel: 0.0072
        Mean episode rew_lin_vel_z: -0.0050
      Mean episode rew_base_height: -0.0046
      Mean episode rew_action_rate: -0.0056
Mean episode rew_similar_to_default: -0.0080
Mean episode rew_joint_pose_matching: 0.0193
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.5948
--------------------------------------------------------------------------------
                   Total timesteps: 4608
                    Iteration time: 0.16s
                        Total time: 1.09s
                               ETA: 180.8s

################################################################################
                       [1m Learning iteration 3/500 [0m

                       Computation: 9842 steps/s (collection: 0.126s, learning 0.030s)
               Value function loss: 4.4789
                    Surrogate loss: -0.0111
             Mean action noise std: 1.00
                 Mean total reward: 3.42
               Mean episode length: 15.98
 Mean episode rew_tracking_lin_vel: 0.0117
 Mean episode rew_tracking_ang_vel: 0.0066
        Mean episode rew_lin_vel_z: -0.0051
      Mean episode rew_base_height: -0.0042
      Mean episode rew_action_rate: -0.0050
Mean episode rew_similar_to_default: -0.0071
Mean episode rew_joint_pose_matching: 0.0127
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.5387
--------------------------------------------------------------------------------
                   Total timesteps: 6144
                    Iteration time: 0.16s
                        Total time: 1.25s
                               ETA: 154.7s

################################################################################
                       [1m Learning iteration 4/500 [0m

                       Computation: 9970 steps/s (collection: 0.124s, learning 0.030s)
               Value function loss: 4.3197
                    Surrogate loss: -0.0105
             Mean action noise std: 1.00
                 Mean total reward: 4.53
               Mean episode length: 19.95
 Mean episode rew_tracking_lin_vel: 0.0170
 Mean episode rew_tracking_ang_vel: 0.0093
        Mean episode rew_lin_vel_z: -0.0052
      Mean episode rew_base_height: -0.0063
      Mean episode rew_action_rate: -0.0076
Mean episode rew_similar_to_default: -0.0119
Mean episode rew_joint_pose_matching: 0.0262
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.8023
--------------------------------------------------------------------------------
                   Total timesteps: 7680
                    Iteration time: 0.15s
                        Total time: 1.40s
                               ETA: 138.8s

################################################################################
                       [1m Learning iteration 5/500 [0m

                       Computation: 9668 steps/s (collection: 0.131s, learning 0.028s)
               Value function loss: 4.2507
                    Surrogate loss: -0.0094
             Mean action noise std: 1.00
                 Mean total reward: 7.22
               Mean episode length: 29.21
 Mean episode rew_tracking_lin_vel: 0.0351
 Mean episode rew_tracking_ang_vel: 0.0155
        Mean episode rew_lin_vel_z: -0.0054
      Mean episode rew_base_height: -0.0062
      Mean episode rew_action_rate: -0.0127
Mean episode rew_similar_to_default: -0.0181
Mean episode rew_joint_pose_matching: 0.0436
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0002
 Mean episode rew_forward_velocity: 1.4122
--------------------------------------------------------------------------------
                   Total timesteps: 9216
                    Iteration time: 0.16s
                        Total time: 1.56s
                               ETA: 128.6s

################################################################################
                       [1m Learning iteration 6/500 [0m

                       Computation: 9275 steps/s (collection: 0.135s, learning 0.031s)
               Value function loss: 3.9955
                    Surrogate loss: -0.0062
             Mean action noise std: 1.00
                 Mean total reward: 8.68
               Mean episode length: 34.30
 Mean episode rew_tracking_lin_vel: 0.0310
 Mean episode rew_tracking_ang_vel: 0.0137
        Mean episode rew_lin_vel_z: -0.0059
      Mean episode rew_base_height: -0.0075
      Mean episode rew_action_rate: -0.0121
Mean episode rew_similar_to_default: -0.0190
Mean episode rew_joint_pose_matching: 0.0320
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0002
 Mean episode rew_forward_velocity: 1.3507
--------------------------------------------------------------------------------
                   Total timesteps: 10752
                    Iteration time: 0.17s
                        Total time: 1.72s
                               ETA: 121.7s

################################################################################
                       [1m Learning iteration 7/500 [0m

                       Computation: 9805 steps/s (collection: 0.127s, learning 0.030s)
               Value function loss: 4.3795
                    Surrogate loss: -0.0039
             Mean action noise std: 1.00
                 Mean total reward: 10.00
               Mean episode length: 38.96
 Mean episode rew_tracking_lin_vel: 0.0344
 Mean episode rew_tracking_ang_vel: 0.0136
        Mean episode rew_lin_vel_z: -0.0059
      Mean episode rew_base_height: -0.0069
      Mean episode rew_action_rate: -0.0122
Mean episode rew_similar_to_default: -0.0181
Mean episode rew_joint_pose_matching: 0.0331
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0006
 Mean episode rew_forward_velocity: 1.3280
--------------------------------------------------------------------------------
                   Total timesteps: 12288
                    Iteration time: 0.16s
                        Total time: 1.88s
                               ETA: 115.9s

################################################################################
                       [1m Learning iteration 8/500 [0m

                       Computation: 10257 steps/s (collection: 0.119s, learning 0.031s)
               Value function loss: 4.0079
                    Surrogate loss: -0.0100
             Mean action noise std: 1.00
                 Mean total reward: 11.06
               Mean episode length: 42.70
 Mean episode rew_tracking_lin_vel: 0.0305
 Mean episode rew_tracking_ang_vel: 0.0134
        Mean episode rew_lin_vel_z: -0.0056
      Mean episode rew_base_height: -0.0059
      Mean episode rew_action_rate: -0.0108
Mean episode rew_similar_to_default: -0.0157
Mean episode rew_joint_pose_matching: 0.0372
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 1.1866
--------------------------------------------------------------------------------
                   Total timesteps: 13824
                    Iteration time: 0.15s
                        Total time: 2.03s
                               ETA: 111.0s

################################################################################
                       [1m Learning iteration 9/500 [0m

                       Computation: 10345 steps/s (collection: 0.119s, learning 0.030s)
               Value function loss: 3.8531
                    Surrogate loss: -0.0074
             Mean action noise std: 1.00
                 Mean total reward: 12.33
               Mean episode length: 47.31
 Mean episode rew_tracking_lin_vel: 0.0508
 Mean episode rew_tracking_ang_vel: 0.0205
        Mean episode rew_lin_vel_z: -0.0058
      Mean episode rew_base_height: -0.0124
      Mean episode rew_action_rate: -0.0201
Mean episode rew_similar_to_default: -0.0325
Mean episode rew_joint_pose_matching: 0.0454
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0007
 Mean episode rew_forward_velocity: 2.1321
--------------------------------------------------------------------------------
                   Total timesteps: 15360
                    Iteration time: 0.15s
                        Total time: 2.18s
                               ETA: 107.0s

################################################################################
                      [1m Learning iteration 10/500 [0m

                       Computation: 9566 steps/s (collection: 0.131s, learning 0.030s)
               Value function loss: 3.9842
                    Surrogate loss: -0.0038
             Mean action noise std: 1.01
                 Mean total reward: 14.47
               Mean episode length: 55.08
 Mean episode rew_tracking_lin_vel: 0.0596
 Mean episode rew_tracking_ang_vel: 0.0263
        Mean episode rew_lin_vel_z: -0.0061
      Mean episode rew_base_height: -0.0139
      Mean episode rew_action_rate: -0.0236
Mean episode rew_similar_to_default: -0.0391
Mean episode rew_joint_pose_matching: 0.0490
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.5253
--------------------------------------------------------------------------------
                   Total timesteps: 16896
                    Iteration time: 0.16s
                        Total time: 2.34s
                               ETA: 104.2s

################################################################################
                      [1m Learning iteration 11/500 [0m

                       Computation: 8989 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 4.3813
                    Surrogate loss: -0.0101
             Mean action noise std: 1.01
                 Mean total reward: 20.65
               Mean episode length: 76.94
 Mean episode rew_tracking_lin_vel: 0.0410
 Mean episode rew_tracking_ang_vel: 0.0165
        Mean episode rew_lin_vel_z: -0.0060
      Mean episode rew_base_height: -0.0075
      Mean episode rew_action_rate: -0.0148
Mean episode rew_similar_to_default: -0.0213
Mean episode rew_joint_pose_matching: 0.0400
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 1.5964
--------------------------------------------------------------------------------
                   Total timesteps: 18432
                    Iteration time: 0.17s
                        Total time: 2.51s
                               ETA: 102.3s

################################################################################
                      [1m Learning iteration 12/500 [0m

                       Computation: 10104 steps/s (collection: 0.123s, learning 0.029s)
               Value function loss: 3.4417
                    Surrogate loss: -0.0114
             Mean action noise std: 1.01
                 Mean total reward: 22.14
               Mean episode length: 82.03
 Mean episode rew_tracking_lin_vel: 0.0413
 Mean episode rew_tracking_ang_vel: 0.0166
        Mean episode rew_lin_vel_z: -0.0064
      Mean episode rew_base_height: -0.0070
      Mean episode rew_action_rate: -0.0155
Mean episode rew_similar_to_default: -0.0220
Mean episode rew_joint_pose_matching: 0.0546
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0023
 Mean episode rew_forward_velocity: 1.7650
--------------------------------------------------------------------------------
                   Total timesteps: 19968
                    Iteration time: 0.15s
                        Total time: 2.66s
                               ETA: 99.9s

################################################################################
                      [1m Learning iteration 13/500 [0m

                       Computation: 9878 steps/s (collection: 0.126s, learning 0.030s)
               Value function loss: 4.0806
                    Surrogate loss: -0.0082
             Mean action noise std: 1.00
                 Mean total reward: 26.44
               Mean episode length: 97.41
 Mean episode rew_tracking_lin_vel: 0.0272
 Mean episode rew_tracking_ang_vel: 0.0117
        Mean episode rew_lin_vel_z: -0.0057
      Mean episode rew_base_height: -0.0063
      Mean episode rew_action_rate: -0.0109
Mean episode rew_similar_to_default: -0.0151
Mean episode rew_joint_pose_matching: 0.0241
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 1.1846
--------------------------------------------------------------------------------
                   Total timesteps: 21504
                    Iteration time: 0.16s
                        Total time: 2.82s
                               ETA: 98.0s

################################################################################
                      [1m Learning iteration 14/500 [0m

                       Computation: 10128 steps/s (collection: 0.122s, learning 0.030s)
               Value function loss: 3.9494
                    Surrogate loss: -0.0137
             Mean action noise std: 1.00
                 Mean total reward: 29.01
               Mean episode length: 106.96
 Mean episode rew_tracking_lin_vel: 0.0544
 Mean episode rew_tracking_ang_vel: 0.0213
        Mean episode rew_lin_vel_z: -0.0062
      Mean episode rew_base_height: -0.0087
      Mean episode rew_action_rate: -0.0195
Mean episode rew_similar_to_default: -0.0290
Mean episode rew_joint_pose_matching: 0.0552
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0004
 Mean episode rew_forward_velocity: 2.0919
--------------------------------------------------------------------------------
                   Total timesteps: 23040
                    Iteration time: 0.15s
                        Total time: 2.97s
                               ETA: 96.2s

################################################################################
                      [1m Learning iteration 15/500 [0m

                       Computation: 10172 steps/s (collection: 0.121s, learning 0.030s)
               Value function loss: 3.6705
                    Surrogate loss: -0.0148
             Mean action noise std: 1.00
                 Mean total reward: 31.90
               Mean episode length: 116.98
 Mean episode rew_tracking_lin_vel: 0.0802
 Mean episode rew_tracking_ang_vel: 0.0363
        Mean episode rew_lin_vel_z: -0.0069
      Mean episode rew_base_height: -0.0166
      Mean episode rew_action_rate: -0.0298
Mean episode rew_similar_to_default: -0.0494
Mean episode rew_joint_pose_matching: 0.0808
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 3.4287
--------------------------------------------------------------------------------
                   Total timesteps: 24576
                    Iteration time: 0.15s
                        Total time: 3.12s
                               ETA: 94.6s

################################################################################
                      [1m Learning iteration 16/500 [0m

                       Computation: 10029 steps/s (collection: 0.126s, learning 0.027s)
               Value function loss: 3.5707
                    Surrogate loss: -0.0085
             Mean action noise std: 1.00
                 Mean total reward: 33.59
               Mean episode length: 123.21
 Mean episode rew_tracking_lin_vel: 0.1029
 Mean episode rew_tracking_ang_vel: 0.0438
        Mean episode rew_lin_vel_z: -0.0082
      Mean episode rew_base_height: -0.0194
      Mean episode rew_action_rate: -0.0397
Mean episode rew_similar_to_default: -0.0620
Mean episode rew_joint_pose_matching: 0.0868
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.2051
--------------------------------------------------------------------------------
                   Total timesteps: 26112
                    Iteration time: 0.15s
                        Total time: 3.27s
                               ETA: 93.2s

################################################################################
                      [1m Learning iteration 17/500 [0m

                       Computation: 10276 steps/s (collection: 0.122s, learning 0.028s)
               Value function loss: 4.7159
                    Surrogate loss: -0.0077
             Mean action noise std: 1.00
                 Mean total reward: 38.42
               Mean episode length: 141.11
 Mean episode rew_tracking_lin_vel: 0.1135
 Mean episode rew_tracking_ang_vel: 0.0432
        Mean episode rew_lin_vel_z: -0.0072
      Mean episode rew_base_height: -0.0184
      Mean episode rew_action_rate: -0.0407
Mean episode rew_similar_to_default: -0.0615
Mean episode rew_joint_pose_matching: 0.0911
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 4.1844
--------------------------------------------------------------------------------
                   Total timesteps: 27648
                    Iteration time: 0.15s
                        Total time: 3.42s
                               ETA: 91.9s

################################################################################
                      [1m Learning iteration 18/500 [0m

                       Computation: 10182 steps/s (collection: 0.121s, learning 0.030s)
               Value function loss: 3.2789
                    Surrogate loss: -0.0119
             Mean action noise std: 1.00
                 Mean total reward: 39.71
               Mean episode length: 145.96
 Mean episode rew_tracking_lin_vel: 0.0810
 Mean episode rew_tracking_ang_vel: 0.0308
        Mean episode rew_lin_vel_z: -0.0062
      Mean episode rew_base_height: -0.0180
      Mean episode rew_action_rate: -0.0306
Mean episode rew_similar_to_default: -0.0497
Mean episode rew_joint_pose_matching: 0.0526
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.1571
--------------------------------------------------------------------------------
                   Total timesteps: 29184
                    Iteration time: 0.15s
                        Total time: 3.57s
                               ETA: 90.7s

################################################################################
                      [1m Learning iteration 19/500 [0m

                       Computation: 9876 steps/s (collection: 0.126s, learning 0.030s)
               Value function loss: 6.3752
                    Surrogate loss: -0.0070
             Mean action noise std: 1.00
                 Mean total reward: 43.19
               Mean episode length: 158.55
 Mean episode rew_tracking_lin_vel: 0.0656
 Mean episode rew_tracking_ang_vel: 0.0246
        Mean episode rew_lin_vel_z: -0.0065
      Mean episode rew_base_height: -0.0127
      Mean episode rew_action_rate: -0.0250
Mean episode rew_similar_to_default: -0.0376
Mean episode rew_joint_pose_matching: 0.0567
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0005
 Mean episode rew_forward_velocity: 2.5559
--------------------------------------------------------------------------------
                   Total timesteps: 30720
                    Iteration time: 0.16s
                        Total time: 3.73s
                               ETA: 89.7s

################################################################################
                      [1m Learning iteration 20/500 [0m

                       Computation: 10057 steps/s (collection: 0.123s, learning 0.030s)
               Value function loss: 3.6951
                    Surrogate loss: -0.0073
             Mean action noise std: 1.01
                 Mean total reward: 45.70
               Mean episode length: 167.39
 Mean episode rew_tracking_lin_vel: 0.0359
 Mean episode rew_tracking_ang_vel: 0.0127
        Mean episode rew_lin_vel_z: -0.0058
      Mean episode rew_base_height: -0.0071
      Mean episode rew_action_rate: -0.0117
Mean episode rew_similar_to_default: -0.0171
Mean episode rew_joint_pose_matching: 0.0255
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 1.2635
--------------------------------------------------------------------------------
                   Total timesteps: 32256
                    Iteration time: 0.15s
                        Total time: 3.88s
                               ETA: 88.7s

################################################################################
                      [1m Learning iteration 21/500 [0m

                       Computation: 10189 steps/s (collection: 0.122s, learning 0.029s)
               Value function loss: 4.0485
                    Surrogate loss: -0.0045
             Mean action noise std: 1.01
                 Mean total reward: 48.49
               Mean episode length: 177.12
 Mean episode rew_tracking_lin_vel: 0.1204
 Mean episode rew_tracking_ang_vel: 0.0440
        Mean episode rew_lin_vel_z: -0.0074
      Mean episode rew_base_height: -0.0170
      Mean episode rew_action_rate: -0.0405
Mean episode rew_similar_to_default: -0.0608
Mean episode rew_joint_pose_matching: 0.0914
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0011
 Mean episode rew_forward_velocity: 4.4323
--------------------------------------------------------------------------------
                   Total timesteps: 33792
                    Iteration time: 0.15s
                        Total time: 4.03s
                               ETA: 87.8s

################################################################################
                      [1m Learning iteration 22/500 [0m

                       Computation: 10036 steps/s (collection: 0.121s, learning 0.032s)
               Value function loss: 4.0965
                    Surrogate loss: -0.0039
             Mean action noise std: 1.01
                 Mean total reward: 49.82
               Mean episode length: 181.81
 Mean episode rew_tracking_lin_vel: 0.0604
 Mean episode rew_tracking_ang_vel: 0.0222
        Mean episode rew_lin_vel_z: -0.0062
      Mean episode rew_base_height: -0.0122
      Mean episode rew_action_rate: -0.0217
Mean episode rew_similar_to_default: -0.0329
Mean episode rew_joint_pose_matching: 0.0450
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 2.2349
--------------------------------------------------------------------------------
                   Total timesteps: 35328
                    Iteration time: 0.15s
                        Total time: 4.19s
                               ETA: 87.0s

################################################################################
                      [1m Learning iteration 23/500 [0m

                       Computation: 10022 steps/s (collection: 0.123s, learning 0.030s)
               Value function loss: 5.5037
                    Surrogate loss: -0.0074
             Mean action noise std: 1.01
                 Mean total reward: 52.27
               Mean episode length: 190.78
 Mean episode rew_tracking_lin_vel: 0.0726
 Mean episode rew_tracking_ang_vel: 0.0275
        Mean episode rew_lin_vel_z: -0.0068
      Mean episode rew_base_height: -0.0140
      Mean episode rew_action_rate: -0.0261
Mean episode rew_similar_to_default: -0.0398
Mean episode rew_joint_pose_matching: 0.0562
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0013
 Mean episode rew_forward_velocity: 2.7732
--------------------------------------------------------------------------------
                   Total timesteps: 36864
                    Iteration time: 0.15s
                        Total time: 4.34s
                               ETA: 86.2s

################################################################################
                      [1m Learning iteration 24/500 [0m

                       Computation: 10223 steps/s (collection: 0.120s, learning 0.030s)
               Value function loss: 3.9495
                    Surrogate loss: -0.0087
             Mean action noise std: 1.01
                 Mean total reward: 54.40
               Mean episode length: 198.34
 Mean episode rew_tracking_lin_vel: 0.0524
 Mean episode rew_tracking_ang_vel: 0.0185
        Mean episode rew_lin_vel_z: -0.0071
      Mean episode rew_base_height: -0.0114
      Mean episode rew_action_rate: -0.0204
Mean episode rew_similar_to_default: -0.0310
Mean episode rew_joint_pose_matching: 0.0368
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0058
 Mean episode rew_forward_velocity: 2.0075
--------------------------------------------------------------------------------
                   Total timesteps: 38400
                    Iteration time: 0.15s
                        Total time: 4.49s
                               ETA: 85.5s

################################################################################
                      [1m Learning iteration 25/500 [0m

                       Computation: 10227 steps/s (collection: 0.120s, learning 0.030s)
               Value function loss: 4.1050
                    Surrogate loss: -0.0054
             Mean action noise std: 1.01
                 Mean total reward: 54.61
               Mean episode length: 199.20
 Mean episode rew_tracking_lin_vel: 0.0376
 Mean episode rew_tracking_ang_vel: 0.0137
        Mean episode rew_lin_vel_z: -0.0064
      Mean episode rew_base_height: -0.0075
      Mean episode rew_action_rate: -0.0155
Mean episode rew_similar_to_default: -0.0219
Mean episode rew_joint_pose_matching: 0.0251
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0037
 Mean episode rew_forward_velocity: 1.5262
--------------------------------------------------------------------------------
                   Total timesteps: 39936
                    Iteration time: 0.15s
                        Total time: 4.64s
                               ETA: 84.8s

################################################################################
                      [1m Learning iteration 26/500 [0m

                       Computation: 10637 steps/s (collection: 0.115s, learning 0.030s)
               Value function loss: 1.6073
                    Surrogate loss: -0.0101
             Mean action noise std: 1.01
                 Mean total reward: 54.61
               Mean episode length: 199.20
 Mean episode rew_tracking_lin_vel: 0.0081
 Mean episode rew_tracking_ang_vel: 0.0040
        Mean episode rew_lin_vel_z: -0.0050
      Mean episode rew_base_height: -0.0036
      Mean episode rew_action_rate: -0.0035
Mean episode rew_similar_to_default: -0.0041
Mean episode rew_joint_pose_matching: 0.0089
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.4063
--------------------------------------------------------------------------------
                   Total timesteps: 41472
                    Iteration time: 0.14s
                        Total time: 4.78s
                               ETA: 84.0s

################################################################################
                      [1m Learning iteration 27/500 [0m

                       Computation: 10192 steps/s (collection: 0.121s, learning 0.030s)
               Value function loss: 2.2439
                    Surrogate loss: 0.0002
             Mean action noise std: 1.01
                 Mean total reward: 55.60
               Mean episode length: 202.71
 Mean episode rew_tracking_lin_vel: 0.0898
 Mean episode rew_tracking_ang_vel: 0.0279
        Mean episode rew_lin_vel_z: -0.0072
      Mean episode rew_base_height: -0.0182
      Mean episode rew_action_rate: -0.0328
Mean episode rew_similar_to_default: -0.0515
Mean episode rew_joint_pose_matching: 0.0443
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.5301
--------------------------------------------------------------------------------
                   Total timesteps: 43008
                    Iteration time: 0.15s
                        Total time: 4.93s
                               ETA: 83.4s

################################################################################
                      [1m Learning iteration 28/500 [0m

                       Computation: 10049 steps/s (collection: 0.123s, learning 0.030s)
               Value function loss: 4.2636
                    Surrogate loss: -0.0074
             Mean action noise std: 1.01
                 Mean total reward: 58.30
               Mean episode length: 211.91
 Mean episode rew_tracking_lin_vel: 0.1080
 Mean episode rew_tracking_ang_vel: 0.0352
        Mean episode rew_lin_vel_z: -0.0070
      Mean episode rew_base_height: -0.0239
      Mean episode rew_action_rate: -0.0395
Mean episode rew_similar_to_default: -0.0630
Mean episode rew_joint_pose_matching: 0.0586
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0043
 Mean episode rew_forward_velocity: 4.2008
--------------------------------------------------------------------------------
                   Total timesteps: 44544
                    Iteration time: 0.15s
                        Total time: 5.09s
                               ETA: 82.8s

################################################################################
                      [1m Learning iteration 29/500 [0m

                       Computation: 10430 steps/s (collection: 0.117s, learning 0.030s)
               Value function loss: 1.2987
                    Surrogate loss: -0.0191
             Mean action noise std: 1.01
                 Mean total reward: 58.30
               Mean episode length: 211.91
 Mean episode rew_tracking_lin_vel: 0.0936
 Mean episode rew_tracking_ang_vel: 0.0323
        Mean episode rew_lin_vel_z: -0.0062
      Mean episode rew_base_height: -0.0212
      Mean episode rew_action_rate: -0.0349
Mean episode rew_similar_to_default: -0.0564
Mean episode rew_joint_pose_matching: 0.0462
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7865
--------------------------------------------------------------------------------
                   Total timesteps: 46080
                    Iteration time: 0.15s
                        Total time: 5.23s
                               ETA: 82.2s

################################################################################
                      [1m Learning iteration 30/500 [0m

                       Computation: 10590 steps/s (collection: 0.117s, learning 0.028s)
               Value function loss: 2.4236
                    Surrogate loss: 0.0011
             Mean action noise std: 1.01
                 Mean total reward: 59.00
               Mean episode length: 214.41
 Mean episode rew_tracking_lin_vel: 0.0936
 Mean episode rew_tracking_ang_vel: 0.0324
        Mean episode rew_lin_vel_z: -0.0062
      Mean episode rew_base_height: -0.0211
      Mean episode rew_action_rate: -0.0350
Mean episode rew_similar_to_default: -0.0563
Mean episode rew_joint_pose_matching: 0.0480
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7794
--------------------------------------------------------------------------------
                   Total timesteps: 47616
                    Iteration time: 0.15s
                        Total time: 5.38s
                               ETA: 81.6s

################################################################################
                      [1m Learning iteration 31/500 [0m

                       Computation: 10553 steps/s (collection: 0.116s, learning 0.030s)
               Value function loss: 2.1947
                    Surrogate loss: 0.0018
             Mean action noise std: 1.01
                 Mean total reward: 60.09
               Mean episode length: 218.21
 Mean episode rew_tracking_lin_vel: 0.1493
 Mean episode rew_tracking_ang_vel: 0.0536
        Mean episode rew_lin_vel_z: -0.0066
      Mean episode rew_base_height: -0.0335
      Mean episode rew_action_rate: -0.0559
Mean episode rew_similar_to_default: -0.0872
Mean episode rew_joint_pose_matching: 0.0840
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0007
 Mean episode rew_forward_velocity: 5.7920
--------------------------------------------------------------------------------
                   Total timesteps: 49152
                    Iteration time: 0.15s
                        Total time: 5.53s
                               ETA: 81.0s

################################################################################
                      [1m Learning iteration 32/500 [0m

                       Computation: 10331 steps/s (collection: 0.119s, learning 0.030s)
               Value function loss: 1.2281
                    Surrogate loss: 0.0019
             Mean action noise std: 1.01
                 Mean total reward: 60.09
               Mean episode length: 218.21
 Mean episode rew_tracking_lin_vel: 0.1964
 Mean episode rew_tracking_ang_vel: 0.0700
        Mean episode rew_lin_vel_z: -0.0076
      Mean episode rew_base_height: -0.0458
      Mean episode rew_action_rate: -0.0715
Mean episode rew_similar_to_default: -0.1147
Mean episode rew_joint_pose_matching: 0.0807
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0013
 Mean episode rew_forward_velocity: 7.6328
--------------------------------------------------------------------------------
                   Total timesteps: 50688
                    Iteration time: 0.15s
                        Total time: 5.67s
                               ETA: 80.5s

################################################################################
                      [1m Learning iteration 33/500 [0m

                       Computation: 10467 steps/s (collection: 0.116s, learning 0.031s)
               Value function loss: 1.1669
                    Surrogate loss: -0.0102
             Mean action noise std: 1.01
                 Mean total reward: 60.44
               Mean episode length: 219.35
 Mean episode rew_tracking_lin_vel: 0.1131
 Mean episode rew_tracking_ang_vel: 0.0465
        Mean episode rew_lin_vel_z: -0.0060
      Mean episode rew_base_height: -0.0255
      Mean episode rew_action_rate: -0.0464
Mean episode rew_similar_to_default: -0.0694
Mean episode rew_joint_pose_matching: 0.0661
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0010
 Mean episode rew_forward_velocity: 4.6602
--------------------------------------------------------------------------------
                   Total timesteps: 52224
                    Iteration time: 0.15s
                        Total time: 5.82s
                               ETA: 79.9s

################################################################################
                      [1m Learning iteration 34/500 [0m

                       Computation: 10378 steps/s (collection: 0.118s, learning 0.030s)
               Value function loss: 2.3864
                    Surrogate loss: -0.0079
             Mean action noise std: 1.01
                 Mean total reward: 61.53
               Mean episode length: 223.20
 Mean episode rew_tracking_lin_vel: 0.1399
 Mean episode rew_tracking_ang_vel: 0.0539
        Mean episode rew_lin_vel_z: -0.0065
      Mean episode rew_base_height: -0.0362
      Mean episode rew_action_rate: -0.0527
Mean episode rew_similar_to_default: -0.0865
Mean episode rew_joint_pose_matching: 0.0916
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0006
 Mean episode rew_forward_velocity: 5.5141
--------------------------------------------------------------------------------
                   Total timesteps: 53760
                    Iteration time: 0.15s
                        Total time: 5.97s
                               ETA: 79.5s

################################################################################
                      [1m Learning iteration 35/500 [0m

                       Computation: 10400 steps/s (collection: 0.118s, learning 0.030s)
               Value function loss: 1.8676
                    Surrogate loss: 0.0069
             Mean action noise std: 1.01
                 Mean total reward: 63.91
               Mean episode length: 231.55
 Mean episode rew_tracking_lin_vel: 0.2468
 Mean episode rew_tracking_ang_vel: 0.0830
        Mean episode rew_lin_vel_z: -0.0082
      Mean episode rew_base_height: -0.0579
      Mean episode rew_action_rate: -0.0867
Mean episode rew_similar_to_default: -0.1435
Mean episode rew_joint_pose_matching: 0.1294
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0023
 Mean episode rew_forward_velocity: 9.2266
--------------------------------------------------------------------------------
                   Total timesteps: 55296
                    Iteration time: 0.15s
                        Total time: 6.12s
                               ETA: 79.0s

################################################################################
                      [1m Learning iteration 36/500 [0m

                       Computation: 10306 steps/s (collection: 0.118s, learning 0.031s)
               Value function loss: 0.6851
                    Surrogate loss: -0.0073
             Mean action noise std: 1.01
                 Mean total reward: 63.91
               Mean episode length: 231.55
 Mean episode rew_tracking_lin_vel: 0.2562
 Mean episode rew_tracking_ang_vel: 0.0857
        Mean episode rew_lin_vel_z: -0.0081
      Mean episode rew_base_height: -0.0594
      Mean episode rew_action_rate: -0.0903
Mean episode rew_similar_to_default: -0.1489
Mean episode rew_joint_pose_matching: 0.1400
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0005
 Mean episode rew_forward_velocity: 9.6741
--------------------------------------------------------------------------------
                   Total timesteps: 56832
                    Iteration time: 0.15s
                        Total time: 6.27s
                               ETA: 78.6s

################################################################################
                      [1m Learning iteration 37/500 [0m

                       Computation: 10291 steps/s (collection: 0.118s, learning 0.031s)
               Value function loss: 3.3748
                    Surrogate loss: 0.0010
             Mean action noise std: 1.01
                 Mean total reward: 64.47
               Mean episode length: 233.32
 Mean episode rew_tracking_lin_vel: 0.1414
 Mean episode rew_tracking_ang_vel: 0.0528
        Mean episode rew_lin_vel_z: -0.0079
      Mean episode rew_base_height: -0.0404
      Mean episode rew_action_rate: -0.0536
Mean episode rew_similar_to_default: -0.0899
Mean episode rew_joint_pose_matching: 0.0688
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0004
 Mean episode rew_forward_velocity: 5.5481
--------------------------------------------------------------------------------
                   Total timesteps: 58368
                    Iteration time: 0.15s
                        Total time: 6.41s
                               ETA: 78.2s

################################################################################
                      [1m Learning iteration 38/500 [0m

                       Computation: 10398 steps/s (collection: 0.119s, learning 0.029s)
               Value function loss: 3.5452
                    Surrogate loss: -0.0074
             Mean action noise std: 1.01
                 Mean total reward: 67.39
               Mean episode length: 243.64
 Mean episode rew_tracking_lin_vel: 0.2127
 Mean episode rew_tracking_ang_vel: 0.0769
        Mean episode rew_lin_vel_z: -0.0091
      Mean episode rew_base_height: -0.0594
      Mean episode rew_action_rate: -0.0798
Mean episode rew_similar_to_default: -0.1337
Mean episode rew_joint_pose_matching: 0.1036
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0035
 Mean episode rew_forward_velocity: 8.1562
--------------------------------------------------------------------------------
                   Total timesteps: 59904
                    Iteration time: 0.15s
                        Total time: 6.56s
                               ETA: 77.7s

################################################################################
                      [1m Learning iteration 39/500 [0m

                       Computation: 10681 steps/s (collection: 0.116s, learning 0.028s)
               Value function loss: 0.7936
                    Surrogate loss: -0.0072
             Mean action noise std: 1.01
                 Mean total reward: 67.39
               Mean episode length: 243.64
 Mean episode rew_tracking_lin_vel: 0.3351
 Mean episode rew_tracking_ang_vel: 0.1194
        Mean episode rew_lin_vel_z: -0.0100
      Mean episode rew_base_height: -0.0868
      Mean episode rew_action_rate: -0.1244
Mean episode rew_similar_to_default: -0.2043
Mean episode rew_joint_pose_matching: 0.1729
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0076
 Mean episode rew_forward_velocity: 12.6753
--------------------------------------------------------------------------------
                   Total timesteps: 61440
                    Iteration time: 0.14s
                        Total time: 6.71s
                               ETA: 77.3s

################################################################################
                      [1m Learning iteration 40/500 [0m

                       Computation: 10607 steps/s (collection: 0.116s, learning 0.029s)
               Value function loss: 2.0776
                    Surrogate loss: -0.0038
             Mean action noise std: 1.01
                 Mean total reward: 66.93
               Mean episode length: 242.00
 Mean episode rew_tracking_lin_vel: 0.2293
 Mean episode rew_tracking_ang_vel: 0.0824
        Mean episode rew_lin_vel_z: -0.0086
      Mean episode rew_base_height: -0.0598
      Mean episode rew_action_rate: -0.0860
Mean episode rew_similar_to_default: -0.1398
Mean episode rew_joint_pose_matching: 0.1173
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0051
 Mean episode rew_forward_velocity: 8.7115
--------------------------------------------------------------------------------
                   Total timesteps: 62976
                    Iteration time: 0.14s
                        Total time: 6.85s
                               ETA: 76.9s

################################################################################
                      [1m Learning iteration 41/500 [0m

                       Computation: 10303 steps/s (collection: 0.121s, learning 0.028s)
               Value function loss: 2.1337
                    Surrogate loss: -0.0070
             Mean action noise std: 1.01
                 Mean total reward: 78.94
               Mean episode length: 284.87
 Mean episode rew_tracking_lin_vel: 0.1012
 Mean episode rew_tracking_ang_vel: 0.0390
        Mean episode rew_lin_vel_z: -0.0071
      Mean episode rew_base_height: -0.0322
      Mean episode rew_action_rate: -0.0395
Mean episode rew_similar_to_default: -0.0652
Mean episode rew_joint_pose_matching: 0.0410
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0021
 Mean episode rew_forward_velocity: 3.9083
--------------------------------------------------------------------------------
                   Total timesteps: 64512
                    Iteration time: 0.15s
                        Total time: 7.00s
                               ETA: 76.5s

################################################################################
                      [1m Learning iteration 42/500 [0m

                       Computation: 9997 steps/s (collection: 0.123s, learning 0.030s)
               Value function loss: 6.1575
                    Surrogate loss: -0.0110
             Mean action noise std: 1.01
                 Mean total reward: 80.99
               Mean episode length: 292.02
 Mean episode rew_tracking_lin_vel: 0.1836
 Mean episode rew_tracking_ang_vel: 0.0679
        Mean episode rew_lin_vel_z: -0.0084
      Mean episode rew_base_height: -0.0501
      Mean episode rew_action_rate: -0.0680
Mean episode rew_similar_to_default: -0.1145
Mean episode rew_joint_pose_matching: 0.0939
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0068
 Mean episode rew_forward_velocity: 7.0037
--------------------------------------------------------------------------------
                   Total timesteps: 66048
                    Iteration time: 0.15s
                        Total time: 7.15s
                               ETA: 76.2s

################################################################################
                      [1m Learning iteration 43/500 [0m

                       Computation: 9770 steps/s (collection: 0.127s, learning 0.030s)
               Value function loss: 4.6613
                    Surrogate loss: -0.0093
             Mean action noise std: 1.01
                 Mean total reward: 88.11
               Mean episode length: 317.17
 Mean episode rew_tracking_lin_vel: 0.2087
 Mean episode rew_tracking_ang_vel: 0.0776
        Mean episode rew_lin_vel_z: -0.0089
      Mean episode rew_base_height: -0.0707
      Mean episode rew_action_rate: -0.0767
Mean episode rew_similar_to_default: -0.1351
Mean episode rew_joint_pose_matching: 0.0722
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0089
 Mean episode rew_forward_velocity: 7.9929
--------------------------------------------------------------------------------
                   Total timesteps: 67584
                    Iteration time: 0.16s
                        Total time: 7.31s
                               ETA: 75.9s

################################################################################
                      [1m Learning iteration 44/500 [0m

                       Computation: 10010 steps/s (collection: 0.123s, learning 0.031s)
               Value function loss: 2.2037
                    Surrogate loss: -0.0105
             Mean action noise std: 1.01
                 Mean total reward: 90.60
               Mean episode length: 325.76
 Mean episode rew_tracking_lin_vel: 0.1579
 Mean episode rew_tracking_ang_vel: 0.0571
        Mean episode rew_lin_vel_z: -0.0084
      Mean episode rew_base_height: -0.0588
      Mean episode rew_action_rate: -0.0591
Mean episode rew_similar_to_default: -0.1053
Mean episode rew_joint_pose_matching: 0.0606
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0136
 Mean episode rew_forward_velocity: 6.1063
--------------------------------------------------------------------------------
                   Total timesteps: 69120
                    Iteration time: 0.15s
                        Total time: 7.46s
                               ETA: 75.6s

################################################################################
                      [1m Learning iteration 45/500 [0m

                       Computation: 10031 steps/s (collection: 0.124s, learning 0.029s)
               Value function loss: 0.4881
                    Surrogate loss: -0.0111
             Mean action noise std: 1.01
                 Mean total reward: 92.87
               Mean episode length: 334.02
 Mean episode rew_tracking_lin_vel: 0.3570
 Mean episode rew_tracking_ang_vel: 0.1264
        Mean episode rew_lin_vel_z: -0.0100
      Mean episode rew_base_height: -0.1109
      Mean episode rew_action_rate: -0.1365
Mean episode rew_similar_to_default: -0.2349
Mean episode rew_joint_pose_matching: 0.1494
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0089
 Mean episode rew_forward_velocity: 13.8797
--------------------------------------------------------------------------------
                   Total timesteps: 70656
                    Iteration time: 0.15s
                        Total time: 7.62s
                               ETA: 75.3s

################################################################################
                      [1m Learning iteration 46/500 [0m

                       Computation: 10103 steps/s (collection: 0.122s, learning 0.030s)
               Value function loss: 2.6599
                    Surrogate loss: -0.0042
             Mean action noise std: 1.01
                 Mean total reward: 93.58
               Mean episode length: 336.49
 Mean episode rew_tracking_lin_vel: 0.3137
 Mean episode rew_tracking_ang_vel: 0.1085
        Mean episode rew_lin_vel_z: -0.0095
      Mean episode rew_base_height: -0.1045
      Mean episode rew_action_rate: -0.1215
Mean episode rew_similar_to_default: -0.2122
Mean episode rew_joint_pose_matching: 0.1230
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0106
 Mean episode rew_forward_velocity: 12.0445
--------------------------------------------------------------------------------
                   Total timesteps: 72192
                    Iteration time: 0.15s
                        Total time: 7.77s
                               ETA: 75.1s

################################################################################
                      [1m Learning iteration 47/500 [0m

                       Computation: 10290 steps/s (collection: 0.119s, learning 0.030s)
               Value function loss: 0.3997
                    Surrogate loss: -0.0061
             Mean action noise std: 1.01
                 Mean total reward: 93.58
               Mean episode length: 336.49
 Mean episode rew_tracking_lin_vel: 0.1015
 Mean episode rew_tracking_ang_vel: 0.0339
        Mean episode rew_lin_vel_z: -0.0071
      Mean episode rew_base_height: -0.0415
      Mean episode rew_action_rate: -0.0403
Mean episode rew_similar_to_default: -0.0743
Mean episode rew_joint_pose_matching: 0.0331
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.0645
--------------------------------------------------------------------------------
                   Total timesteps: 73728
                    Iteration time: 0.15s
                        Total time: 7.92s
                               ETA: 74.7s

################################################################################
                      [1m Learning iteration 48/500 [0m

                       Computation: 10568 steps/s (collection: 0.116s, learning 0.030s)
               Value function loss: 0.6189
                    Surrogate loss: -0.0030
             Mean action noise std: 1.01
                 Mean total reward: 94.52
               Mean episode length: 339.67
 Mean episode rew_tracking_lin_vel: 0.2261
 Mean episode rew_tracking_ang_vel: 0.0801
        Mean episode rew_lin_vel_z: -0.0098
      Mean episode rew_base_height: -0.1017
      Mean episode rew_action_rate: -0.0887
Mean episode rew_similar_to_default: -0.1635
Mean episode rew_joint_pose_matching: 0.0391
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0044
 Mean episode rew_forward_velocity: 8.8439
--------------------------------------------------------------------------------
                   Total timesteps: 75264
                    Iteration time: 0.15s
                        Total time: 8.06s
                               ETA: 74.4s

################################################################################
                      [1m Learning iteration 49/500 [0m

                       Computation: 10391 steps/s (collection: 0.119s, learning 0.029s)
               Value function loss: 6.1077
                    Surrogate loss: -0.0107
             Mean action noise std: 1.01
                 Mean total reward: 94.29
               Mean episode length: 338.79
 Mean episode rew_tracking_lin_vel: 0.1266
 Mean episode rew_tracking_ang_vel: 0.0470
        Mean episode rew_lin_vel_z: -0.0080
      Mean episode rew_base_height: -0.0564
      Mean episode rew_action_rate: -0.0503
Mean episode rew_similar_to_default: -0.0932
Mean episode rew_joint_pose_matching: 0.0279
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0015
 Mean episode rew_forward_velocity: 4.9584
--------------------------------------------------------------------------------
                   Total timesteps: 76800
                    Iteration time: 0.15s
                        Total time: 8.21s
                               ETA: 74.1s

################################################################################
                      [1m Learning iteration 50/500 [0m

                       Computation: 10404 steps/s (collection: 0.120s, learning 0.028s)
               Value function loss: 4.1569
                    Surrogate loss: -0.0097
             Mean action noise std: 1.01
                 Mean total reward: 94.22
               Mean episode length: 338.35
 Mean episode rew_tracking_lin_vel: 0.0211
 Mean episode rew_tracking_ang_vel: 0.0106
        Mean episode rew_lin_vel_z: -0.0057
      Mean episode rew_base_height: -0.0115
      Mean episode rew_action_rate: -0.0093
Mean episode rew_similar_to_default: -0.0169
Mean episode rew_joint_pose_matching: 0.0100
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.9855
--------------------------------------------------------------------------------
                   Total timesteps: 78336
                    Iteration time: 0.15s
                        Total time: 8.36s
                               ETA: 73.8s

################################################################################
                      [1m Learning iteration 51/500 [0m

                       Computation: 10484 steps/s (collection: 0.117s, learning 0.030s)
               Value function loss: 3.4314
                    Surrogate loss: -0.0062
             Mean action noise std: 1.01
                 Mean total reward: 94.13
               Mean episode length: 338.11
 Mean episode rew_tracking_lin_vel: 0.0091
 Mean episode rew_tracking_ang_vel: 0.0059
        Mean episode rew_lin_vel_z: -0.0054
      Mean episode rew_base_height: -0.0058
      Mean episode rew_action_rate: -0.0043
Mean episode rew_similar_to_default: -0.0069
Mean episode rew_joint_pose_matching: 0.0106
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.5536
--------------------------------------------------------------------------------
                   Total timesteps: 79872
                    Iteration time: 0.15s
                        Total time: 8.51s
                               ETA: 73.4s

################################################################################
                      [1m Learning iteration 52/500 [0m

                       Computation: 9891 steps/s (collection: 0.127s, learning 0.028s)
               Value function loss: 13.0280
                    Surrogate loss: -0.0071
             Mean action noise std: 1.01
                 Mean total reward: 108.52
               Mean episode length: 388.55
 Mean episode rew_tracking_lin_vel: 0.1823
 Mean episode rew_tracking_ang_vel: 0.0678
        Mean episode rew_lin_vel_z: -0.0088
      Mean episode rew_base_height: -0.0794
      Mean episode rew_action_rate: -0.0720
Mean episode rew_similar_to_default: -0.1337
Mean episode rew_joint_pose_matching: 0.0537
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0012
 Mean episode rew_forward_velocity: 7.2641
--------------------------------------------------------------------------------
                   Total timesteps: 81408
                    Iteration time: 0.16s
                        Total time: 8.66s
                               ETA: 73.2s

################################################################################
                      [1m Learning iteration 53/500 [0m

                       Computation: 10038 steps/s (collection: 0.120s, learning 0.033s)
               Value function loss: 2.3014
                    Surrogate loss: -0.0060
             Mean action noise std: 1.01
                 Mean total reward: 110.78
               Mean episode length: 396.38
 Mean episode rew_tracking_lin_vel: 0.0918
 Mean episode rew_tracking_ang_vel: 0.0335
        Mean episode rew_lin_vel_z: -0.0070
      Mean episode rew_base_height: -0.0397
      Mean episode rew_action_rate: -0.0363
Mean episode rew_similar_to_default: -0.0654
Mean episode rew_joint_pose_matching: 0.0265
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0021
 Mean episode rew_forward_velocity: 3.6898
--------------------------------------------------------------------------------
                   Total timesteps: 82944
                    Iteration time: 0.15s
                        Total time: 8.81s
                               ETA: 73.0s

################################################################################
                      [1m Learning iteration 54/500 [0m

                       Computation: 9786 steps/s (collection: 0.126s, learning 0.031s)
               Value function loss: 4.5653
                    Surrogate loss: -0.0105
             Mean action noise std: 1.01
                 Mean total reward: 114.36
               Mean episode length: 409.31
 Mean episode rew_tracking_lin_vel: 0.0899
 Mean episode rew_tracking_ang_vel: 0.0348
        Mean episode rew_lin_vel_z: -0.0070
      Mean episode rew_base_height: -0.0425
      Mean episode rew_action_rate: -0.0363
Mean episode rew_similar_to_default: -0.0661
Mean episode rew_joint_pose_matching: 0.0258
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0013
 Mean episode rew_forward_velocity: 3.5426
--------------------------------------------------------------------------------
                   Total timesteps: 84480
                    Iteration time: 0.16s
                        Total time: 8.97s
                               ETA: 72.7s

################################################################################
                      [1m Learning iteration 55/500 [0m

                       Computation: 9670 steps/s (collection: 0.129s, learning 0.030s)
               Value function loss: 4.9130
                    Surrogate loss: -0.0103
             Mean action noise std: 1.01
                 Mean total reward: 121.80
               Mean episode length: 434.91
 Mean episode rew_tracking_lin_vel: 0.2777
 Mean episode rew_tracking_ang_vel: 0.1054
        Mean episode rew_lin_vel_z: -0.0095
      Mean episode rew_base_height: -0.1262
      Mean episode rew_action_rate: -0.1112
Mean episode rew_similar_to_default: -0.2055
Mean episode rew_joint_pose_matching: 0.0715
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0052
 Mean episode rew_forward_velocity: 10.9419
--------------------------------------------------------------------------------
                   Total timesteps: 86016
                    Iteration time: 0.16s
                        Total time: 9.13s
                               ETA: 72.6s

################################################################################
                      [1m Learning iteration 56/500 [0m

                       Computation: 10113 steps/s (collection: 0.122s, learning 0.030s)
               Value function loss: 6.8795
                    Surrogate loss: -0.0097
             Mean action noise std: 1.01
                 Mean total reward: 124.26
               Mean episode length: 443.30
 Mean episode rew_tracking_lin_vel: 0.2194
 Mean episode rew_tracking_ang_vel: 0.0876
        Mean episode rew_lin_vel_z: -0.0096
      Mean episode rew_base_height: -0.1097
      Mean episode rew_action_rate: -0.0866
Mean episode rew_similar_to_default: -0.1664
Mean episode rew_joint_pose_matching: 0.0550
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0053
 Mean episode rew_forward_velocity: 8.5600
--------------------------------------------------------------------------------
                   Total timesteps: 87552
                    Iteration time: 0.15s
                        Total time: 9.28s
                               ETA: 72.3s

################################################################################
                      [1m Learning iteration 57/500 [0m

                       Computation: 10504 steps/s (collection: 0.117s, learning 0.030s)
               Value function loss: 0.2608
                    Surrogate loss: -0.0107
             Mean action noise std: 1.01
                 Mean total reward: 126.41
               Mean episode length: 451.02
 Mean episode rew_tracking_lin_vel: 0.1403
 Mean episode rew_tracking_ang_vel: 0.0551
        Mean episode rew_lin_vel_z: -0.0076
      Mean episode rew_base_height: -0.0790
      Mean episode rew_action_rate: -0.0568
Mean episode rew_similar_to_default: -0.1091
Mean episode rew_joint_pose_matching: 0.0287
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 5.5682
--------------------------------------------------------------------------------
                   Total timesteps: 89088
                    Iteration time: 0.15s
                        Total time: 9.43s
                               ETA: 72.0s

################################################################################
                      [1m Learning iteration 58/500 [0m

                       Computation: 10490 steps/s (collection: 0.118s, learning 0.028s)
               Value function loss: 0.2505
                    Surrogate loss: 0.0069
             Mean action noise std: 1.01
                 Mean total reward: 131.07
               Mean episode length: 467.96
 Mean episode rew_tracking_lin_vel: 0.3626
 Mean episode rew_tracking_ang_vel: 0.1390
        Mean episode rew_lin_vel_z: -0.0104
      Mean episode rew_base_height: -0.1972
      Mean episode rew_action_rate: -0.1431
Mean episode rew_similar_to_default: -0.2785
Mean episode rew_joint_pose_matching: 0.0737
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0008
 Mean episode rew_forward_velocity: 13.9689
--------------------------------------------------------------------------------
                   Total timesteps: 90624
                    Iteration time: 0.15s
                        Total time: 9.57s
                               ETA: 71.7s

################################################################################
                      [1m Learning iteration 59/500 [0m

                       Computation: 10713 steps/s (collection: 0.115s, learning 0.028s)
               Value function loss: 0.2267
                    Surrogate loss: -0.0061
             Mean action noise std: 1.01
                 Mean total reward: 131.07
               Mean episode length: 467.96
 Mean episode rew_tracking_lin_vel: 0.3624
 Mean episode rew_tracking_ang_vel: 0.1379
        Mean episode rew_lin_vel_z: -0.0100
      Mean episode rew_base_height: -0.1753
      Mean episode rew_action_rate: -0.1433
Mean episode rew_similar_to_default: -0.2759
Mean episode rew_joint_pose_matching: 0.0725
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0160
 Mean episode rew_forward_velocity: 13.7532
--------------------------------------------------------------------------------
                   Total timesteps: 92160
                    Iteration time: 0.14s
                        Total time: 9.72s
                               ETA: 71.4s

################################################################################
                      [1m Learning iteration 60/500 [0m

                       Computation: 10051 steps/s (collection: 0.119s, learning 0.033s)
               Value function loss: 1.9192
                    Surrogate loss: -0.0074
             Mean action noise std: 1.01
                 Mean total reward: 133.63
               Mean episode length: 477.05
 Mean episode rew_tracking_lin_vel: 0.1113
 Mean episode rew_tracking_ang_vel: 0.0436
        Mean episode rew_lin_vel_z: -0.0084
      Mean episode rew_base_height: -0.0614
      Mean episode rew_action_rate: -0.0448
Mean episode rew_similar_to_default: -0.0881
Mean episode rew_joint_pose_matching: 0.0200
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0036
 Mean episode rew_forward_velocity: 4.3778
--------------------------------------------------------------------------------
                   Total timesteps: 93696
                    Iteration time: 0.15s
                        Total time: 9.87s
                               ETA: 71.2s

################################################################################
                      [1m Learning iteration 61/500 [0m

                       Computation: 9855 steps/s (collection: 0.126s, learning 0.030s)
               Value function loss: 6.3073
                    Surrogate loss: -0.0072
             Mean action noise std: 1.01
                 Mean total reward: 142.43
               Mean episode length: 508.67
 Mean episode rew_tracking_lin_vel: 0.1712
 Mean episode rew_tracking_ang_vel: 0.0674
        Mean episode rew_lin_vel_z: -0.0096
      Mean episode rew_base_height: -0.1020
      Mean episode rew_action_rate: -0.0696
Mean episode rew_similar_to_default: -0.1404
Mean episode rew_joint_pose_matching: 0.0338
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0029
 Mean episode rew_forward_velocity: 6.7927
--------------------------------------------------------------------------------
                   Total timesteps: 95232
                    Iteration time: 0.16s
                        Total time: 10.03s
                               ETA: 71.0s

################################################################################
                      [1m Learning iteration 62/500 [0m

                       Computation: 10321 steps/s (collection: 0.119s, learning 0.030s)
               Value function loss: 0.6337
                    Surrogate loss: -0.0092
             Mean action noise std: 1.01
                 Mean total reward: 143.66
               Mean episode length: 513.45
 Mean episode rew_tracking_lin_vel: 0.2558
 Mean episode rew_tracking_ang_vel: 0.0960
        Mean episode rew_lin_vel_z: -0.0108
      Mean episode rew_base_height: -0.1577
      Mean episode rew_action_rate: -0.1033
Mean episode rew_similar_to_default: -0.2129
Mean episode rew_joint_pose_matching: 0.0435
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0082
 Mean episode rew_forward_velocity: 9.9701
--------------------------------------------------------------------------------
                   Total timesteps: 96768
                    Iteration time: 0.15s
                        Total time: 10.18s
                               ETA: 70.7s

################################################################################
                      [1m Learning iteration 63/500 [0m

                       Computation: 10159 steps/s (collection: 0.121s, learning 0.030s)
               Value function loss: 1.5038
                    Surrogate loss: -0.0046
             Mean action noise std: 1.01
                 Mean total reward: 147.19
               Mean episode length: 526.19
 Mean episode rew_tracking_lin_vel: 0.2053
 Mean episode rew_tracking_ang_vel: 0.0795
        Mean episode rew_lin_vel_z: -0.0098
      Mean episode rew_base_height: -0.1250
      Mean episode rew_action_rate: -0.0834
Mean episode rew_similar_to_default: -0.1679
Mean episode rew_joint_pose_matching: 0.0363
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0035
 Mean episode rew_forward_velocity: 7.9903
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 0.15s
                        Total time: 10.33s
                               ETA: 70.5s

################################################################################
                      [1m Learning iteration 64/500 [0m

                       Computation: 9941 steps/s (collection: 0.124s, learning 0.030s)
               Value function loss: 6.0195
                    Surrogate loss: -0.0089
             Mean action noise std: 1.01
                 Mean total reward: 150.75
               Mean episode length: 539.05
 Mean episode rew_tracking_lin_vel: 0.1929
 Mean episode rew_tracking_ang_vel: 0.0750
        Mean episode rew_lin_vel_z: -0.0095
      Mean episode rew_base_height: -0.1346
      Mean episode rew_action_rate: -0.0802
Mean episode rew_similar_to_default: -0.1702
Mean episode rew_joint_pose_matching: 0.0336
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0021
 Mean episode rew_forward_velocity: 7.6780
--------------------------------------------------------------------------------
                   Total timesteps: 99840
                    Iteration time: 0.15s
                        Total time: 10.48s
                               ETA: 70.3s

################################################################################
                      [1m Learning iteration 65/500 [0m

                       Computation: 10343 steps/s (collection: 0.119s, learning 0.029s)
               Value function loss: 0.2580
                    Surrogate loss: -0.0115
             Mean action noise std: 1.01
                 Mean total reward: 155.37
               Mean episode length: 556.01
 Mean episode rew_tracking_lin_vel: 0.3411
 Mean episode rew_tracking_ang_vel: 0.1307
        Mean episode rew_lin_vel_z: -0.0137
      Mean episode rew_base_height: -0.2326
      Mean episode rew_action_rate: -0.1343
Mean episode rew_similar_to_default: -0.2910
Mean episode rew_joint_pose_matching: 0.0537
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0036
 Mean episode rew_forward_velocity: 13.0751
--------------------------------------------------------------------------------
                   Total timesteps: 101376
                    Iteration time: 0.15s
                        Total time: 10.63s
                               ETA: 70.1s

################################################################################
                      [1m Learning iteration 66/500 [0m

                       Computation: 9995 steps/s (collection: 0.125s, learning 0.028s)
               Value function loss: 7.4633
                    Surrogate loss: 0.0031
             Mean action noise std: 1.01
                 Mean total reward: 155.53
               Mean episode length: 556.74
 Mean episode rew_tracking_lin_vel: 0.1285
 Mean episode rew_tracking_ang_vel: 0.0487
        Mean episode rew_lin_vel_z: -0.0109
      Mean episode rew_base_height: -0.0979
      Mean episode rew_action_rate: -0.0512
Mean episode rew_similar_to_default: -0.1131
Mean episode rew_joint_pose_matching: 0.0189
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0018
 Mean episode rew_forward_velocity: 5.0270
--------------------------------------------------------------------------------
                   Total timesteps: 102912
                    Iteration time: 0.15s
                        Total time: 10.78s
                               ETA: 69.9s

################################################################################
                      [1m Learning iteration 67/500 [0m

                       Computation: 10031 steps/s (collection: 0.124s, learning 0.029s)
               Value function loss: 0.1441
                    Surrogate loss: -0.0157
             Mean action noise std: 1.01
                 Mean total reward: 159.56
               Mean episode length: 571.64
 Mean episode rew_tracking_lin_vel: 0.3005
 Mean episode rew_tracking_ang_vel: 0.1134
        Mean episode rew_lin_vel_z: -0.0118
      Mean episode rew_base_height: -0.2249
      Mean episode rew_action_rate: -0.1210
Mean episode rew_similar_to_default: -0.2669
Mean episode rew_joint_pose_matching: 0.0471
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0017
 Mean episode rew_forward_velocity: 11.5674
--------------------------------------------------------------------------------
                   Total timesteps: 104448
                    Iteration time: 0.15s
                        Total time: 10.94s
                               ETA: 69.6s

################################################################################
                      [1m Learning iteration 68/500 [0m

                       Computation: 9880 steps/s (collection: 0.127s, learning 0.028s)
               Value function loss: 7.8343
                    Surrogate loss: 0.0000
             Mean action noise std: 1.01
                 Mean total reward: 159.83
               Mean episode length: 573.01
 Mean episode rew_tracking_lin_vel: 0.1737
 Mean episode rew_tracking_ang_vel: 0.0670
        Mean episode rew_lin_vel_z: -0.0120
      Mean episode rew_base_height: -0.1754
      Mean episode rew_action_rate: -0.0705
Mean episode rew_similar_to_default: -0.1729
Mean episode rew_joint_pose_matching: 0.0140
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0022
 Mean episode rew_forward_velocity: 6.7931
--------------------------------------------------------------------------------
                   Total timesteps: 105984
                    Iteration time: 0.16s
                        Total time: 11.09s
                               ETA: 69.4s

################################################################################
                      [1m Learning iteration 69/500 [0m

                       Computation: 10107 steps/s (collection: 0.123s, learning 0.029s)
               Value function loss: 6.3912
                    Surrogate loss: -0.0073
             Mean action noise std: 1.01
                 Mean total reward: 162.76
               Mean episode length: 584.26
 Mean episode rew_tracking_lin_vel: 0.2048
 Mean episode rew_tracking_ang_vel: 0.0763
        Mean episode rew_lin_vel_z: -0.0110
      Mean episode rew_base_height: -0.1642
      Mean episode rew_action_rate: -0.0821
Mean episode rew_similar_to_default: -0.1814
Mean episode rew_joint_pose_matching: 0.0239
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0011
 Mean episode rew_forward_velocity: 7.6370
--------------------------------------------------------------------------------
                   Total timesteps: 107520
                    Iteration time: 0.15s
                        Total time: 11.24s
                               ETA: 69.2s

################################################################################
                      [1m Learning iteration 70/500 [0m

                       Computation: 9922 steps/s (collection: 0.126s, learning 0.029s)
               Value function loss: 1.5726
                    Surrogate loss: -0.0032
             Mean action noise std: 1.01
                 Mean total reward: 168.15
               Mean episode length: 604.25
 Mean episode rew_tracking_lin_vel: 0.2904
 Mean episode rew_tracking_ang_vel: 0.1146
        Mean episode rew_lin_vel_z: -0.0118
      Mean episode rew_base_height: -0.2571
      Mean episode rew_action_rate: -0.1173
Mean episode rew_similar_to_default: -0.2745
Mean episode rew_joint_pose_matching: 0.0321
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0006
 Mean episode rew_forward_velocity: 11.2852
--------------------------------------------------------------------------------
                   Total timesteps: 109056
                    Iteration time: 0.15s
                        Total time: 11.40s
                               ETA: 69.0s

################################################################################
                      [1m Learning iteration 71/500 [0m

                       Computation: 10029 steps/s (collection: 0.124s, learning 0.029s)
               Value function loss: 4.3669
                    Surrogate loss: 0.0005
             Mean action noise std: 1.01
                 Mean total reward: 167.53
               Mean episode length: 602.35
 Mean episode rew_tracking_lin_vel: 0.1728
 Mean episode rew_tracking_ang_vel: 0.0714
        Mean episode rew_lin_vel_z: -0.0099
      Mean episode rew_base_height: -0.1774
      Mean episode rew_action_rate: -0.0709
Mean episode rew_similar_to_default: -0.1737
Mean episode rew_joint_pose_matching: 0.0128
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 6.7892
--------------------------------------------------------------------------------
                   Total timesteps: 110592
                    Iteration time: 0.15s
                        Total time: 11.55s
                               ETA: 68.8s

################################################################################
                      [1m Learning iteration 72/500 [0m

                       Computation: 10099 steps/s (collection: 0.123s, learning 0.029s)
               Value function loss: 0.1324
                    Surrogate loss: -0.0055
             Mean action noise std: 1.01
                 Mean total reward: 169.50
               Mean episode length: 609.68
 Mean episode rew_tracking_lin_vel: 0.2077
 Mean episode rew_tracking_ang_vel: 0.0858
        Mean episode rew_lin_vel_z: -0.0103
      Mean episode rew_base_height: -0.2321
      Mean episode rew_action_rate: -0.0850
Mean episode rew_similar_to_default: -0.2165
Mean episode rew_joint_pose_matching: 0.0180
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0047
 Mean episode rew_forward_velocity: 8.1565
--------------------------------------------------------------------------------
                   Total timesteps: 112128
                    Iteration time: 0.15s
                        Total time: 11.70s
                               ETA: 68.6s

################################################################################
                      [1m Learning iteration 73/500 [0m

                       Computation: 10480 steps/s (collection: 0.118s, learning 0.029s)
               Value function loss: 0.1331
                    Surrogate loss: -0.0032
             Mean action noise std: 1.01
                 Mean total reward: 170.60
               Mean episode length: 614.28
 Mean episode rew_tracking_lin_vel: 0.3625
 Mean episode rew_tracking_ang_vel: 0.1331
        Mean episode rew_lin_vel_z: -0.0135
      Mean episode rew_base_height: -0.3419
      Mean episode rew_action_rate: -0.1455
Mean episode rew_similar_to_default: -0.3476
Mean episode rew_joint_pose_matching: 0.0388
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0027
 Mean episode rew_forward_velocity: 13.5743
--------------------------------------------------------------------------------
                   Total timesteps: 113664
                    Iteration time: 0.15s
                        Total time: 11.85s
                               ETA: 68.4s

################################################################################
                      [1m Learning iteration 74/500 [0m

                       Computation: 10055 steps/s (collection: 0.125s, learning 0.028s)
               Value function loss: 0.1504
                    Surrogate loss: -0.0126
             Mean action noise std: 1.01
                 Mean total reward: 172.36
               Mean episode length: 621.05
 Mean episode rew_tracking_lin_vel: 0.3624
 Mean episode rew_tracking_ang_vel: 0.1340
        Mean episode rew_lin_vel_z: -0.0138
      Mean episode rew_base_height: -0.3514
      Mean episode rew_action_rate: -0.1451
Mean episode rew_similar_to_default: -0.3494
Mean episode rew_joint_pose_matching: 0.0350
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0009
 Mean episode rew_forward_velocity: 13.5839
--------------------------------------------------------------------------------
                   Total timesteps: 115200
                    Iteration time: 0.15s
                        Total time: 12.00s
                               ETA: 68.2s

################################################################################
                      [1m Learning iteration 75/500 [0m

                       Computation: 10161 steps/s (collection: 0.123s, learning 0.029s)
               Value function loss: 0.1035
                    Surrogate loss: -0.0070
             Mean action noise std: 1.01
                 Mean total reward: 172.36
               Mean episode length: 621.05
 Mean episode rew_tracking_lin_vel: 0.3584
 Mean episode rew_tracking_ang_vel: 0.1409
        Mean episode rew_lin_vel_z: -0.0143
      Mean episode rew_base_height: -0.3753
      Mean episode rew_action_rate: -0.1425
Mean episode rew_similar_to_default: -0.3529
Mean episode rew_joint_pose_matching: 0.0261
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0024
 Mean episode rew_forward_velocity: 13.7800
--------------------------------------------------------------------------------
                   Total timesteps: 116736
                    Iteration time: 0.15s
                        Total time: 12.15s
                               ETA: 68.0s

################################################################################
                      [1m Learning iteration 76/500 [0m

                       Computation: 9258 steps/s (collection: 0.137s, learning 0.029s)
               Value function loss: 0.1311
                    Surrogate loss: -0.0024
             Mean action noise std: 1.01
                 Mean total reward: 173.74
               Mean episode length: 626.24
 Mean episode rew_tracking_lin_vel: 0.3581
 Mean episode rew_tracking_ang_vel: 0.1410
        Mean episode rew_lin_vel_z: -0.0142
      Mean episode rew_base_height: -0.3793
      Mean episode rew_action_rate: -0.1427
Mean episode rew_similar_to_default: -0.3542
Mean episode rew_joint_pose_matching: 0.0291
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0024
 Mean episode rew_forward_velocity: 13.8144
--------------------------------------------------------------------------------
                   Total timesteps: 118272
                    Iteration time: 0.17s
                        Total time: 12.32s
                               ETA: 67.8s

################################################################################
                      [1m Learning iteration 77/500 [0m

                       Computation: 9891 steps/s (collection: 0.125s, learning 0.031s)
               Value function loss: 0.1226
                    Surrogate loss: -0.0046
             Mean action noise std: 1.01
                 Mean total reward: 173.74
               Mean episode length: 626.24
 Mean episode rew_tracking_lin_vel: 0.3561
 Mean episode rew_tracking_ang_vel: 0.1415
        Mean episode rew_lin_vel_z: -0.0133
      Mean episode rew_base_height: -0.4071
      Mean episode rew_action_rate: -0.1445
Mean episode rew_similar_to_default: -0.3634
Mean episode rew_joint_pose_matching: 0.0504
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0022
 Mean episode rew_forward_velocity: 14.0546
--------------------------------------------------------------------------------
                   Total timesteps: 119808
                    Iteration time: 0.16s
                        Total time: 12.48s
                               ETA: 67.7s

################################################################################
                      [1m Learning iteration 78/500 [0m

                       Computation: 9802 steps/s (collection: 0.126s, learning 0.030s)
               Value function loss: 0.1288
                    Surrogate loss: 0.0005
             Mean action noise std: 1.01
                 Mean total reward: 174.99
               Mean episode length: 630.99
 Mean episode rew_tracking_lin_vel: 0.3564
 Mean episode rew_tracking_ang_vel: 0.1415
        Mean episode rew_lin_vel_z: -0.0135
      Mean episode rew_base_height: -0.4150
      Mean episode rew_action_rate: -0.1444
Mean episode rew_similar_to_default: -0.3656
Mean episode rew_joint_pose_matching: 0.0476
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0021
 Mean episode rew_forward_velocity: 14.0421
--------------------------------------------------------------------------------
                   Total timesteps: 121344
                    Iteration time: 0.16s
                        Total time: 12.63s
                               ETA: 67.5s

################################################################################
                      [1m Learning iteration 79/500 [0m

                       Computation: 9768 steps/s (collection: 0.127s, learning 0.030s)
               Value function loss: 0.1553
                    Surrogate loss: 0.0048
             Mean action noise std: 1.01
                 Mean total reward: 175.71
               Mean episode length: 634.12
 Mean episode rew_tracking_lin_vel: 0.3620
 Mean episode rew_tracking_ang_vel: 0.1462
        Mean episode rew_lin_vel_z: -0.0155
      Mean episode rew_base_height: -0.4900
      Mean episode rew_action_rate: -0.1426
Mean episode rew_similar_to_default: -0.3841
Mean episode rew_joint_pose_matching: 0.0329
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0003
 Mean episode rew_forward_velocity: 13.8979
--------------------------------------------------------------------------------
                   Total timesteps: 122880
                    Iteration time: 0.16s
                        Total time: 12.79s
                               ETA: 67.3s

################################################################################
                      [1m Learning iteration 80/500 [0m

                       Computation: 9711 steps/s (collection: 0.128s, learning 0.030s)
               Value function loss: 0.1534
                    Surrogate loss: -0.0004
             Mean action noise std: 1.01
                 Mean total reward: 177.36
               Mean episode length: 640.79
 Mean episode rew_tracking_lin_vel: 0.3626
 Mean episode rew_tracking_ang_vel: 0.1441
        Mean episode rew_lin_vel_z: -0.0171
      Mean episode rew_base_height: -0.5008
      Mean episode rew_action_rate: -0.1443
Mean episode rew_similar_to_default: -0.3884
Mean episode rew_joint_pose_matching: 0.0372
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6396
--------------------------------------------------------------------------------
                   Total timesteps: 124416
                    Iteration time: 0.16s
                        Total time: 12.95s
                               ETA: 67.1s

################################################################################
                      [1m Learning iteration 81/500 [0m

                       Computation: 9939 steps/s (collection: 0.124s, learning 0.031s)
               Value function loss: 0.1076
                    Surrogate loss: -0.0069
             Mean action noise std: 1.01
                 Mean total reward: 177.36
               Mean episode length: 640.79
 Mean episode rew_tracking_lin_vel: 0.3623
 Mean episode rew_tracking_ang_vel: 0.1426
        Mean episode rew_lin_vel_z: -0.0180
      Mean episode rew_base_height: -0.5073
      Mean episode rew_action_rate: -0.1451
Mean episode rew_similar_to_default: -0.3910
Mean episode rew_joint_pose_matching: 0.0363
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5344
--------------------------------------------------------------------------------
                   Total timesteps: 125952
                    Iteration time: 0.15s
                        Total time: 13.10s
                               ETA: 66.9s

################################################################################
                      [1m Learning iteration 82/500 [0m

                       Computation: 9761 steps/s (collection: 0.127s, learning 0.030s)
               Value function loss: 1.3263
                    Surrogate loss: -0.0023
             Mean action noise std: 1.01
                 Mean total reward: 177.83
               Mean episode length: 642.71
 Mean episode rew_tracking_lin_vel: 0.1936
 Mean episode rew_tracking_ang_vel: 0.0792
        Mean episode rew_lin_vel_z: -0.0126
      Mean episode rew_base_height: -0.4118
      Mean episode rew_action_rate: -0.0774
Mean episode rew_similar_to_default: -0.2478
Mean episode rew_joint_pose_matching: 0.0049
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.6585
--------------------------------------------------------------------------------
                   Total timesteps: 127488
                    Iteration time: 0.16s
                        Total time: 13.26s
                               ETA: 66.8s

################################################################################
                      [1m Learning iteration 83/500 [0m

                       Computation: 9895 steps/s (collection: 0.126s, learning 0.029s)
               Value function loss: 0.1508
                    Surrogate loss: -0.0015
             Mean action noise std: 1.01
                 Mean total reward: 179.29
               Mean episode length: 649.09
 Mean episode rew_tracking_lin_vel: 0.2515
 Mean episode rew_tracking_ang_vel: 0.1034
        Mean episode rew_lin_vel_z: -0.0127
      Mean episode rew_base_height: -0.4857
      Mean episode rew_action_rate: -0.1001
Mean episode rew_similar_to_default: -0.3123
Mean episode rew_joint_pose_matching: 0.0202
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0005
 Mean episode rew_forward_velocity: 9.9243
--------------------------------------------------------------------------------
                   Total timesteps: 129024
                    Iteration time: 0.16s
                        Total time: 13.41s
                               ETA: 66.6s

################################################################################
                      [1m Learning iteration 84/500 [0m

                       Computation: 9919 steps/s (collection: 0.125s, learning 0.029s)
               Value function loss: 3.3806
                    Surrogate loss: -0.0004
             Mean action noise std: 1.01
                 Mean total reward: 180.55
               Mean episode length: 654.53
 Mean episode rew_tracking_lin_vel: 0.2708
 Mean episode rew_tracking_ang_vel: 0.1091
        Mean episode rew_lin_vel_z: -0.0132
      Mean episode rew_base_height: -0.4503
      Mean episode rew_action_rate: -0.1088
Mean episode rew_similar_to_default: -0.3147
Mean episode rew_joint_pose_matching: 0.0228
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 10.5038
--------------------------------------------------------------------------------
                   Total timesteps: 130560
                    Iteration time: 0.15s
                        Total time: 13.57s
                               ETA: 66.4s

################################################################################
                      [1m Learning iteration 85/500 [0m

                       Computation: 9968 steps/s (collection: 0.125s, learning 0.030s)
               Value function loss: 0.1431
                    Surrogate loss: -0.0056
             Mean action noise std: 1.01
                 Mean total reward: 180.27
               Mean episode length: 654.53
 Mean episode rew_tracking_lin_vel: 0.3585
 Mean episode rew_tracking_ang_vel: 0.1489
        Mean episode rew_lin_vel_z: -0.0138
      Mean episode rew_base_height: -0.6198
      Mean episode rew_action_rate: -0.1469
Mean episode rew_similar_to_default: -0.4244
Mean episode rew_joint_pose_matching: 0.0287
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0001
 Mean episode rew_forward_velocity: 13.9825
--------------------------------------------------------------------------------
                   Total timesteps: 132096
                    Iteration time: 0.15s
                        Total time: 13.72s
                               ETA: 66.2s

################################################################################
                      [1m Learning iteration 86/500 [0m

                       Computation: 10029 steps/s (collection: 0.124s, learning 0.029s)
               Value function loss: 0.1536
                    Surrogate loss: 0.0081
             Mean action noise std: 1.01
                 Mean total reward: 179.85
               Mean episode length: 654.53
 Mean episode rew_tracking_lin_vel: 0.3585
 Mean episode rew_tracking_ang_vel: 0.1441
        Mean episode rew_lin_vel_z: -0.0135
      Mean episode rew_base_height: -0.6369
      Mean episode rew_action_rate: -0.1441
Mean episode rew_similar_to_default: -0.4244
Mean episode rew_joint_pose_matching: 0.0212
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.8077
--------------------------------------------------------------------------------
                   Total timesteps: 133632
                    Iteration time: 0.15s
                        Total time: 13.88s
                               ETA: 66.0s

################################################################################
                      [1m Learning iteration 87/500 [0m

                       Computation: 9582 steps/s (collection: 0.129s, learning 0.031s)
               Value function loss: 0.1283
                    Surrogate loss: 0.0019
             Mean action noise std: 1.01
                 Mean total reward: 179.85
               Mean episode length: 654.53
 Mean episode rew_tracking_lin_vel: 0.3537
 Mean episode rew_tracking_ang_vel: 0.1462
        Mean episode rew_lin_vel_z: -0.0124
      Mean episode rew_base_height: -0.6395
      Mean episode rew_action_rate: -0.1452
Mean episode rew_similar_to_default: -0.4222
Mean episode rew_joint_pose_matching: 0.0195
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7147
--------------------------------------------------------------------------------
                   Total timesteps: 135168
                    Iteration time: 0.16s
                        Total time: 14.04s
                               ETA: 65.9s

################################################################################
                      [1m Learning iteration 88/500 [0m

                       Computation: 9501 steps/s (collection: 0.131s, learning 0.031s)
               Value function loss: 0.0854
                    Surrogate loss: 0.0004
             Mean action noise std: 1.01
                 Mean total reward: 179.85
               Mean episode length: 654.53
 Mean episode rew_tracking_lin_vel: 0.3537
 Mean episode rew_tracking_ang_vel: 0.1462
        Mean episode rew_lin_vel_z: -0.0124
      Mean episode rew_base_height: -0.6395
      Mean episode rew_action_rate: -0.1452
Mean episode rew_similar_to_default: -0.4222
Mean episode rew_joint_pose_matching: 0.0195
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7147
--------------------------------------------------------------------------------
                   Total timesteps: 136704
                    Iteration time: 0.16s
                        Total time: 14.20s
                               ETA: 65.7s

################################################################################
                      [1m Learning iteration 89/500 [0m

                       Computation: 9541 steps/s (collection: 0.130s, learning 0.030s)
               Value function loss: 0.1023
                    Surrogate loss: 0.0103
             Mean action noise std: 1.01
                 Mean total reward: 181.11
               Mean episode length: 659.82
 Mean episode rew_tracking_lin_vel: 0.3547
 Mean episode rew_tracking_ang_vel: 0.1464
        Mean episode rew_lin_vel_z: -0.0134
      Mean episode rew_base_height: -0.6772
      Mean episode rew_action_rate: -0.1464
Mean episode rew_similar_to_default: -0.4330
Mean episode rew_joint_pose_matching: 0.0163
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7470
--------------------------------------------------------------------------------
                   Total timesteps: 138240
                    Iteration time: 0.16s
                        Total time: 14.36s
                               ETA: 65.6s

################################################################################
                      [1m Learning iteration 90/500 [0m

                       Computation: 9488 steps/s (collection: 0.132s, learning 0.030s)
               Value function loss: 0.1096
                    Surrogate loss: 0.0075
             Mean action noise std: 1.01
                 Mean total reward: 181.11
               Mean episode length: 659.82
 Mean episode rew_tracking_lin_vel: 0.3572
 Mean episode rew_tracking_ang_vel: 0.1469
        Mean episode rew_lin_vel_z: -0.0158
      Mean episode rew_base_height: -0.7688
      Mean episode rew_action_rate: -0.1491
Mean episode rew_similar_to_default: -0.4592
Mean episode rew_joint_pose_matching: 0.0084
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.8253
--------------------------------------------------------------------------------
                   Total timesteps: 139776
                    Iteration time: 0.16s
                        Total time: 14.52s
                               ETA: 65.4s

################################################################################
                      [1m Learning iteration 91/500 [0m

                       Computation: 9399 steps/s (collection: 0.133s, learning 0.031s)
               Value function loss: 0.0995
                    Surrogate loss: 0.0013
             Mean action noise std: 1.01
                 Mean total reward: 184.45
               Mean episode length: 673.23
 Mean episode rew_tracking_lin_vel: 0.3582
 Mean episode rew_tracking_ang_vel: 0.1486
        Mean episode rew_lin_vel_z: -0.0146
      Mean episode rew_base_height: -0.7936
      Mean episode rew_action_rate: -0.1462
Mean episode rew_similar_to_default: -0.4612
Mean episode rew_joint_pose_matching: 0.0088
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.8317
--------------------------------------------------------------------------------
                   Total timesteps: 141312
                    Iteration time: 0.16s
                        Total time: 14.69s
                               ETA: 65.3s

################################################################################
                      [1m Learning iteration 92/500 [0m

                       Computation: 9311 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.1174
                    Surrogate loss: -0.0007
             Mean action noise std: 1.01
                 Mean total reward: 184.45
               Mean episode length: 673.23
 Mean episode rew_tracking_lin_vel: 0.3635
 Mean episode rew_tracking_ang_vel: 0.1488
        Mean episode rew_lin_vel_z: -0.0141
      Mean episode rew_base_height: -0.8077
      Mean episode rew_action_rate: -0.1446
Mean episode rew_similar_to_default: -0.4605
Mean episode rew_joint_pose_matching: 0.0071
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7533
--------------------------------------------------------------------------------
                   Total timesteps: 142848
                    Iteration time: 0.16s
                        Total time: 14.85s
                               ETA: 65.1s

################################################################################
                      [1m Learning iteration 93/500 [0m

                       Computation: 9275 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 0.1230
                    Surrogate loss: 0.0112
             Mean action noise std: 1.01
                 Mean total reward: 184.12
               Mean episode length: 673.23
 Mean episode rew_tracking_lin_vel: 0.3612
 Mean episode rew_tracking_ang_vel: 0.1486
        Mean episode rew_lin_vel_z: -0.0149
      Mean episode rew_base_height: -0.8358
      Mean episode rew_action_rate: -0.1422
Mean episode rew_similar_to_default: -0.4663
Mean episode rew_joint_pose_matching: 0.0096
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6880
--------------------------------------------------------------------------------
                   Total timesteps: 144384
                    Iteration time: 0.17s
                        Total time: 15.02s
                               ETA: 65.0s

################################################################################
                      [1m Learning iteration 94/500 [0m

                       Computation: 9519 steps/s (collection: 0.134s, learning 0.028s)
               Value function loss: 0.1485
                    Surrogate loss: -0.0072
             Mean action noise std: 1.01
                 Mean total reward: 189.19
               Mean episode length: 698.84
 Mean episode rew_tracking_lin_vel: 0.3610
 Mean episode rew_tracking_ang_vel: 0.1484
        Mean episode rew_lin_vel_z: -0.0163
      Mean episode rew_base_height: -0.9255
      Mean episode rew_action_rate: -0.1459
Mean episode rew_similar_to_default: -0.4883
Mean episode rew_joint_pose_matching: 0.0062
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6482
--------------------------------------------------------------------------------
                   Total timesteps: 145920
                    Iteration time: 0.16s
                        Total time: 15.18s
                               ETA: 64.9s

################################################################################
                      [1m Learning iteration 95/500 [0m

                       Computation: 9943 steps/s (collection: 0.127s, learning 0.027s)
               Value function loss: 0.1101
                    Surrogate loss: 0.0001
             Mean action noise std: 1.01
                 Mean total reward: 192.26
               Mean episode length: 711.99
 Mean episode rew_tracking_lin_vel: 0.3626
 Mean episode rew_tracking_ang_vel: 0.1514
        Mean episode rew_lin_vel_z: -0.0148
      Mean episode rew_base_height: -0.9664
      Mean episode rew_action_rate: -0.1474
Mean episode rew_similar_to_default: -0.4901
Mean episode rew_joint_pose_matching: 0.0044
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7717
--------------------------------------------------------------------------------
                   Total timesteps: 147456
                    Iteration time: 0.15s
                        Total time: 15.33s
                               ETA: 64.7s

################################################################################
                      [1m Learning iteration 96/500 [0m

                       Computation: 9951 steps/s (collection: 0.127s, learning 0.027s)
               Value function loss: 0.1241
                    Surrogate loss: 0.0118
             Mean action noise std: 1.01
                 Mean total reward: 194.44
               Mean episode length: 720.55
 Mean episode rew_tracking_lin_vel: 0.3629
 Mean episode rew_tracking_ang_vel: 0.1537
        Mean episode rew_lin_vel_z: -0.0155
      Mean episode rew_base_height: -0.9915
      Mean episode rew_action_rate: -0.1439
Mean episode rew_similar_to_default: -0.5008
Mean episode rew_joint_pose_matching: 0.0043
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7962
--------------------------------------------------------------------------------
                   Total timesteps: 148992
                    Iteration time: 0.15s
                        Total time: 15.49s
                               ETA: 64.5s

################################################################################
                      [1m Learning iteration 97/500 [0m

                       Computation: 9016 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 0.1371
                    Surrogate loss: -0.0012
             Mean action noise std: 1.01
                 Mean total reward: 204.63
               Mean episode length: 763.07
 Mean episode rew_tracking_lin_vel: 0.3602
 Mean episode rew_tracking_ang_vel: 0.1523
        Mean episode rew_lin_vel_z: -0.0158
      Mean episode rew_base_height: -1.0039
      Mean episode rew_action_rate: -0.1447
Mean episode rew_similar_to_default: -0.5062
Mean episode rew_joint_pose_matching: 0.0067
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4251
--------------------------------------------------------------------------------
                   Total timesteps: 150528
                    Iteration time: 0.17s
                        Total time: 15.66s
                               ETA: 64.4s

################################################################################
                      [1m Learning iteration 98/500 [0m

                       Computation: 9396 steps/s (collection: 0.133s, learning 0.031s)
               Value function loss: 0.0946
                    Surrogate loss: 0.0023
             Mean action noise std: 1.01
                 Mean total reward: 204.63
               Mean episode length: 763.07
 Mean episode rew_tracking_lin_vel: 0.3636
 Mean episode rew_tracking_ang_vel: 0.1542
        Mean episode rew_lin_vel_z: -0.0163
      Mean episode rew_base_height: -1.0320
      Mean episode rew_action_rate: -0.1491
Mean episode rew_similar_to_default: -0.5121
Mean episode rew_joint_pose_matching: 0.0090
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6818
--------------------------------------------------------------------------------
                   Total timesteps: 152064
                    Iteration time: 0.16s
                        Total time: 15.82s
                               ETA: 64.2s

################################################################################
                      [1m Learning iteration 99/500 [0m

                       Computation: 9229 steps/s (collection: 0.135s, learning 0.031s)
               Value function loss: 0.0836
                    Surrogate loss: -0.0039
             Mean action noise std: 1.01
                 Mean total reward: 207.00
               Mean episode length: 772.70
 Mean episode rew_tracking_lin_vel: 0.3623
 Mean episode rew_tracking_ang_vel: 0.1501
        Mean episode rew_lin_vel_z: -0.0153
      Mean episode rew_base_height: -1.0564
      Mean episode rew_action_rate: -0.1462
Mean episode rew_similar_to_default: -0.5167
Mean episode rew_joint_pose_matching: 0.0050
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6271
--------------------------------------------------------------------------------
                   Total timesteps: 153600
                    Iteration time: 0.17s
                        Total time: 15.99s
                               ETA: 64.1s

################################################################################
                      [1m Learning iteration 100/500 [0m

                       Computation: 9280 steps/s (collection: 0.134s, learning 0.031s)
               Value function loss: 0.0936
                    Surrogate loss: 0.0025
             Mean action noise std: 1.01
                 Mean total reward: 206.86
               Mean episode length: 773.64
 Mean episode rew_tracking_lin_vel: 0.3608
 Mean episode rew_tracking_ang_vel: 0.1497
        Mean episode rew_lin_vel_z: -0.0153
      Mean episode rew_base_height: -1.0960
      Mean episode rew_action_rate: -0.1437
Mean episode rew_similar_to_default: -0.5268
Mean episode rew_joint_pose_matching: 0.0029
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5444
--------------------------------------------------------------------------------
                   Total timesteps: 155136
                    Iteration time: 0.17s
                        Total time: 16.15s
                               ETA: 64.0s

################################################################################
                      [1m Learning iteration 101/500 [0m

                       Computation: 9096 steps/s (collection: 0.138s, learning 0.030s)
               Value function loss: 0.0970
                    Surrogate loss: -0.0064
             Mean action noise std: 1.01
                 Mean total reward: 207.00
               Mean episode length: 776.90
 Mean episode rew_tracking_lin_vel: 0.3595
 Mean episode rew_tracking_ang_vel: 0.1529
        Mean episode rew_lin_vel_z: -0.0163
      Mean episode rew_base_height: -1.1436
      Mean episode rew_action_rate: -0.1422
Mean episode rew_similar_to_default: -0.5393
Mean episode rew_joint_pose_matching: 0.0027
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4629
--------------------------------------------------------------------------------
                   Total timesteps: 156672
                    Iteration time: 0.17s
                        Total time: 16.32s
                               ETA: 63.8s

################################################################################
                      [1m Learning iteration 102/500 [0m

                       Computation: 9290 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.0877
                    Surrogate loss: 0.0012
             Mean action noise std: 1.01
                 Mean total reward: 207.00
               Mean episode length: 776.90
 Mean episode rew_tracking_lin_vel: 0.3623
 Mean episode rew_tracking_ang_vel: 0.1599
        Mean episode rew_lin_vel_z: -0.0161
      Mean episode rew_base_height: -1.1791
      Mean episode rew_action_rate: -0.1448
Mean episode rew_similar_to_default: -0.5285
Mean episode rew_joint_pose_matching: 0.0020
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4085
--------------------------------------------------------------------------------
                   Total timesteps: 158208
                    Iteration time: 0.17s
                        Total time: 16.49s
                               ETA: 63.7s

################################################################################
                      [1m Learning iteration 103/500 [0m

                       Computation: 9107 steps/s (collection: 0.139s, learning 0.030s)
               Value function loss: 0.1529
                    Surrogate loss: 0.0082
             Mean action noise std: 1.01
                 Mean total reward: 206.52
               Mean episode length: 780.73
 Mean episode rew_tracking_lin_vel: 0.3639
 Mean episode rew_tracking_ang_vel: 0.1533
        Mean episode rew_lin_vel_z: -0.0164
      Mean episode rew_base_height: -1.2038
      Mean episode rew_action_rate: -0.1429
Mean episode rew_similar_to_default: -0.5411
Mean episode rew_joint_pose_matching: 0.0021
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5291
--------------------------------------------------------------------------------
                   Total timesteps: 159744
                    Iteration time: 0.17s
                        Total time: 16.65s
                               ETA: 63.6s

################################################################################
                      [1m Learning iteration 104/500 [0m

                       Computation: 9118 steps/s (collection: 0.137s, learning 0.031s)
               Value function loss: 0.1048
                    Surrogate loss: 0.0024
             Mean action noise std: 1.01
                 Mean total reward: 210.81
               Mean episode length: 800.36
 Mean episode rew_tracking_lin_vel: 0.3608
 Mean episode rew_tracking_ang_vel: 0.1522
        Mean episode rew_lin_vel_z: -0.0158
      Mean episode rew_base_height: -1.2350
      Mean episode rew_action_rate: -0.1437
Mean episode rew_similar_to_default: -0.5478
Mean episode rew_joint_pose_matching: 0.0020
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5389
--------------------------------------------------------------------------------
                   Total timesteps: 161280
                    Iteration time: 0.17s
                        Total time: 16.82s
                               ETA: 63.4s

################################################################################
                      [1m Learning iteration 105/500 [0m

                       Computation: 9227 steps/s (collection: 0.138s, learning 0.029s)
               Value function loss: 0.0699
                    Surrogate loss: 0.0045
             Mean action noise std: 1.01
                 Mean total reward: 210.81
               Mean episode length: 800.36
 Mean episode rew_tracking_lin_vel: 0.3591
 Mean episode rew_tracking_ang_vel: 0.1561
        Mean episode rew_lin_vel_z: -0.0161
      Mean episode rew_base_height: -1.2837
      Mean episode rew_action_rate: -0.1412
Mean episode rew_similar_to_default: -0.5549
Mean episode rew_joint_pose_matching: 0.0015
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4836
--------------------------------------------------------------------------------
                   Total timesteps: 162816
                    Iteration time: 0.17s
                        Total time: 16.99s
                               ETA: 63.3s

################################################################################
                      [1m Learning iteration 106/500 [0m

                       Computation: 8881 steps/s (collection: 0.144s, learning 0.029s)
               Value function loss: 0.0791
                    Surrogate loss: 0.0021
             Mean action noise std: 1.01
                 Mean total reward: 215.75
               Mean episode length: 822.93
 Mean episode rew_tracking_lin_vel: 0.3624
 Mean episode rew_tracking_ang_vel: 0.1575
        Mean episode rew_lin_vel_z: -0.0172
      Mean episode rew_base_height: -1.3243
      Mean episode rew_action_rate: -0.1441
Mean episode rew_similar_to_default: -0.5595
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7222
--------------------------------------------------------------------------------
                   Total timesteps: 164352
                    Iteration time: 0.17s
                        Total time: 17.16s
                               ETA: 63.2s

################################################################################
                      [1m Learning iteration 107/500 [0m

                       Computation: 9238 steps/s (collection: 0.135s, learning 0.031s)
               Value function loss: 0.1173
                    Surrogate loss: 0.0069
             Mean action noise std: 1.01
                 Mean total reward: 215.75
               Mean episode length: 822.93
 Mean episode rew_tracking_lin_vel: 0.3631
 Mean episode rew_tracking_ang_vel: 0.1538
        Mean episode rew_lin_vel_z: -0.0185
      Mean episode rew_base_height: -1.3270
      Mean episode rew_action_rate: -0.1416
Mean episode rew_similar_to_default: -0.5610
Mean episode rew_joint_pose_matching: 0.0017
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6466
--------------------------------------------------------------------------------
                   Total timesteps: 165888
                    Iteration time: 0.17s
                        Total time: 17.33s
                               ETA: 63.1s

################################################################################
                      [1m Learning iteration 108/500 [0m

                       Computation: 8523 steps/s (collection: 0.149s, learning 0.031s)
               Value function loss: 0.0797
                    Surrogate loss: -0.0005
             Mean action noise std: 1.01
                 Mean total reward: 214.27
               Mean episode length: 823.87
 Mean episode rew_tracking_lin_vel: 0.3618
 Mean episode rew_tracking_ang_vel: 0.1580
        Mean episode rew_lin_vel_z: -0.0163
      Mean episode rew_base_height: -1.3891
      Mean episode rew_action_rate: -0.1445
Mean episode rew_similar_to_default: -0.5732
Mean episode rew_joint_pose_matching: 0.0023
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4849
--------------------------------------------------------------------------------
                   Total timesteps: 167424
                    Iteration time: 0.18s
                        Total time: 17.51s
                               ETA: 63.0s

################################################################################
                      [1m Learning iteration 109/500 [0m

                       Computation: 8674 steps/s (collection: 0.146s, learning 0.031s)
               Value function loss: 0.1004
                    Surrogate loss: 0.0000
             Mean action noise std: 1.01
                 Mean total reward: 215.89
               Mean episode length: 832.65
 Mean episode rew_tracking_lin_vel: 0.3636
 Mean episode rew_tracking_ang_vel: 0.1570
        Mean episode rew_lin_vel_z: -0.0146
      Mean episode rew_base_height: -1.3722
      Mean episode rew_action_rate: -0.1466
Mean episode rew_similar_to_default: -0.5660
Mean episode rew_joint_pose_matching: 0.0021
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5268
--------------------------------------------------------------------------------
                   Total timesteps: 168960
                    Iteration time: 0.18s
                        Total time: 17.69s
                               ETA: 62.9s

################################################################################
                      [1m Learning iteration 110/500 [0m

                       Computation: 9318 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.0785
                    Surrogate loss: 0.0065
             Mean action noise std: 1.01
                 Mean total reward: 215.48
               Mean episode length: 832.65
 Mean episode rew_tracking_lin_vel: 0.3588
 Mean episode rew_tracking_ang_vel: 0.1549
        Mean episode rew_lin_vel_z: -0.0161
      Mean episode rew_base_height: -1.4652
      Mean episode rew_action_rate: -0.1394
Mean episode rew_similar_to_default: -0.5818
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5038
--------------------------------------------------------------------------------
                   Total timesteps: 170496
                    Iteration time: 0.16s
                        Total time: 17.85s
                               ETA: 62.7s

################################################################################
                      [1m Learning iteration 111/500 [0m

                       Computation: 8007 steps/s (collection: 0.156s, learning 0.036s)
               Value function loss: 0.0677
                    Surrogate loss: 0.0138
             Mean action noise std: 1.01
                 Mean total reward: 219.33
               Mean episode length: 852.44
 Mean episode rew_tracking_lin_vel: 0.3610
 Mean episode rew_tracking_ang_vel: 0.1606
        Mean episode rew_lin_vel_z: -0.0167
      Mean episode rew_base_height: -1.4675
      Mean episode rew_action_rate: -0.1409
Mean episode rew_similar_to_default: -0.5848
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5495
--------------------------------------------------------------------------------
                   Total timesteps: 172032
                    Iteration time: 0.19s
                        Total time: 18.04s
                               ETA: 62.7s

################################################################################
                      [1m Learning iteration 112/500 [0m

                       Computation: 7701 steps/s (collection: 0.165s, learning 0.034s)
               Value function loss: 0.0907
                    Surrogate loss: 0.0062
             Mean action noise std: 1.01
                 Mean total reward: 218.92
               Mean episode length: 852.44
 Mean episode rew_tracking_lin_vel: 0.3601
 Mean episode rew_tracking_ang_vel: 0.1541
        Mean episode rew_lin_vel_z: -0.0185
      Mean episode rew_base_height: -1.5209
      Mean episode rew_action_rate: -0.1430
Mean episode rew_similar_to_default: -0.5945
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4529
--------------------------------------------------------------------------------
                   Total timesteps: 173568
                    Iteration time: 0.20s
                        Total time: 18.24s
                               ETA: 62.6s

################################################################################
                      [1m Learning iteration 113/500 [0m

                       Computation: 8213 steps/s (collection: 0.149s, learning 0.038s)
               Value function loss: 0.0950
                    Surrogate loss: 0.0089
             Mean action noise std: 1.01
                 Mean total reward: 218.10
               Mean episode length: 852.44
 Mean episode rew_tracking_lin_vel: 0.3618
 Mean episode rew_tracking_ang_vel: 0.1570
        Mean episode rew_lin_vel_z: -0.0159
      Mean episode rew_base_height: -1.5043
      Mean episode rew_action_rate: -0.1437
Mean episode rew_similar_to_default: -0.5932
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5721
--------------------------------------------------------------------------------
                   Total timesteps: 175104
                    Iteration time: 0.19s
                        Total time: 18.43s
                               ETA: 62.6s

################################################################################
                      [1m Learning iteration 114/500 [0m

                       Computation: 8297 steps/s (collection: 0.155s, learning 0.030s)
               Value function loss: 0.1018
                    Surrogate loss: 0.0009
             Mean action noise std: 1.01
                 Mean total reward: 219.73
               Mean episode length: 861.56
 Mean episode rew_tracking_lin_vel: 0.3612
 Mean episode rew_tracking_ang_vel: 0.1587
        Mean episode rew_lin_vel_z: -0.0158
      Mean episode rew_base_height: -1.5065
      Mean episode rew_action_rate: -0.1427
Mean episode rew_similar_to_default: -0.5927
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4557
--------------------------------------------------------------------------------
                   Total timesteps: 176640
                    Iteration time: 0.19s
                        Total time: 18.61s
                               ETA: 62.5s

################################################################################
                      [1m Learning iteration 115/500 [0m

                       Computation: 9262 steps/s (collection: 0.137s, learning 0.029s)
               Value function loss: 0.0682
                    Surrogate loss: 0.0006
             Mean action noise std: 1.01
                 Mean total reward: 219.73
               Mean episode length: 861.56
 Mean episode rew_tracking_lin_vel: 0.3615
 Mean episode rew_tracking_ang_vel: 0.1583
        Mean episode rew_lin_vel_z: -0.0148
      Mean episode rew_base_height: -1.5289
      Mean episode rew_action_rate: -0.1385
Mean episode rew_similar_to_default: -0.5936
Mean episode rew_joint_pose_matching: 0.0015
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.3872
--------------------------------------------------------------------------------
                   Total timesteps: 178176
                    Iteration time: 0.17s
                        Total time: 18.78s
                               ETA: 62.3s

################################################################################
                      [1m Learning iteration 116/500 [0m

                       Computation: 9170 steps/s (collection: 0.139s, learning 0.029s)
               Value function loss: 0.0823
                    Surrogate loss: 0.0056
             Mean action noise std: 1.01
                 Mean total reward: 219.22
               Mean episode length: 861.56
 Mean episode rew_tracking_lin_vel: 0.3624
 Mean episode rew_tracking_ang_vel: 0.1607
        Mean episode rew_lin_vel_z: -0.0163
      Mean episode rew_base_height: -1.5774
      Mean episode rew_action_rate: -0.1409
Mean episode rew_similar_to_default: -0.6032
Mean episode rew_joint_pose_matching: 0.0015
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4198
--------------------------------------------------------------------------------
                   Total timesteps: 179712
                    Iteration time: 0.17s
                        Total time: 18.95s
                               ETA: 62.2s

################################################################################
                      [1m Learning iteration 117/500 [0m

                       Computation: 9285 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 0.0579
                    Surrogate loss: -0.0045
             Mean action noise std: 1.01
                 Mean total reward: 219.22
               Mean episode length: 861.56
 Mean episode rew_tracking_lin_vel: 0.3633
 Mean episode rew_tracking_ang_vel: 0.1627
        Mean episode rew_lin_vel_z: -0.0175
      Mean episode rew_base_height: -1.6185
      Mean episode rew_action_rate: -0.1430
Mean episode rew_similar_to_default: -0.6114
Mean episode rew_joint_pose_matching: 0.0015
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4473
--------------------------------------------------------------------------------
                   Total timesteps: 181248
                    Iteration time: 0.17s
                        Total time: 19.11s
                               ETA: 62.0s

################################################################################
                      [1m Learning iteration 118/500 [0m

                       Computation: 9376 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 0.0683
                    Surrogate loss: 0.0042
             Mean action noise std: 1.01
                 Mean total reward: 218.82
               Mean episode length: 861.56
 Mean episode rew_tracking_lin_vel: 0.3619
 Mean episode rew_tracking_ang_vel: 0.1636
        Mean episode rew_lin_vel_z: -0.0174
      Mean episode rew_base_height: -1.6445
      Mean episode rew_action_rate: -0.1411
Mean episode rew_similar_to_default: -0.6163
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5388
--------------------------------------------------------------------------------
                   Total timesteps: 182784
                    Iteration time: 0.16s
                        Total time: 19.28s
                               ETA: 61.9s

################################################################################
                      [1m Learning iteration 119/500 [0m

                       Computation: 9213 steps/s (collection: 0.136s, learning 0.031s)
               Value function loss: 1.3790
                    Surrogate loss: -0.0025
             Mean action noise std: 1.01
                 Mean total reward: 216.64
               Mean episode length: 853.67
 Mean episode rew_tracking_lin_vel: 0.0773
 Mean episode rew_tracking_ang_vel: 0.0354
        Mean episode rew_lin_vel_z: -0.0112
      Mean episode rew_base_height: -0.3536
      Mean episode rew_action_rate: -0.0305
Mean episode rew_similar_to_default: -0.1331
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.0316
--------------------------------------------------------------------------------
                   Total timesteps: 184320
                    Iteration time: 0.17s
                        Total time: 19.44s
                               ETA: 61.7s

################################################################################
                      [1m Learning iteration 120/500 [0m

                       Computation: 9265 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 0.0792
                    Surrogate loss: -0.0056
             Mean action noise std: 1.01
                 Mean total reward: 216.15
               Mean episode length: 853.67
 Mean episode rew_tracking_lin_vel: 0.1373
 Mean episode rew_tracking_ang_vel: 0.0627
        Mean episode rew_lin_vel_z: -0.0141
      Mean episode rew_base_height: -0.6538
      Mean episode rew_action_rate: -0.0540
Mean episode rew_similar_to_default: -0.2383
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.1871
--------------------------------------------------------------------------------
                   Total timesteps: 185856
                    Iteration time: 0.17s
                        Total time: 19.61s
                               ETA: 61.6s

################################################################################
                      [1m Learning iteration 121/500 [0m

                       Computation: 9323 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.0712
                    Surrogate loss: -0.0162
             Mean action noise std: 1.01
                 Mean total reward: 218.23
               Mean episode length: 863.02
 Mean episode rew_tracking_lin_vel: 0.3616
 Mean episode rew_tracking_ang_vel: 0.1626
        Mean episode rew_lin_vel_z: -0.0189
      Mean episode rew_base_height: -1.6739
      Mean episode rew_action_rate: -0.1415
Mean episode rew_similar_to_default: -0.6217
Mean episode rew_joint_pose_matching: 0.0015
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.2352
--------------------------------------------------------------------------------
                   Total timesteps: 187392
                    Iteration time: 0.16s
                        Total time: 19.77s
                               ETA: 61.4s

################################################################################
                      [1m Learning iteration 122/500 [0m

                       Computation: 9229 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 0.0570
                    Surrogate loss: -0.0141
             Mean action noise std: 1.01
                 Mean total reward: 219.16
               Mean episode length: 868.20
 Mean episode rew_tracking_lin_vel: 0.3590
 Mean episode rew_tracking_ang_vel: 0.1649
        Mean episode rew_lin_vel_z: -0.0199
      Mean episode rew_base_height: -1.7518
      Mean episode rew_action_rate: -0.1427
Mean episode rew_similar_to_default: -0.6297
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.2378
--------------------------------------------------------------------------------
                   Total timesteps: 188928
                    Iteration time: 0.17s
                        Total time: 19.94s
                               ETA: 61.3s

################################################################################
                      [1m Learning iteration 123/500 [0m

                       Computation: 9296 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.0685
                    Surrogate loss: 0.0017
             Mean action noise std: 1.01
                 Mean total reward: 218.63
               Mean episode length: 868.20
 Mean episode rew_tracking_lin_vel: 0.3593
 Mean episode rew_tracking_ang_vel: 0.1640
        Mean episode rew_lin_vel_z: -0.0192
      Mean episode rew_base_height: -1.7548
      Mean episode rew_action_rate: -0.1426
Mean episode rew_similar_to_default: -0.6297
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.2224
--------------------------------------------------------------------------------
                   Total timesteps: 190464
                    Iteration time: 0.17s
                        Total time: 20.11s
                               ETA: 61.1s

################################################################################
                      [1m Learning iteration 124/500 [0m

                       Computation: 9451 steps/s (collection: 0.133s, learning 0.030s)
               Value function loss: 0.0488
                    Surrogate loss: -0.0060
             Mean action noise std: 1.01
                 Mean total reward: 218.63
               Mean episode length: 868.20
 Mean episode rew_tracking_lin_vel: 0.3605
 Mean episode rew_tracking_ang_vel: 0.1609
        Mean episode rew_lin_vel_z: -0.0163
      Mean episode rew_base_height: -1.7665
      Mean episode rew_action_rate: -0.1420
Mean episode rew_similar_to_default: -0.6295
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.1639
--------------------------------------------------------------------------------
                   Total timesteps: 192000
                    Iteration time: 0.16s
                        Total time: 20.27s
                               ETA: 61.0s

################################################################################
                      [1m Learning iteration 125/500 [0m

                       Computation: 9216 steps/s (collection: 0.135s, learning 0.032s)
               Value function loss: 0.0516
                    Surrogate loss: -0.0047
             Mean action noise std: 1.01
                 Mean total reward: 217.58
               Mean episode length: 868.20
 Mean episode rew_tracking_lin_vel: 0.3597
 Mean episode rew_tracking_ang_vel: 0.1634
        Mean episode rew_lin_vel_z: -0.0163
      Mean episode rew_base_height: -1.8080
      Mean episode rew_action_rate: -0.1409
Mean episode rew_similar_to_default: -0.6374
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.3104
--------------------------------------------------------------------------------
                   Total timesteps: 193536
                    Iteration time: 0.17s
                        Total time: 20.43s
                               ETA: 60.8s

################################################################################
                      [1m Learning iteration 126/500 [0m

                       Computation: 9020 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 0.0526
                    Surrogate loss: -0.0117
             Mean action noise std: 1.01
                 Mean total reward: 220.95
               Mean episode length: 885.58
 Mean episode rew_tracking_lin_vel: 0.3628
 Mean episode rew_tracking_ang_vel: 0.1636
        Mean episode rew_lin_vel_z: -0.0193
      Mean episode rew_base_height: -1.7925
      Mean episode rew_action_rate: -0.1383
Mean episode rew_similar_to_default: -0.6400
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4923
--------------------------------------------------------------------------------
                   Total timesteps: 195072
                    Iteration time: 0.17s
                        Total time: 20.60s
                               ETA: 60.7s

################################################################################
                      [1m Learning iteration 127/500 [0m

                       Computation: 9059 steps/s (collection: 0.141s, learning 0.029s)
               Value function loss: 0.0631
                    Surrogate loss: -0.0122
             Mean action noise std: 1.01
                 Mean total reward: 221.25
               Mean episode length: 889.86
 Mean episode rew_tracking_lin_vel: 0.3616
 Mean episode rew_tracking_ang_vel: 0.1676
        Mean episode rew_lin_vel_z: -0.0186
      Mean episode rew_base_height: -1.8318
      Mean episode rew_action_rate: -0.1429
Mean episode rew_similar_to_default: -0.6445
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5801
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 0.17s
                        Total time: 20.77s
                               ETA: 60.5s

################################################################################
                      [1m Learning iteration 128/500 [0m

                       Computation: 9397 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 0.0559
                    Surrogate loss: -0.0125
             Mean action noise std: 1.01
                 Mean total reward: 220.80
               Mean episode length: 889.86
 Mean episode rew_tracking_lin_vel: 0.3626
 Mean episode rew_tracking_ang_vel: 0.1652
        Mean episode rew_lin_vel_z: -0.0188
      Mean episode rew_base_height: -1.8238
      Mean episode rew_action_rate: -0.1415
Mean episode rew_similar_to_default: -0.6430
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6266
--------------------------------------------------------------------------------
                   Total timesteps: 198144
                    Iteration time: 0.16s
                        Total time: 20.94s
                               ETA: 60.4s

################################################################################
                      [1m Learning iteration 129/500 [0m

                       Computation: 8836 steps/s (collection: 0.137s, learning 0.037s)
               Value function loss: 0.0451
                    Surrogate loss: -0.0083
             Mean action noise std: 1.01
                 Mean total reward: 220.80
               Mean episode length: 889.86
 Mean episode rew_tracking_lin_vel: 0.3625
 Mean episode rew_tracking_ang_vel: 0.1653
        Mean episode rew_lin_vel_z: -0.0201
      Mean episode rew_base_height: -1.8246
      Mean episode rew_action_rate: -0.1402
Mean episode rew_similar_to_default: -0.6442
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6510
--------------------------------------------------------------------------------
                   Total timesteps: 199680
                    Iteration time: 0.17s
                        Total time: 21.11s
                               ETA: 60.2s

################################################################################
                      [1m Learning iteration 130/500 [0m

                       Computation: 9404 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 0.0353
                    Surrogate loss: -0.0102
             Mean action noise std: 1.01
                 Mean total reward: 220.80
               Mean episode length: 889.86
 Mean episode rew_tracking_lin_vel: 0.3625
 Mean episode rew_tracking_ang_vel: 0.1653
        Mean episode rew_lin_vel_z: -0.0201
      Mean episode rew_base_height: -1.8246
      Mean episode rew_action_rate: -0.1402
Mean episode rew_similar_to_default: -0.6442
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6510
--------------------------------------------------------------------------------
                   Total timesteps: 201216
                    Iteration time: 0.16s
                        Total time: 21.28s
                               ETA: 60.1s

################################################################################
                      [1m Learning iteration 131/500 [0m

                       Computation: 9435 steps/s (collection: 0.133s, learning 0.030s)
               Value function loss: 0.0499
                    Surrogate loss: -0.0089
             Mean action noise std: 1.01
                 Mean total reward: 220.27
               Mean episode length: 889.86
 Mean episode rew_tracking_lin_vel: 0.3601
 Mean episode rew_tracking_ang_vel: 0.1674
        Mean episode rew_lin_vel_z: -0.0183
      Mean episode rew_base_height: -1.8823
      Mean episode rew_action_rate: -0.1410
Mean episode rew_similar_to_default: -0.6509
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5131
--------------------------------------------------------------------------------
                   Total timesteps: 202752
                    Iteration time: 0.16s
                        Total time: 21.44s
                               ETA: 59.9s

################################################################################
                      [1m Learning iteration 132/500 [0m

                       Computation: 9489 steps/s (collection: 0.132s, learning 0.030s)
               Value function loss: 0.0395
                    Surrogate loss: -0.0097
             Mean action noise std: 1.01
                 Mean total reward: 220.27
               Mean episode length: 889.86
 Mean episode rew_tracking_lin_vel: 0.3584
 Mean episode rew_tracking_ang_vel: 0.1690
        Mean episode rew_lin_vel_z: -0.0171
      Mean episode rew_base_height: -1.9234
      Mean episode rew_action_rate: -0.1416
Mean episode rew_similar_to_default: -0.6556
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4146
--------------------------------------------------------------------------------
                   Total timesteps: 204288
                    Iteration time: 0.16s
                        Total time: 21.60s
                               ETA: 59.8s

################################################################################
                      [1m Learning iteration 133/500 [0m

                       Computation: 9496 steps/s (collection: 0.133s, learning 0.029s)
               Value function loss: 0.0491
                    Surrogate loss: -0.0051
             Mean action noise std: 1.01
                 Mean total reward: 224.56
               Mean episode length: 908.63
 Mean episode rew_tracking_lin_vel: 0.3619
 Mean episode rew_tracking_ang_vel: 0.1663
        Mean episode rew_lin_vel_z: -0.0189
      Mean episode rew_base_height: -1.9256
      Mean episode rew_action_rate: -0.1410
Mean episode rew_similar_to_default: -0.6584
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6829
--------------------------------------------------------------------------------
                   Total timesteps: 205824
                    Iteration time: 0.16s
                        Total time: 21.76s
                               ETA: 59.6s

################################################################################
                      [1m Learning iteration 134/500 [0m

                       Computation: 9173 steps/s (collection: 0.139s, learning 0.029s)
               Value function loss: 0.0353
                    Surrogate loss: -0.0123
             Mean action noise std: 1.01
                 Mean total reward: 224.56
               Mean episode length: 908.63
 Mean episode rew_tracking_lin_vel: 0.3626
 Mean episode rew_tracking_ang_vel: 0.1663
        Mean episode rew_lin_vel_z: -0.0201
      Mean episode rew_base_height: -1.9283
      Mean episode rew_action_rate: -0.1425
Mean episode rew_similar_to_default: -0.6603
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7363
--------------------------------------------------------------------------------
                   Total timesteps: 207360
                    Iteration time: 0.17s
                        Total time: 21.93s
                               ETA: 59.5s

################################################################################
                      [1m Learning iteration 135/500 [0m

                       Computation: 8806 steps/s (collection: 0.144s, learning 0.030s)
               Value function loss: 0.0406
                    Surrogate loss: -0.0110
             Mean action noise std: 1.01
                 Mean total reward: 226.43
               Mean episode length: 918.47
 Mean episode rew_tracking_lin_vel: 0.3630
 Mean episode rew_tracking_ang_vel: 0.1694
        Mean episode rew_lin_vel_z: -0.0208
      Mean episode rew_base_height: -1.9613
      Mean episode rew_action_rate: -0.1407
Mean episode rew_similar_to_default: -0.6641
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.8287
--------------------------------------------------------------------------------
                   Total timesteps: 208896
                    Iteration time: 0.17s
                        Total time: 22.10s
                               ETA: 59.3s

################################################################################
                      [1m Learning iteration 136/500 [0m

                       Computation: 9131 steps/s (collection: 0.141s, learning 0.028s)
               Value function loss: 0.0732
                    Surrogate loss: -0.0119
             Mean action noise std: 1.01
                 Mean total reward: 231.80
               Mean episode length: 947.45
 Mean episode rew_tracking_lin_vel: 0.3622
 Mean episode rew_tracking_ang_vel: 0.1683
        Mean episode rew_lin_vel_z: -0.0184
      Mean episode rew_base_height: -2.0058
      Mean episode rew_action_rate: -0.1415
Mean episode rew_similar_to_default: -0.6670
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.7334
--------------------------------------------------------------------------------
                   Total timesteps: 210432
                    Iteration time: 0.17s
                        Total time: 22.27s
                               ETA: 59.2s

################################################################################
                      [1m Learning iteration 137/500 [0m

                       Computation: 9511 steps/s (collection: 0.134s, learning 0.028s)
               Value function loss: 0.0513
                    Surrogate loss: -0.0097
             Mean action noise std: 1.01
                 Mean total reward: 234.56
               Mean episode length: 960.45
 Mean episode rew_tracking_lin_vel: 0.3613
 Mean episode rew_tracking_ang_vel: 0.1671
        Mean episode rew_lin_vel_z: -0.0161
      Mean episode rew_base_height: -1.9983
      Mean episode rew_action_rate: -0.1413
Mean episode rew_similar_to_default: -0.6665
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.8608
--------------------------------------------------------------------------------
                   Total timesteps: 211968
                    Iteration time: 0.16s
                        Total time: 22.43s
                               ETA: 59.0s

################################################################################
                      [1m Learning iteration 138/500 [0m

                       Computation: 9574 steps/s (collection: 0.133s, learning 0.028s)
               Value function loss: 0.0522
                    Surrogate loss: -0.0105
             Mean action noise std: 1.01
                 Mean total reward: 233.29
               Mean episode length: 960.45
 Mean episode rew_tracking_lin_vel: 0.3616
 Mean episode rew_tracking_ang_vel: 0.1668
        Mean episode rew_lin_vel_z: -0.0174
      Mean episode rew_base_height: -1.9935
      Mean episode rew_action_rate: -0.1404
Mean episode rew_similar_to_default: -0.6679
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.8976
--------------------------------------------------------------------------------
                   Total timesteps: 213504
                    Iteration time: 0.16s
                        Total time: 22.59s
                               ETA: 58.8s

################################################################################
                      [1m Learning iteration 139/500 [0m

                       Computation: 9487 steps/s (collection: 0.134s, learning 0.028s)
               Value function loss: 0.0522
                    Surrogate loss: -0.0072
             Mean action noise std: 1.01
                 Mean total reward: 236.51
               Mean episode length: 976.40
 Mean episode rew_tracking_lin_vel: 0.3629
 Mean episode rew_tracking_ang_vel: 0.1712
        Mean episode rew_lin_vel_z: -0.0185
      Mean episode rew_base_height: -2.0133
      Mean episode rew_action_rate: -0.1393
Mean episode rew_similar_to_default: -0.6684
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.0477
--------------------------------------------------------------------------------
                   Total timesteps: 215040
                    Iteration time: 0.16s
                        Total time: 22.76s
                               ETA: 58.7s

################################################################################
                      [1m Learning iteration 140/500 [0m

                       Computation: 9822 steps/s (collection: 0.129s, learning 0.028s)
               Value function loss: 0.0331
                    Surrogate loss: -0.0050
             Mean action noise std: 1.01
                 Mean total reward: 236.51
               Mean episode length: 976.40
 Mean episode rew_tracking_lin_vel: 0.3628
 Mean episode rew_tracking_ang_vel: 0.1720
        Mean episode rew_lin_vel_z: -0.0174
      Mean episode rew_base_height: -1.9928
      Mean episode rew_action_rate: -0.1408
Mean episode rew_similar_to_default: -0.6661
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.1585
--------------------------------------------------------------------------------
                   Total timesteps: 216576
                    Iteration time: 0.16s
                        Total time: 22.91s
                               ETA: 58.5s

################################################################################
                      [1m Learning iteration 141/500 [0m

                       Computation: 9738 steps/s (collection: 0.130s, learning 0.027s)
               Value function loss: 0.7950
                    Surrogate loss: 0.0016
             Mean action noise std: 1.01
                 Mean total reward: 233.77
               Mean episode length: 967.54
 Mean episode rew_tracking_lin_vel: 0.2073
 Mean episode rew_tracking_ang_vel: 0.0982
        Mean episode rew_lin_vel_z: -0.0167
      Mean episode rew_base_height: -1.1761
      Mean episode rew_action_rate: -0.0785
Mean episode rew_similar_to_default: -0.3860
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.0557
--------------------------------------------------------------------------------
                   Total timesteps: 218112
                    Iteration time: 0.16s
                        Total time: 23.07s
                               ETA: 58.3s

################################################################################
                      [1m Learning iteration 142/500 [0m

                       Computation: 9413 steps/s (collection: 0.133s, learning 0.030s)
               Value function loss: 3.0676
                    Surrogate loss: -0.0040
             Mean action noise std: 1.01
                 Mean total reward: 231.64
               Mean episode length: 961.25
 Mean episode rew_tracking_lin_vel: 0.2221
 Mean episode rew_tracking_ang_vel: 0.1067
        Mean episode rew_lin_vel_z: -0.0185
      Mean episode rew_base_height: -1.2854
      Mean episode rew_action_rate: -0.0835
Mean episode rew_similar_to_default: -0.4181
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.7961
--------------------------------------------------------------------------------
                   Total timesteps: 219648
                    Iteration time: 0.16s
                        Total time: 23.23s
                               ETA: 58.2s

################################################################################
                      [1m Learning iteration 143/500 [0m

                       Computation: 9345 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 2.4161
                    Surrogate loss: -0.0037
             Mean action noise std: 1.01
                 Mean total reward: 229.75
               Mean episode length: 956.42
 Mean episode rew_tracking_lin_vel: 0.1817
 Mean episode rew_tracking_ang_vel: 0.0869
        Mean episode rew_lin_vel_z: -0.0192
      Mean episode rew_base_height: -1.0551
      Mean episode rew_action_rate: -0.0692
Mean episode rew_similar_to_default: -0.3414
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.1430
--------------------------------------------------------------------------------
                   Total timesteps: 221184
                    Iteration time: 0.16s
                        Total time: 23.40s
                               ETA: 58.0s

################################################################################
                      [1m Learning iteration 144/500 [0m

                       Computation: 9378 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 3.3503
                    Surrogate loss: -0.0071
             Mean action noise std: 1.01
                 Mean total reward: 228.82
               Mean episode length: 954.84
 Mean episode rew_tracking_lin_vel: 0.3595
 Mean episode rew_tracking_ang_vel: 0.1702
        Mean episode rew_lin_vel_z: -0.0166
      Mean episode rew_base_height: -2.0675
      Mean episode rew_action_rate: -0.1364
Mean episode rew_similar_to_default: -0.6737
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.9558
--------------------------------------------------------------------------------
                   Total timesteps: 222720
                    Iteration time: 0.16s
                        Total time: 23.56s
                               ETA: 57.8s

################################################################################
                      [1m Learning iteration 145/500 [0m

                       Computation: 9378 steps/s (collection: 0.135s, learning 0.029s)
               Value function loss: 0.0658
                    Surrogate loss: -0.0095
             Mean action noise std: 1.01
                 Mean total reward: 230.16
               Mean episode length: 964.57
 Mean episode rew_tracking_lin_vel: 0.3611
 Mean episode rew_tracking_ang_vel: 0.1691
        Mean episode rew_lin_vel_z: -0.0186
      Mean episode rew_base_height: -2.1016
      Mean episode rew_action_rate: -0.1389
Mean episode rew_similar_to_default: -0.6823
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.0420
--------------------------------------------------------------------------------
                   Total timesteps: 224256
                    Iteration time: 0.16s
                        Total time: 23.72s
                               ETA: 57.7s

################################################################################
                      [1m Learning iteration 146/500 [0m

                       Computation: 9477 steps/s (collection: 0.134s, learning 0.028s)
               Value function loss: 0.0513
                    Surrogate loss: -0.0041
             Mean action noise std: 1.01
                 Mean total reward: 229.60
               Mean episode length: 964.57
 Mean episode rew_tracking_lin_vel: 0.3630
 Mean episode rew_tracking_ang_vel: 0.1734
        Mean episode rew_lin_vel_z: -0.0198
      Mean episode rew_base_height: -2.1146
      Mean episode rew_action_rate: -0.1381
Mean episode rew_similar_to_default: -0.6834
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.2399
--------------------------------------------------------------------------------
                   Total timesteps: 225792
                    Iteration time: 0.16s
                        Total time: 23.89s
                               ETA: 57.5s

################################################################################
                      [1m Learning iteration 147/500 [0m

                       Computation: 9491 steps/s (collection: 0.133s, learning 0.028s)
               Value function loss: 0.0490
                    Surrogate loss: -0.0053
             Mean action noise std: 1.01
                 Mean total reward: 229.18
               Mean episode length: 964.57
 Mean episode rew_tracking_lin_vel: 0.3624
 Mean episode rew_tracking_ang_vel: 0.1715
        Mean episode rew_lin_vel_z: -0.0191
      Mean episode rew_base_height: -2.1074
      Mean episode rew_action_rate: -0.1392
Mean episode rew_similar_to_default: -0.6837
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.2753
--------------------------------------------------------------------------------
                   Total timesteps: 227328
                    Iteration time: 0.16s
                        Total time: 24.05s
                               ETA: 57.4s

################################################################################
                      [1m Learning iteration 148/500 [0m

                       Computation: 9544 steps/s (collection: 0.132s, learning 0.029s)
               Value function loss: 0.0430
                    Surrogate loss: 0.0013
             Mean action noise std: 1.01
                 Mean total reward: 228.71
               Mean episode length: 964.57
 Mean episode rew_tracking_lin_vel: 0.3625
 Mean episode rew_tracking_ang_vel: 0.1717
        Mean episode rew_lin_vel_z: -0.0194
      Mean episode rew_base_height: -2.1183
      Mean episode rew_action_rate: -0.1383
Mean episode rew_similar_to_default: -0.6817
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.3007
--------------------------------------------------------------------------------
                   Total timesteps: 228864
                    Iteration time: 0.16s
                        Total time: 24.21s
                               ETA: 57.2s

################################################################################
                      [1m Learning iteration 149/500 [0m

                       Computation: 9167 steps/s (collection: 0.139s, learning 0.028s)
               Value function loss: 0.4466
                    Surrogate loss: -0.0008
             Mean action noise std: 1.01
                 Mean total reward: 227.49
               Mean episode length: 960.61
 Mean episode rew_tracking_lin_vel: 0.2554
 Mean episode rew_tracking_ang_vel: 0.1218
        Mean episode rew_lin_vel_z: -0.0216
      Mean episode rew_base_height: -1.5300
      Mean episode rew_action_rate: -0.0956
Mean episode rew_similar_to_default: -0.4871
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.1738
--------------------------------------------------------------------------------
                   Total timesteps: 230400
                    Iteration time: 0.17s
                        Total time: 24.38s
                               ETA: 57.0s

################################################################################
                      [1m Learning iteration 150/500 [0m

                       Computation: 9384 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 0.0469
                    Surrogate loss: -0.0082
             Mean action noise std: 1.01
                 Mean total reward: 227.04
               Mean episode length: 960.61
 Mean episode rew_tracking_lin_vel: 0.3659
 Mean episode rew_tracking_ang_vel: 0.1714
        Mean episode rew_lin_vel_z: -0.0181
      Mean episode rew_base_height: -2.1281
      Mean episode rew_action_rate: -0.1386
Mean episode rew_similar_to_default: -0.6849
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.4214
--------------------------------------------------------------------------------
                   Total timesteps: 231936
                    Iteration time: 0.16s
                        Total time: 24.54s
                               ETA: 56.9s

################################################################################
                      [1m Learning iteration 151/500 [0m

                       Computation: 9532 steps/s (collection: 0.133s, learning 0.028s)
               Value function loss: 2.0817
                    Surrogate loss: -0.0031
             Mean action noise std: 1.01
                 Mean total reward: 224.41
               Mean episode length: 950.74
 Mean episode rew_tracking_lin_vel: 0.1701
 Mean episode rew_tracking_ang_vel: 0.0807
        Mean episode rew_lin_vel_z: -0.0143
      Mean episode rew_base_height: -0.9768
      Mean episode rew_action_rate: -0.0644
Mean episode rew_similar_to_default: -0.3178
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.7282
--------------------------------------------------------------------------------
                   Total timesteps: 233472
                    Iteration time: 0.16s
                        Total time: 24.70s
                               ETA: 56.7s

################################################################################
                      [1m Learning iteration 152/500 [0m

                       Computation: 9065 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 0.0382
                    Surrogate loss: -0.0093
             Mean action noise std: 1.01
                 Mean total reward: 224.33
               Mean episode length: 950.74
 Mean episode rew_tracking_lin_vel: 0.3648
 Mean episode rew_tracking_ang_vel: 0.1732
        Mean episode rew_lin_vel_z: -0.0196
      Mean episode rew_base_height: -2.1318
      Mean episode rew_action_rate: -0.1350
Mean episode rew_similar_to_default: -0.6893
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.3545
--------------------------------------------------------------------------------
                   Total timesteps: 235008
                    Iteration time: 0.17s
                        Total time: 24.87s
                               ETA: 56.6s

################################################################################
                      [1m Learning iteration 153/500 [0m

                       Computation: 9561 steps/s (collection: 0.133s, learning 0.028s)
               Value function loss: 0.0572
                    Surrogate loss: -0.0106
             Mean action noise std: 1.01
                 Mean total reward: 224.02
               Mean episode length: 950.74
 Mean episode rew_tracking_lin_vel: 0.3636
 Mean episode rew_tracking_ang_vel: 0.1705
        Mean episode rew_lin_vel_z: -0.0192
      Mean episode rew_base_height: -2.1649
      Mean episode rew_action_rate: -0.1407
Mean episode rew_similar_to_default: -0.6906
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.5622
--------------------------------------------------------------------------------
                   Total timesteps: 236544
                    Iteration time: 0.16s
                        Total time: 25.03s
                               ETA: 56.4s

################################################################################
                      [1m Learning iteration 154/500 [0m

                       Computation: 4750 steps/s (collection: 0.296s, learning 0.027s)
               Value function loss: 0.0552
                    Surrogate loss: -0.0032
             Mean action noise std: 1.01
                 Mean total reward: 223.87
               Mean episode length: 950.74
 Mean episode rew_tracking_lin_vel: 0.3626
 Mean episode rew_tracking_ang_vel: 0.1737
        Mean episode rew_lin_vel_z: -0.0162
      Mean episode rew_base_height: -2.1236
      Mean episode rew_action_rate: -0.1376
Mean episode rew_similar_to_default: -0.6839
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.3891
--------------------------------------------------------------------------------
                   Total timesteps: 238080
                    Iteration time: 0.32s
                        Total time: 25.36s
                               ETA: 56.6s

################################################################################
                      [1m Learning iteration 155/500 [0m

                       Computation: 9775 steps/s (collection: 0.130s, learning 0.028s)
               Value function loss: 0.0443
                    Surrogate loss: -0.0069
             Mean action noise std: 1.01
                 Mean total reward: 223.87
               Mean episode length: 950.74
 Mean episode rew_tracking_lin_vel: 0.3629
 Mean episode rew_tracking_ang_vel: 0.1734
        Mean episode rew_lin_vel_z: -0.0189
      Mean episode rew_base_height: -2.1392
      Mean episode rew_action_rate: -0.1396
Mean episode rew_similar_to_default: -0.6906
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.3636
--------------------------------------------------------------------------------
                   Total timesteps: 239616
                    Iteration time: 0.16s
                        Total time: 25.51s
                               ETA: 56.4s

################################################################################
                      [1m Learning iteration 156/500 [0m

                       Computation: 9043 steps/s (collection: 0.142s, learning 0.028s)
               Value function loss: 0.0593
                    Surrogate loss: -0.0066
             Mean action noise std: 1.01
                 Mean total reward: 223.67
               Mean episode length: 950.74
 Mean episode rew_tracking_lin_vel: 0.3615
 Mean episode rew_tracking_ang_vel: 0.1742
        Mean episode rew_lin_vel_z: -0.0206
      Mean episode rew_base_height: -2.1575
      Mean episode rew_action_rate: -0.1357
Mean episode rew_similar_to_default: -0.6890
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.4082
--------------------------------------------------------------------------------
                   Total timesteps: 241152
                    Iteration time: 0.17s
                        Total time: 25.68s
                               ETA: 56.3s

################################################################################
                      [1m Learning iteration 157/500 [0m

                       Computation: 9799 steps/s (collection: 0.129s, learning 0.028s)
               Value function loss: 0.0355
                    Surrogate loss: -0.0085
             Mean action noise std: 1.01
                 Mean total reward: 223.67
               Mean episode length: 950.74
 Mean episode rew_tracking_lin_vel: 0.3623
 Mean episode rew_tracking_ang_vel: 0.1728
        Mean episode rew_lin_vel_z: -0.0204
      Mean episode rew_base_height: -2.1618
      Mean episode rew_action_rate: -0.1404
Mean episode rew_similar_to_default: -0.6894
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0007
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.3025
--------------------------------------------------------------------------------
                   Total timesteps: 242688
                    Iteration time: 0.16s
                        Total time: 25.84s
                               ETA: 56.1s

################################################################################
                      [1m Learning iteration 158/500 [0m

                       Computation: 9575 steps/s (collection: 0.132s, learning 0.028s)
               Value function loss: 0.4760
                    Surrogate loss: -0.0006
             Mean action noise std: 1.01
                 Mean total reward: 221.68
               Mean episode length: 942.70
 Mean episode rew_tracking_lin_vel: 0.3157
 Mean episode rew_tracking_ang_vel: 0.1519
        Mean episode rew_lin_vel_z: -0.0202
      Mean episode rew_base_height: -1.8775
      Mean episode rew_action_rate: -0.1184
Mean episode rew_similar_to_default: -0.5976
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.8059
--------------------------------------------------------------------------------
                   Total timesteps: 244224
                    Iteration time: 0.16s
                        Total time: 26.00s
                               ETA: 55.9s

################################################################################
                      [1m Learning iteration 159/500 [0m

                       Computation: 9978 steps/s (collection: 0.127s, learning 0.027s)
               Value function loss: 0.0340
                    Surrogate loss: -0.0062
             Mean action noise std: 1.01
                 Mean total reward: 221.68
               Mean episode length: 942.70
 Mean episode rew_tracking_lin_vel: 0.3649
 Mean episode rew_tracking_ang_vel: 0.1755
        Mean episode rew_lin_vel_z: -0.0210
      Mean episode rew_base_height: -2.1716
      Mean episode rew_action_rate: -0.1366
Mean episode rew_similar_to_default: -0.6908
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.8145
--------------------------------------------------------------------------------
                   Total timesteps: 245760
                    Iteration time: 0.15s
                        Total time: 26.15s
                               ETA: 55.7s

################################################################################
                      [1m Learning iteration 160/500 [0m

                       Computation: 9556 steps/s (collection: 0.131s, learning 0.030s)
               Value function loss: 0.0353
                    Surrogate loss: -0.0025
             Mean action noise std: 1.01
                 Mean total reward: 221.72
               Mean episode length: 942.70
 Mean episode rew_tracking_lin_vel: 0.3648
 Mean episode rew_tracking_ang_vel: 0.1752
        Mean episode rew_lin_vel_z: -0.0205
      Mean episode rew_base_height: -2.1727
      Mean episode rew_action_rate: -0.1371
Mean episode rew_similar_to_default: -0.6913
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.8118
--------------------------------------------------------------------------------
                   Total timesteps: 247296
                    Iteration time: 0.16s
                        Total time: 26.31s
                               ETA: 55.6s

################################################################################
                      [1m Learning iteration 161/500 [0m

                       Computation: 9930 steps/s (collection: 0.127s, learning 0.028s)
               Value function loss: 0.0359
                    Surrogate loss: -0.0055
             Mean action noise std: 1.01
                 Mean total reward: 221.72
               Mean episode length: 942.70
 Mean episode rew_tracking_lin_vel: 0.3637
 Mean episode rew_tracking_ang_vel: 0.1720
        Mean episode rew_lin_vel_z: -0.0159
      Mean episode rew_base_height: -2.1845
      Mean episode rew_action_rate: -0.1421
Mean episode rew_similar_to_default: -0.6968
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0007
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.7822
--------------------------------------------------------------------------------
                   Total timesteps: 248832
                    Iteration time: 0.15s
                        Total time: 26.47s
                               ETA: 55.4s

################################################################################
                      [1m Learning iteration 162/500 [0m

                       Computation: 9607 steps/s (collection: 0.131s, learning 0.029s)
               Value function loss: 0.0454
                    Surrogate loss: -0.0052
             Mean action noise std: 1.01
                 Mean total reward: 221.79
               Mean episode length: 942.70
 Mean episode rew_tracking_lin_vel: 0.3624
 Mean episode rew_tracking_ang_vel: 0.1727
        Mean episode rew_lin_vel_z: -0.0157
      Mean episode rew_base_height: -2.1738
      Mean episode rew_action_rate: -0.1406
Mean episode rew_similar_to_default: -0.6944
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.7890
--------------------------------------------------------------------------------
                   Total timesteps: 250368
                    Iteration time: 0.16s
                        Total time: 26.63s
                               ETA: 55.2s

################################################################################
                      [1m Learning iteration 163/500 [0m

                       Computation: 9802 steps/s (collection: 0.129s, learning 0.027s)
               Value function loss: 0.0359
                    Surrogate loss: -0.0112
             Mean action noise std: 1.01
                 Mean total reward: 221.80
               Mean episode length: 942.70
 Mean episode rew_tracking_lin_vel: 0.3628
 Mean episode rew_tracking_ang_vel: 0.1738
        Mean episode rew_lin_vel_z: -0.0153
      Mean episode rew_base_height: -2.1806
      Mean episode rew_action_rate: -0.1407
Mean episode rew_similar_to_default: -0.6935
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.7961
--------------------------------------------------------------------------------
                   Total timesteps: 251904
                    Iteration time: 0.16s
                        Total time: 26.79s
                               ETA: 55.0s

################################################################################
                      [1m Learning iteration 164/500 [0m

                       Computation: 9696 steps/s (collection: 0.130s, learning 0.029s)
               Value function loss: 1.9699
                    Surrogate loss: -0.0028
             Mean action noise std: 1.01
                 Mean total reward: 219.82
               Mean episode length: 934.52
 Mean episode rew_tracking_lin_vel: 0.1264
 Mean episode rew_tracking_ang_vel: 0.0613
        Mean episode rew_lin_vel_z: -0.0176
      Mean episode rew_base_height: -0.7526
      Mean episode rew_action_rate: -0.0503
Mean episode rew_similar_to_default: -0.2451
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.1630
--------------------------------------------------------------------------------
                   Total timesteps: 253440
                    Iteration time: 0.16s
                        Total time: 26.94s
                               ETA: 54.9s

################################################################################
                      [1m Learning iteration 165/500 [0m

                       Computation: 9838 steps/s (collection: 0.128s, learning 0.029s)
               Value function loss: 0.0439
                    Surrogate loss: -0.0097
             Mean action noise std: 1.01
                 Mean total reward: 219.82
               Mean episode length: 934.52
 Mean episode rew_tracking_lin_vel: 0.0647
 Mean episode rew_tracking_ang_vel: 0.0315
        Mean episode rew_lin_vel_z: -0.0176
      Mean episode rew_base_height: -0.3716
      Mean episode rew_action_rate: -0.0264
Mean episode rew_similar_to_default: -0.1257
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.6131
--------------------------------------------------------------------------------
                   Total timesteps: 254976
                    Iteration time: 0.16s
                        Total time: 27.10s
                               ETA: 54.7s

################################################################################
                      [1m Learning iteration 166/500 [0m

                       Computation: 9682 steps/s (collection: 0.131s, learning 0.028s)
               Value function loss: 0.0429
                    Surrogate loss: -0.0085
             Mean action noise std: 1.01
                 Mean total reward: 219.82
               Mean episode length: 934.52
 Mean episode rew_tracking_lin_vel: 0.0647
 Mean episode rew_tracking_ang_vel: 0.0315
        Mean episode rew_lin_vel_z: -0.0176
      Mean episode rew_base_height: -0.3716
      Mean episode rew_action_rate: -0.0264
Mean episode rew_similar_to_default: -0.1257
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.6131
--------------------------------------------------------------------------------
                   Total timesteps: 256512
                    Iteration time: 0.16s
                        Total time: 27.26s
                               ETA: 54.5s

################################################################################
                      [1m Learning iteration 167/500 [0m

                       Computation: 9426 steps/s (collection: 0.136s, learning 0.027s)
               Value function loss: 3.3610
                    Surrogate loss: 0.0003
             Mean action noise std: 1.01
                 Mean total reward: 219.35
               Mean episode length: 931.58
 Mean episode rew_tracking_lin_vel: 0.3561
 Mean episode rew_tracking_ang_vel: 0.1705
        Mean episode rew_lin_vel_z: -0.0215
      Mean episode rew_base_height: -2.1300
      Mean episode rew_action_rate: -0.1363
Mean episode rew_similar_to_default: -0.6885
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.6418
--------------------------------------------------------------------------------
                   Total timesteps: 258048
                    Iteration time: 0.16s
                        Total time: 27.42s
                               ETA: 54.4s

################################################################################
                      [1m Learning iteration 168/500 [0m

                       Computation: 9630 steps/s (collection: 0.130s, learning 0.030s)
               Value function loss: 2.3605
                    Surrogate loss: 0.0005
             Mean action noise std: 1.01
                 Mean total reward: 217.12
               Mean episode length: 921.71
 Mean episode rew_tracking_lin_vel: 0.2741
 Mean episode rew_tracking_ang_vel: 0.1308
        Mean episode rew_lin_vel_z: -0.0182
      Mean episode rew_base_height: -1.6380
      Mean episode rew_action_rate: -0.1040
Mean episode rew_similar_to_default: -0.5306
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.3836
--------------------------------------------------------------------------------
                   Total timesteps: 259584
                    Iteration time: 0.16s
                        Total time: 27.58s
                               ETA: 54.2s

################################################################################
                      [1m Learning iteration 169/500 [0m

                       Computation: 9763 steps/s (collection: 0.130s, learning 0.028s)
               Value function loss: 0.0511
                    Surrogate loss: -0.0104
             Mean action noise std: 1.01
                 Mean total reward: 217.19
               Mean episode length: 921.71
 Mean episode rew_tracking_lin_vel: 0.1524
 Mean episode rew_tracking_ang_vel: 0.0719
        Mean episode rew_lin_vel_z: -0.0137
      Mean episode rew_base_height: -0.9095
      Mean episode rew_action_rate: -0.0590
Mean episode rew_similar_to_default: -0.2966
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.3351
--------------------------------------------------------------------------------
                   Total timesteps: 261120
                    Iteration time: 0.16s
                        Total time: 27.74s
                               ETA: 54.0s

################################################################################
                      [1m Learning iteration 170/500 [0m

                       Computation: 9951 steps/s (collection: 0.127s, learning 0.028s)
               Value function loss: 0.0395
                    Surrogate loss: -0.0126
             Mean action noise std: 1.01
                 Mean total reward: 217.31
               Mean episode length: 921.71
 Mean episode rew_tracking_lin_vel: 0.3660
 Mean episode rew_tracking_ang_vel: 0.1760
        Mean episode rew_lin_vel_z: -0.0204
      Mean episode rew_base_height: -2.2080
      Mean episode rew_action_rate: -0.1393
Mean episode rew_similar_to_default: -0.7112
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.9566
--------------------------------------------------------------------------------
                   Total timesteps: 262656
                    Iteration time: 0.15s
                        Total time: 27.89s
                               ETA: 53.8s

################################################################################
                      [1m Learning iteration 171/500 [0m

                       Computation: 9901 steps/s (collection: 0.128s, learning 0.028s)
               Value function loss: 0.0306
                    Surrogate loss: -0.0123
             Mean action noise std: 1.01
                 Mean total reward: 217.31
               Mean episode length: 921.71
 Mean episode rew_tracking_lin_vel: 0.3660
 Mean episode rew_tracking_ang_vel: 0.1760
        Mean episode rew_lin_vel_z: -0.0204
      Mean episode rew_base_height: -2.2080
      Mean episode rew_action_rate: -0.1393
Mean episode rew_similar_to_default: -0.7112
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.9566
--------------------------------------------------------------------------------
                   Total timesteps: 264192
                    Iteration time: 0.16s
                        Total time: 28.05s
                               ETA: 53.6s

################################################################################
                      [1m Learning iteration 172/500 [0m

                       Computation: 9925 steps/s (collection: 0.126s, learning 0.028s)
               Value function loss: 0.0400
                    Surrogate loss: -0.0116
             Mean action noise std: 1.01
                 Mean total reward: 217.31
               Mean episode length: 921.71
 Mean episode rew_tracking_lin_vel: 0.3660
 Mean episode rew_tracking_ang_vel: 0.1760
        Mean episode rew_lin_vel_z: -0.0204
      Mean episode rew_base_height: -2.2080
      Mean episode rew_action_rate: -0.1393
Mean episode rew_similar_to_default: -0.7112
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.9566
--------------------------------------------------------------------------------
                   Total timesteps: 265728
                    Iteration time: 0.15s
                        Total time: 28.20s
                               ETA: 53.5s

################################################################################
                      [1m Learning iteration 173/500 [0m

                       Computation: 9669 steps/s (collection: 0.128s, learning 0.031s)
               Value function loss: 0.0545
                    Surrogate loss: -0.0093
             Mean action noise std: 1.01
                 Mean total reward: 217.40
               Mean episode length: 921.71
 Mean episode rew_tracking_lin_vel: 0.3616
 Mean episode rew_tracking_ang_vel: 0.1751
        Mean episode rew_lin_vel_z: -0.0178
      Mean episode rew_base_height: -2.1847
      Mean episode rew_action_rate: -0.1397
Mean episode rew_similar_to_default: -0.7062
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.9163
--------------------------------------------------------------------------------
                   Total timesteps: 267264
                    Iteration time: 0.16s
                        Total time: 28.36s
                               ETA: 53.3s

################################################################################
                      [1m Learning iteration 174/500 [0m

                       Computation: 9654 steps/s (collection: 0.130s, learning 0.029s)
               Value function loss: 2.8274
                    Surrogate loss: -0.0067
             Mean action noise std: 1.01
                 Mean total reward: 216.32
               Mean episode length: 916.41
 Mean episode rew_tracking_lin_vel: 0.2977
 Mean episode rew_tracking_ang_vel: 0.1441
        Mean episode rew_lin_vel_z: -0.0180
      Mean episode rew_base_height: -1.7887
      Mean episode rew_action_rate: -0.1162
Mean episode rew_similar_to_default: -0.5838
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.3609
--------------------------------------------------------------------------------
                   Total timesteps: 268800
                    Iteration time: 0.16s
                        Total time: 28.52s
                               ETA: 53.1s

################################################################################
                      [1m Learning iteration 175/500 [0m

                       Computation: 9359 steps/s (collection: 0.134s, learning 0.031s)
               Value function loss: 8.3619
                    Surrogate loss: -0.0057
             Mean action noise std: 1.01
                 Mean total reward: 213.61
               Mean episode length: 903.06
 Mean episode rew_tracking_lin_vel: 0.3227
 Mean episode rew_tracking_ang_vel: 0.1564
        Mean episode rew_lin_vel_z: -0.0194
      Mean episode rew_base_height: -1.9243
      Mean episode rew_action_rate: -0.1242
Mean episode rew_similar_to_default: -0.6364
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4214
--------------------------------------------------------------------------------
                   Total timesteps: 270336
                    Iteration time: 0.16s
                        Total time: 28.68s
                               ETA: 53.0s

################################################################################
                      [1m Learning iteration 176/500 [0m

                       Computation: 9351 steps/s (collection: 0.133s, learning 0.031s)
               Value function loss: 0.0692
                    Surrogate loss: -0.0119
             Mean action noise std: 1.01
                 Mean total reward: 213.61
               Mean episode length: 903.06
 Mean episode rew_tracking_lin_vel: 0.2658
 Mean episode rew_tracking_ang_vel: 0.1268
        Mean episode rew_lin_vel_z: -0.0179
      Mean episode rew_base_height: -1.5604
      Mean episode rew_action_rate: -0.1052
Mean episode rew_similar_to_default: -0.5235
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.1799
--------------------------------------------------------------------------------
                   Total timesteps: 271872
                    Iteration time: 0.16s
                        Total time: 28.85s
                               ETA: 52.8s

################################################################################
                      [1m Learning iteration 177/500 [0m

                       Computation: 9347 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 0.0570
                    Surrogate loss: -0.0092
             Mean action noise std: 1.01
                 Mean total reward: 214.42
               Mean episode length: 903.06
 Mean episode rew_tracking_lin_vel: 0.3559
 Mean episode rew_tracking_ang_vel: 0.1715
        Mean episode rew_lin_vel_z: -0.0210
      Mean episode rew_base_height: -2.1113
      Mean episode rew_action_rate: -0.1367
Mean episode rew_similar_to_default: -0.6986
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.8723
--------------------------------------------------------------------------------
                   Total timesteps: 273408
                    Iteration time: 0.16s
                        Total time: 29.01s
                               ETA: 52.6s

################################################################################
                      [1m Learning iteration 178/500 [0m

                       Computation: 9451 steps/s (collection: 0.133s, learning 0.030s)
               Value function loss: 8.7176
                    Surrogate loss: 0.0040
             Mean action noise std: 1.01
                 Mean total reward: 214.74
               Mean episode length: 900.21
 Mean episode rew_tracking_lin_vel: 0.2850
 Mean episode rew_tracking_ang_vel: 0.1368
        Mean episode rew_lin_vel_z: -0.0199
      Mean episode rew_base_height: -1.6916
      Mean episode rew_action_rate: -0.1085
Mean episode rew_similar_to_default: -0.5574
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.8660
--------------------------------------------------------------------------------
                   Total timesteps: 274944
                    Iteration time: 0.16s
                        Total time: 29.18s
                               ETA: 52.5s

################################################################################
                      [1m Learning iteration 179/500 [0m

                       Computation: 9040 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 6.0125
                    Surrogate loss: 0.0019
             Mean action noise std: 1.01
                 Mean total reward: 213.35
               Mean episode length: 890.05
 Mean episode rew_tracking_lin_vel: 0.2295
 Mean episode rew_tracking_ang_vel: 0.1099
        Mean episode rew_lin_vel_z: -0.0196
      Mean episode rew_base_height: -1.3517
      Mean episode rew_action_rate: -0.0918
Mean episode rew_similar_to_default: -0.4539
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.5761
--------------------------------------------------------------------------------
                   Total timesteps: 276480
                    Iteration time: 0.17s
                        Total time: 29.35s
                               ETA: 52.3s

################################################################################
                      [1m Learning iteration 180/500 [0m

                       Computation: 8771 steps/s (collection: 0.146s, learning 0.030s)
               Value function loss: 14.9578
                    Surrogate loss: 0.0034
             Mean action noise std: 1.01
                 Mean total reward: 208.62
               Mean episode length: 861.43
 Mean episode rew_tracking_lin_vel: 0.2589
 Mean episode rew_tracking_ang_vel: 0.1237
        Mean episode rew_lin_vel_z: -0.0200
      Mean episode rew_base_height: -1.5193
      Mean episode rew_action_rate: -0.1002
Mean episode rew_similar_to_default: -0.5111
Mean episode rew_joint_pose_matching: 0.0015
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.8672
--------------------------------------------------------------------------------
                   Total timesteps: 278016
                    Iteration time: 0.18s
                        Total time: 29.52s
                               ETA: 52.2s

################################################################################
                      [1m Learning iteration 181/500 [0m

                       Computation: 9148 steps/s (collection: 0.137s, learning 0.031s)
               Value function loss: 4.4409
                    Surrogate loss: -0.0040
             Mean action noise std: 1.01
                 Mean total reward: 206.24
               Mean episode length: 849.12
 Mean episode rew_tracking_lin_vel: 0.3462
 Mean episode rew_tracking_ang_vel: 0.1660
        Mean episode rew_lin_vel_z: -0.0195
      Mean episode rew_base_height: -2.0418
      Mean episode rew_action_rate: -0.1349
Mean episode rew_similar_to_default: -0.6802
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.4947
--------------------------------------------------------------------------------
                   Total timesteps: 279552
                    Iteration time: 0.17s
                        Total time: 29.69s
                               ETA: 52.0s

################################################################################
                      [1m Learning iteration 182/500 [0m

                       Computation: 9165 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 5.8352
                    Surrogate loss: 0.0007
             Mean action noise std: 1.01
                 Mean total reward: 203.90
               Mean episode length: 835.88
 Mean episode rew_tracking_lin_vel: 0.2741
 Mean episode rew_tracking_ang_vel: 0.1312
        Mean episode rew_lin_vel_z: -0.0191
      Mean episode rew_base_height: -1.6184
      Mean episode rew_action_rate: -0.1070
Mean episode rew_similar_to_default: -0.5441
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.5708
--------------------------------------------------------------------------------
                   Total timesteps: 281088
                    Iteration time: 0.17s
                        Total time: 29.86s
                               ETA: 51.9s

################################################################################
                      [1m Learning iteration 183/500 [0m

                       Computation: 9408 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 1.6294
                    Surrogate loss: -0.0037
             Mean action noise std: 1.01
                 Mean total reward: 203.82
               Mean episode length: 834.34
 Mean episode rew_tracking_lin_vel: 0.3165
 Mean episode rew_tracking_ang_vel: 0.1516
        Mean episode rew_lin_vel_z: -0.0218
      Mean episode rew_base_height: -1.8736
      Mean episode rew_action_rate: -0.1227
Mean episode rew_similar_to_default: -0.6265
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0008
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5257
--------------------------------------------------------------------------------
                   Total timesteps: 282624
                    Iteration time: 0.16s
                        Total time: 30.02s
                               ETA: 51.7s

################################################################################
                      [1m Learning iteration 184/500 [0m

                       Computation: 9369 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 2.6569
                    Surrogate loss: -0.0045
             Mean action noise std: 1.01
                 Mean total reward: 202.04
               Mean episode length: 825.05
 Mean episode rew_tracking_lin_vel: 0.1517
 Mean episode rew_tracking_ang_vel: 0.0719
        Mean episode rew_lin_vel_z: -0.0194
      Mean episode rew_base_height: -0.8712
      Mean episode rew_action_rate: -0.0580
Mean episode rew_similar_to_default: -0.2956
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.3512
--------------------------------------------------------------------------------
                   Total timesteps: 284160
                    Iteration time: 0.16s
                        Total time: 30.18s
                               ETA: 51.6s

################################################################################
                      [1m Learning iteration 185/500 [0m

                       Computation: 9353 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 11.1343
                    Surrogate loss: -0.0006
             Mean action noise std: 1.01
                 Mean total reward: 194.69
               Mean episode length: 792.47
 Mean episode rew_tracking_lin_vel: 0.0495
 Mean episode rew_tracking_ang_vel: 0.0224
        Mean episode rew_lin_vel_z: -0.0199
      Mean episode rew_base_height: -0.2658
      Mean episode rew_action_rate: -0.0192
Mean episode rew_similar_to_default: -0.0942
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.0244
--------------------------------------------------------------------------------
                   Total timesteps: 285696
                    Iteration time: 0.16s
                        Total time: 30.35s
                               ETA: 51.4s

################################################################################
                      [1m Learning iteration 186/500 [0m

                       Computation: 9350 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 3.1303
                    Surrogate loss: -0.0035
             Mean action noise std: 1.01
                 Mean total reward: 193.39
               Mean episode length: 783.94
 Mean episode rew_tracking_lin_vel: 0.0850
 Mean episode rew_tracking_ang_vel: 0.0408
        Mean episode rew_lin_vel_z: -0.0141
      Mean episode rew_base_height: -0.4845
      Mean episode rew_action_rate: -0.0335
Mean episode rew_similar_to_default: -0.1660
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.5700
--------------------------------------------------------------------------------
                   Total timesteps: 287232
                    Iteration time: 0.16s
                        Total time: 30.51s
                               ETA: 51.2s

################################################################################
                      [1m Learning iteration 187/500 [0m

                       Computation: 8861 steps/s (collection: 0.138s, learning 0.035s)
               Value function loss: 0.0737
                    Surrogate loss: -0.0017
             Mean action noise std: 1.01
                 Mean total reward: 193.62
               Mean episode length: 783.94
 Mean episode rew_tracking_lin_vel: 0.1585
 Mean episode rew_tracking_ang_vel: 0.0745
        Mean episode rew_lin_vel_z: -0.0202
      Mean episode rew_base_height: -0.9141
      Mean episode rew_action_rate: -0.0596
Mean episode rew_similar_to_default: -0.3117
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.6054
--------------------------------------------------------------------------------
                   Total timesteps: 288768
                    Iteration time: 0.17s
                        Total time: 30.69s
                               ETA: 51.1s

################################################################################
                      [1m Learning iteration 188/500 [0m

                       Computation: 8536 steps/s (collection: 0.149s, learning 0.031s)
               Value function loss: 0.0603
                    Surrogate loss: -0.0065
             Mean action noise std: 1.01
                 Mean total reward: 196.20
               Mean episode length: 792.80
 Mean episode rew_tracking_lin_vel: 0.3642
 Mean episode rew_tracking_ang_vel: 0.1720
        Mean episode rew_lin_vel_z: -0.0189
      Mean episode rew_base_height: -2.1473
      Mean episode rew_action_rate: -0.1406
Mean episode rew_similar_to_default: -0.7277
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.4475
--------------------------------------------------------------------------------
                   Total timesteps: 290304
                    Iteration time: 0.18s
                        Total time: 30.87s
                               ETA: 51.0s

################################################################################
                      [1m Learning iteration 189/500 [0m

                       Computation: 8634 steps/s (collection: 0.148s, learning 0.030s)
               Value function loss: 5.9504
                    Surrogate loss: 0.0033
             Mean action noise std: 1.02
                 Mean total reward: 196.17
               Mean episode length: 792.47
 Mean episode rew_tracking_lin_vel: 0.2608
 Mean episode rew_tracking_ang_vel: 0.1229
        Mean episode rew_lin_vel_z: -0.0194
      Mean episode rew_base_height: -1.5339
      Mean episode rew_action_rate: -0.1019
Mean episode rew_similar_to_default: -0.5212
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.0832
--------------------------------------------------------------------------------
                   Total timesteps: 291840
                    Iteration time: 0.18s
                        Total time: 31.04s
                               ETA: 50.8s

################################################################################
                      [1m Learning iteration 190/500 [0m

                       Computation: 8276 steps/s (collection: 0.151s, learning 0.034s)
               Value function loss: 8.5366
                    Surrogate loss: -0.0056
             Mean action noise std: 1.02
                 Mean total reward: 193.76
               Mean episode length: 778.65
 Mean episode rew_tracking_lin_vel: 0.2299
 Mean episode rew_tracking_ang_vel: 0.1089
        Mean episode rew_lin_vel_z: -0.0205
      Mean episode rew_base_height: -1.3497
      Mean episode rew_action_rate: -0.0901
Mean episode rew_similar_to_default: -0.4601
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.7852
--------------------------------------------------------------------------------
                   Total timesteps: 293376
                    Iteration time: 0.19s
                        Total time: 31.23s
                               ETA: 50.7s

################################################################################
                      [1m Learning iteration 191/500 [0m

                       Computation: 8950 steps/s (collection: 0.141s, learning 0.031s)
               Value function loss: 1.8107
                    Surrogate loss: -0.0043
             Mean action noise std: 1.02
                 Mean total reward: 191.85
               Mean episode length: 770.28
 Mean episode rew_tracking_lin_vel: 0.0718
 Mean episode rew_tracking_ang_vel: 0.0319
        Mean episode rew_lin_vel_z: -0.0193
      Mean episode rew_base_height: -0.3998
      Mean episode rew_action_rate: -0.0292
Mean episode rew_similar_to_default: -0.1403
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.0359
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 0.17s
                        Total time: 31.40s
                               ETA: 50.5s

################################################################################
                      [1m Learning iteration 192/500 [0m

                       Computation: 8993 steps/s (collection: 0.142s, learning 0.029s)
               Value function loss: 6.4570
                    Surrogate loss: 0.0037
             Mean action noise std: 1.02
                 Mean total reward: 186.12
               Mean episode length: 743.61
 Mean episode rew_tracking_lin_vel: 0.1599
 Mean episode rew_tracking_ang_vel: 0.0759
        Mean episode rew_lin_vel_z: -0.0207
      Mean episode rew_base_height: -0.9306
      Mean episode rew_action_rate: -0.0631
Mean episode rew_similar_to_default: -0.3193
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.8080
--------------------------------------------------------------------------------
                   Total timesteps: 296448
                    Iteration time: 0.17s
                        Total time: 31.57s
                               ETA: 50.4s

################################################################################
                      [1m Learning iteration 193/500 [0m

                       Computation: 9519 steps/s (collection: 0.133s, learning 0.028s)
               Value function loss: 0.0676
                    Surrogate loss: -0.0069
             Mean action noise std: 1.02
                 Mean total reward: 186.52
               Mean episode length: 743.61
 Mean episode rew_tracking_lin_vel: 0.3200
 Mean episode rew_tracking_ang_vel: 0.1541
        Mean episode rew_lin_vel_z: -0.0216
      Mean episode rew_base_height: -1.9101
      Mean episode rew_action_rate: -0.1241
Mean episode rew_similar_to_default: -0.6485
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5050
--------------------------------------------------------------------------------
                   Total timesteps: 297984
                    Iteration time: 0.16s
                        Total time: 31.73s
                               ETA: 50.2s

################################################################################
                      [1m Learning iteration 194/500 [0m

                       Computation: 9117 steps/s (collection: 0.138s, learning 0.031s)
               Value function loss: 3.0283
                    Surrogate loss: -0.0041
             Mean action noise std: 1.02
                 Mean total reward: 185.53
               Mean episode length: 738.74
 Mean episode rew_tracking_lin_vel: 0.2835
 Mean episode rew_tracking_ang_vel: 0.1362
        Mean episode rew_lin_vel_z: -0.0215
      Mean episode rew_base_height: -1.6943
      Mean episode rew_action_rate: -0.1101
Mean episode rew_similar_to_default: -0.5789
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.0832
--------------------------------------------------------------------------------
                   Total timesteps: 299520
                    Iteration time: 0.17s
                        Total time: 31.90s
                               ETA: 50.1s

################################################################################
                      [1m Learning iteration 195/500 [0m

                       Computation: 8691 steps/s (collection: 0.147s, learning 0.030s)
               Value function loss: 3.3088
                    Surrogate loss: -0.0097
             Mean action noise std: 1.02
                 Mean total reward: 183.68
               Mean episode length: 728.41
 Mean episode rew_tracking_lin_vel: 0.2750
 Mean episode rew_tracking_ang_vel: 0.1320
        Mean episode rew_lin_vel_z: -0.0196
      Mean episode rew_base_height: -1.6243
      Mean episode rew_action_rate: -0.1074
Mean episode rew_similar_to_default: -0.5585
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.6085
--------------------------------------------------------------------------------
                   Total timesteps: 301056
                    Iteration time: 0.18s
                        Total time: 32.08s
                               ETA: 49.9s

################################################################################
                      [1m Learning iteration 196/500 [0m

                       Computation: 8825 steps/s (collection: 0.143s, learning 0.031s)
               Value function loss: 6.5028
                    Surrogate loss: 0.0008
             Mean action noise std: 1.02
                 Mean total reward: 184.73
               Mean episode length: 730.82
 Mean episode rew_tracking_lin_vel: 0.3462
 Mean episode rew_tracking_ang_vel: 0.1667
        Mean episode rew_lin_vel_z: -0.0206
      Mean episode rew_base_height: -2.0483
      Mean episode rew_action_rate: -0.1334
Mean episode rew_similar_to_default: -0.7034
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.6807
--------------------------------------------------------------------------------
                   Total timesteps: 302592
                    Iteration time: 0.17s
                        Total time: 32.25s
                               ETA: 49.8s

################################################################################
                      [1m Learning iteration 197/500 [0m

                       Computation: 8974 steps/s (collection: 0.142s, learning 0.029s)
               Value function loss: 5.8340
                    Surrogate loss: -0.0049
             Mean action noise std: 1.02
                 Mean total reward: 181.64
               Mean episode length: 716.68
 Mean episode rew_tracking_lin_vel: 0.1745
 Mean episode rew_tracking_ang_vel: 0.0827
        Mean episode rew_lin_vel_z: -0.0223
      Mean episode rew_base_height: -1.0249
      Mean episode rew_action_rate: -0.0678
Mean episode rew_similar_to_default: -0.3549
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.4498
--------------------------------------------------------------------------------
                   Total timesteps: 304128
                    Iteration time: 0.17s
                        Total time: 32.42s
                               ETA: 49.6s

################################################################################
                      [1m Learning iteration 198/500 [0m

                       Computation: 9177 steps/s (collection: 0.135s, learning 0.032s)
               Value function loss: 2.5345
                    Surrogate loss: -0.0045
             Mean action noise std: 1.02
                 Mean total reward: 179.75
               Mean episode length: 708.63
 Mean episode rew_tracking_lin_vel: 0.1057
 Mean episode rew_tracking_ang_vel: 0.0498
        Mean episode rew_lin_vel_z: -0.0200
      Mean episode rew_base_height: -0.6119
      Mean episode rew_action_rate: -0.0428
Mean episode rew_similar_to_default: -0.2155
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.4465
--------------------------------------------------------------------------------
                   Total timesteps: 305664
                    Iteration time: 0.17s
                        Total time: 32.59s
                               ETA: 49.5s

################################################################################
                      [1m Learning iteration 199/500 [0m

                       Computation: 9428 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 3.2633
                    Surrogate loss: 0.0014
             Mean action noise std: 1.02
                 Mean total reward: 177.86
               Mean episode length: 699.75
 Mean episode rew_tracking_lin_vel: 0.1097
 Mean episode rew_tracking_ang_vel: 0.0524
        Mean episode rew_lin_vel_z: -0.0203
      Mean episode rew_base_height: -0.6365
      Mean episode rew_action_rate: -0.0429
Mean episode rew_similar_to_default: -0.2218
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.6998
--------------------------------------------------------------------------------
                   Total timesteps: 307200
                    Iteration time: 0.16s
                        Total time: 32.75s
                               ETA: 49.3s

################################################################################
                      [1m Learning iteration 200/500 [0m

                       Computation: 9336 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 4.8554
                    Surrogate loss: -0.0029
             Mean action noise std: 1.02
                 Mean total reward: 176.27
               Mean episode length: 691.92
 Mean episode rew_tracking_lin_vel: 0.2311
 Mean episode rew_tracking_ang_vel: 0.1098
        Mean episode rew_lin_vel_z: -0.0201
      Mean episode rew_base_height: -1.3655
      Mean episode rew_action_rate: -0.0889
Mean episode rew_similar_to_default: -0.4743
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.8846
--------------------------------------------------------------------------------
                   Total timesteps: 308736
                    Iteration time: 0.16s
                        Total time: 32.92s
                               ETA: 49.1s

################################################################################
                      [1m Learning iteration 201/500 [0m

                       Computation: 9354 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 0.0763
                    Surrogate loss: -0.0053
             Mean action noise std: 1.02
                 Mean total reward: 176.27
               Mean episode length: 691.92
 Mean episode rew_tracking_lin_vel: 0.1563
 Mean episode rew_tracking_ang_vel: 0.0757
        Mean episode rew_lin_vel_z: -0.0234
      Mean episode rew_base_height: -0.9334
      Mean episode rew_action_rate: -0.0615
Mean episode rew_similar_to_default: -0.3288
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.7338
--------------------------------------------------------------------------------
                   Total timesteps: 310272
                    Iteration time: 0.16s
                        Total time: 33.08s
                               ETA: 49.0s

################################################################################
                      [1m Learning iteration 202/500 [0m

                       Computation: 9303 steps/s (collection: 0.138s, learning 0.027s)
               Value function loss: 3.1495
                    Surrogate loss: -0.0020
             Mean action noise std: 1.02
                 Mean total reward: 177.69
               Mean episode length: 695.87
 Mean episode rew_tracking_lin_vel: 0.2281
 Mean episode rew_tracking_ang_vel: 0.1091
        Mean episode rew_lin_vel_z: -0.0237
      Mean episode rew_base_height: -1.3656
      Mean episode rew_action_rate: -0.0893
Mean episode rew_similar_to_default: -0.4740
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.9734
--------------------------------------------------------------------------------
                   Total timesteps: 311808
                    Iteration time: 0.17s
                        Total time: 33.25s
                               ETA: 48.8s

################################################################################
                      [1m Learning iteration 203/500 [0m

                       Computation: 9295 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 7.7264
                    Surrogate loss: -0.0025
             Mean action noise std: 1.02
                 Mean total reward: 170.56
               Mean episode length: 666.92
 Mean episode rew_tracking_lin_vel: 0.0733
 Mean episode rew_tracking_ang_vel: 0.0353
        Mean episode rew_lin_vel_z: -0.0185
      Mean episode rew_base_height: -0.4223
      Mean episode rew_action_rate: -0.0279
Mean episode rew_similar_to_default: -0.1477
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.1008
--------------------------------------------------------------------------------
                   Total timesteps: 313344
                    Iteration time: 0.17s
                        Total time: 33.41s
                               ETA: 48.6s

################################################################################
                      [1m Learning iteration 204/500 [0m

                       Computation: 9068 steps/s (collection: 0.139s, learning 0.031s)
               Value function loss: 5.4801
                    Surrogate loss: -0.0049
             Mean action noise std: 1.02
                 Mean total reward: 170.61
               Mean episode length: 665.54
 Mean episode rew_tracking_lin_vel: 0.2662
 Mean episode rew_tracking_ang_vel: 0.1265
        Mean episode rew_lin_vel_z: -0.0223
      Mean episode rew_base_height: -1.5749
      Mean episode rew_action_rate: -0.1055
Mean episode rew_similar_to_default: -0.5460
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.4540
--------------------------------------------------------------------------------
                   Total timesteps: 314880
                    Iteration time: 0.17s
                        Total time: 33.58s
                               ETA: 48.5s

################################################################################
                      [1m Learning iteration 205/500 [0m

                       Computation: 8571 steps/s (collection: 0.144s, learning 0.035s)
               Value function loss: 3.0143
                    Surrogate loss: -0.0090
             Mean action noise std: 1.02
                 Mean total reward: 167.59
               Mean episode length: 652.26
 Mean episode rew_tracking_lin_vel: 0.1151
 Mean episode rew_tracking_ang_vel: 0.0547
        Mean episode rew_lin_vel_z: -0.0161
      Mean episode rew_base_height: -0.6748
      Mean episode rew_action_rate: -0.0437
Mean episode rew_similar_to_default: -0.2342
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.8987
--------------------------------------------------------------------------------
                   Total timesteps: 316416
                    Iteration time: 0.18s
                        Total time: 33.76s
                               ETA: 48.3s

################################################################################
                      [1m Learning iteration 206/500 [0m

                       Computation: 8734 steps/s (collection: 0.145s, learning 0.031s)
               Value function loss: 0.0935
                    Surrogate loss: -0.0058
             Mean action noise std: 1.02
                 Mean total reward: 167.59
               Mean episode length: 652.26
 Mean episode rew_tracking_lin_vel: 0.3682
 Mean episode rew_tracking_ang_vel: 0.1777
        Mean episode rew_lin_vel_z: -0.0224
      Mean episode rew_base_height: -2.1868
      Mean episode rew_action_rate: -0.1416
Mean episode rew_similar_to_default: -0.7548
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.4798
--------------------------------------------------------------------------------
                   Total timesteps: 317952
                    Iteration time: 0.18s
                        Total time: 33.94s
                               ETA: 48.2s

################################################################################
                      [1m Learning iteration 207/500 [0m

                       Computation: 9392 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 2.9927
                    Surrogate loss: -0.0071
             Mean action noise std: 1.02
                 Mean total reward: 166.00
               Mean episode length: 645.74
 Mean episode rew_tracking_lin_vel: 0.2881
 Mean episode rew_tracking_ang_vel: 0.1381
        Mean episode rew_lin_vel_z: -0.0211
      Mean episode rew_base_height: -1.7075
      Mean episode rew_action_rate: -0.1107
Mean episode rew_similar_to_default: -0.5892
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.1124
--------------------------------------------------------------------------------
                   Total timesteps: 319488
                    Iteration time: 0.16s
                        Total time: 34.10s
                               ETA: 48.0s

################################################################################
                      [1m Learning iteration 208/500 [0m

                       Computation: 8998 steps/s (collection: 0.140s, learning 0.031s)
               Value function loss: 4.2257
                    Surrogate loss: -0.0061
             Mean action noise std: 1.02
                 Mean total reward: 165.27
               Mean episode length: 642.15
 Mean episode rew_tracking_lin_vel: 0.2333
 Mean episode rew_tracking_ang_vel: 0.1093
        Mean episode rew_lin_vel_z: -0.0187
      Mean episode rew_base_height: -1.3842
      Mean episode rew_action_rate: -0.0912
Mean episode rew_similar_to_default: -0.4780
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.9260
--------------------------------------------------------------------------------
                   Total timesteps: 321024
                    Iteration time: 0.17s
                        Total time: 34.27s
                               ETA: 47.9s

################################################################################
                      [1m Learning iteration 209/500 [0m

                       Computation: 8727 steps/s (collection: 0.143s, learning 0.033s)
               Value function loss: 0.0717
                    Surrogate loss: -0.0059
             Mean action noise std: 1.02
                 Mean total reward: 165.44
               Mean episode length: 642.15
 Mean episode rew_tracking_lin_vel: 0.3649
 Mean episode rew_tracking_ang_vel: 0.1742
        Mean episode rew_lin_vel_z: -0.0231
      Mean episode rew_base_height: -2.1947
      Mean episode rew_action_rate: -0.1432
Mean episode rew_similar_to_default: -0.7566
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.7804
--------------------------------------------------------------------------------
                   Total timesteps: 322560
                    Iteration time: 0.18s
                        Total time: 34.45s
                               ETA: 47.7s

################################################################################
                      [1m Learning iteration 210/500 [0m

                       Computation: 8710 steps/s (collection: 0.146s, learning 0.030s)
               Value function loss: 5.2690
                    Surrogate loss: 0.0005
             Mean action noise std: 1.02
                 Mean total reward: 164.05
               Mean episode length: 635.61
 Mean episode rew_tracking_lin_vel: 0.2264
 Mean episode rew_tracking_ang_vel: 0.1077
        Mean episode rew_lin_vel_z: -0.0195
      Mean episode rew_base_height: -1.3536
      Mean episode rew_action_rate: -0.0885
Mean episode rew_similar_to_default: -0.4677
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.8007
--------------------------------------------------------------------------------
                   Total timesteps: 324096
                    Iteration time: 0.18s
                        Total time: 34.62s
                               ETA: 47.6s

################################################################################
                      [1m Learning iteration 211/500 [0m

                       Computation: 9045 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 0.0642
                    Surrogate loss: -0.0046
             Mean action noise std: 1.02
                 Mean total reward: 165.58
               Mean episode length: 641.55
 Mean episode rew_tracking_lin_vel: 0.1477
 Mean episode rew_tracking_ang_vel: 0.0685
        Mean episode rew_lin_vel_z: -0.0175
      Mean episode rew_base_height: -0.8735
      Mean episode rew_action_rate: -0.0588
Mean episode rew_similar_to_default: -0.3023
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.2730
--------------------------------------------------------------------------------
                   Total timesteps: 325632
                    Iteration time: 0.17s
                        Total time: 34.79s
                               ETA: 47.4s

################################################################################
                      [1m Learning iteration 212/500 [0m

                       Computation: 9211 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 5.5326
                    Surrogate loss: -0.0074
             Mean action noise std: 1.02
                 Mean total reward: 165.81
               Mean episode length: 641.54
 Mean episode rew_tracking_lin_vel: 0.3000
 Mean episode rew_tracking_ang_vel: 0.1432
        Mean episode rew_lin_vel_z: -0.0230
      Mean episode rew_base_height: -1.8102
      Mean episode rew_action_rate: -0.1165
Mean episode rew_similar_to_default: -0.6244
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.9208
--------------------------------------------------------------------------------
                   Total timesteps: 327168
                    Iteration time: 0.17s
                        Total time: 34.96s
                               ETA: 47.3s

################################################################################
                      [1m Learning iteration 213/500 [0m

                       Computation: 9310 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.0482
                    Surrogate loss: -0.0075
             Mean action noise std: 1.02
                 Mean total reward: 165.81
               Mean episode length: 641.54
 Mean episode rew_tracking_lin_vel: 0.2247
 Mean episode rew_tracking_ang_vel: 0.1092
        Mean episode rew_lin_vel_z: -0.0247
      Mean episode rew_base_height: -1.3745
      Mean episode rew_action_rate: -0.0884
Mean episode rew_similar_to_default: -0.4738
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.9444
--------------------------------------------------------------------------------
                   Total timesteps: 328704
                    Iteration time: 0.16s
                        Total time: 35.12s
                               ETA: 47.1s

################################################################################
                      [1m Learning iteration 214/500 [0m

                       Computation: 9432 steps/s (collection: 0.133s, learning 0.030s)
               Value function loss: 0.0476
                    Surrogate loss: -0.0078
             Mean action noise std: 1.02
                 Mean total reward: 165.81
               Mean episode length: 641.54
 Mean episode rew_tracking_lin_vel: 0.2247
 Mean episode rew_tracking_ang_vel: 0.1092
        Mean episode rew_lin_vel_z: -0.0247
      Mean episode rew_base_height: -1.3745
      Mean episode rew_action_rate: -0.0884
Mean episode rew_similar_to_default: -0.4738
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.9444
--------------------------------------------------------------------------------
                   Total timesteps: 330240
                    Iteration time: 0.16s
                        Total time: 35.29s
                               ETA: 46.9s

################################################################################
                      [1m Learning iteration 215/500 [0m

                       Computation: 9489 steps/s (collection: 0.132s, learning 0.030s)
               Value function loss: 0.0627
                    Surrogate loss: 0.0018
             Mean action noise std: 1.02
                 Mean total reward: 165.81
               Mean episode length: 641.54
 Mean episode rew_tracking_lin_vel: 0.2247
 Mean episode rew_tracking_ang_vel: 0.1092
        Mean episode rew_lin_vel_z: -0.0247
      Mean episode rew_base_height: -1.3745
      Mean episode rew_action_rate: -0.0884
Mean episode rew_similar_to_default: -0.4738
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.9444
--------------------------------------------------------------------------------
                   Total timesteps: 331776
                    Iteration time: 0.16s
                        Total time: 35.45s
                               ETA: 46.8s

################################################################################
                      [1m Learning iteration 216/500 [0m

                       Computation: 9205 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 7.9849
                    Surrogate loss: -0.0024
             Mean action noise std: 1.02
                 Mean total reward: 162.99
               Mean episode length: 629.06
 Mean episode rew_tracking_lin_vel: 0.2097
 Mean episode rew_tracking_ang_vel: 0.0997
        Mean episode rew_lin_vel_z: -0.0219
      Mean episode rew_base_height: -1.2675
      Mean episode rew_action_rate: -0.0806
Mean episode rew_similar_to_default: -0.4366
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.1909
--------------------------------------------------------------------------------
                   Total timesteps: 333312
                    Iteration time: 0.17s
                        Total time: 35.62s
                               ETA: 46.6s

################################################################################
                      [1m Learning iteration 217/500 [0m

                       Computation: 9161 steps/s (collection: 0.138s, learning 0.030s)
               Value function loss: 4.3148
                    Surrogate loss: -0.0067
             Mean action noise std: 1.02
                 Mean total reward: 158.25
               Mean episode length: 609.59
 Mean episode rew_tracking_lin_vel: 0.2489
 Mean episode rew_tracking_ang_vel: 0.1179
        Mean episode rew_lin_vel_z: -0.0199
      Mean episode rew_base_height: -1.4903
      Mean episode rew_action_rate: -0.0959
Mean episode rew_similar_to_default: -0.5158
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.7563
--------------------------------------------------------------------------------
                   Total timesteps: 334848
                    Iteration time: 0.17s
                        Total time: 35.78s
                               ETA: 46.5s

################################################################################
                      [1m Learning iteration 218/500 [0m

                       Computation: 9403 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 2.2217
                    Surrogate loss: -0.0070
             Mean action noise std: 1.02
                 Mean total reward: 156.96
               Mean episode length: 604.56
 Mean episode rew_tracking_lin_vel: 0.1977
 Mean episode rew_tracking_ang_vel: 0.0931
        Mean episode rew_lin_vel_z: -0.0224
      Mean episode rew_base_height: -1.1827
      Mean episode rew_action_rate: -0.0767
Mean episode rew_similar_to_default: -0.4112
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.5192
--------------------------------------------------------------------------------
                   Total timesteps: 336384
                    Iteration time: 0.16s
                        Total time: 35.95s
                               ETA: 46.3s

################################################################################
                      [1m Learning iteration 219/500 [0m

                       Computation: 9324 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 2.8262
                    Surrogate loss: -0.0078
             Mean action noise std: 1.02
                 Mean total reward: 159.21
               Mean episode length: 613.26
 Mean episode rew_tracking_lin_vel: 0.2356
 Mean episode rew_tracking_ang_vel: 0.1125
        Mean episode rew_lin_vel_z: -0.0223
      Mean episode rew_base_height: -1.4217
      Mean episode rew_action_rate: -0.0938
Mean episode rew_similar_to_default: -0.4926
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.0229
--------------------------------------------------------------------------------
                   Total timesteps: 337920
                    Iteration time: 0.16s
                        Total time: 36.11s
                               ETA: 46.1s

################################################################################
                      [1m Learning iteration 220/500 [0m

                       Computation: 9183 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 0.0915
                    Surrogate loss: -0.0078
             Mean action noise std: 1.02
                 Mean total reward: 161.98
               Mean episode length: 623.13
 Mean episode rew_tracking_lin_vel: 0.3662
 Mean episode rew_tracking_ang_vel: 0.1739
        Mean episode rew_lin_vel_z: -0.0227
      Mean episode rew_base_height: -2.1981
      Mean episode rew_action_rate: -0.1433
Mean episode rew_similar_to_default: -0.7611
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.8429
--------------------------------------------------------------------------------
                   Total timesteps: 339456
                    Iteration time: 0.17s
                        Total time: 36.28s
                               ETA: 46.0s

################################################################################
                      [1m Learning iteration 221/500 [0m

                       Computation: 9054 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 0.1167
                    Surrogate loss: -0.0043
             Mean action noise std: 1.02
                 Mean total reward: 162.90
               Mean episode length: 625.89
 Mean episode rew_tracking_lin_vel: 0.3678
 Mean episode rew_tracking_ang_vel: 0.1731
        Mean episode rew_lin_vel_z: -0.0210
      Mean episode rew_base_height: -2.2032
      Mean episode rew_action_rate: -0.1403
Mean episode rew_similar_to_default: -0.7650
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.7761
--------------------------------------------------------------------------------
                   Total timesteps: 340992
                    Iteration time: 0.17s
                        Total time: 36.45s
                               ETA: 45.8s

################################################################################
                      [1m Learning iteration 222/500 [0m

                       Computation: 9108 steps/s (collection: 0.139s, learning 0.030s)
               Value function loss: 2.5427
                    Surrogate loss: -0.0022
             Mean action noise std: 1.02
                 Mean total reward: 163.14
               Mean episode length: 626.38
 Mean episode rew_tracking_lin_vel: 0.3531
 Mean episode rew_tracking_ang_vel: 0.1670
        Mean episode rew_lin_vel_z: -0.0216
      Mean episode rew_base_height: -2.1274
      Mean episode rew_action_rate: -0.1364
Mean episode rew_similar_to_default: -0.7383
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.2087
--------------------------------------------------------------------------------
                   Total timesteps: 342528
                    Iteration time: 0.17s
                        Total time: 36.62s
                               ETA: 45.6s

################################################################################
                      [1m Learning iteration 223/500 [0m

                       Computation: 9127 steps/s (collection: 0.139s, learning 0.030s)
               Value function loss: 2.0442
                    Surrogate loss: -0.0067
             Mean action noise std: 1.02
                 Mean total reward: 165.19
               Mean episode length: 633.87
 Mean episode rew_tracking_lin_vel: 0.1638
 Mean episode rew_tracking_ang_vel: 0.0766
        Mean episode rew_lin_vel_z: -0.0233
      Mean episode rew_base_height: -0.9828
      Mean episode rew_action_rate: -0.0643
Mean episode rew_similar_to_default: -0.3419
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.0545
--------------------------------------------------------------------------------
                   Total timesteps: 344064
                    Iteration time: 0.17s
                        Total time: 36.79s
                               ETA: 45.5s

################################################################################
                      [1m Learning iteration 224/500 [0m

                       Computation: 9309 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 4.8001
                    Surrogate loss: 0.0004
             Mean action noise std: 1.02
                 Mean total reward: 165.05
               Mean episode length: 632.99
 Mean episode rew_tracking_lin_vel: 0.2787
 Mean episode rew_tracking_ang_vel: 0.1324
        Mean episode rew_lin_vel_z: -0.0226
      Mean episode rew_base_height: -1.6958
      Mean episode rew_action_rate: -0.1115
Mean episode rew_similar_to_default: -0.5857
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.9944
--------------------------------------------------------------------------------
                   Total timesteps: 345600
                    Iteration time: 0.16s
                        Total time: 36.95s
                               ETA: 45.3s

################################################################################
                      [1m Learning iteration 225/500 [0m

                       Computation: 8713 steps/s (collection: 0.137s, learning 0.039s)
               Value function loss: 0.0589
                    Surrogate loss: -0.0080
             Mean action noise std: 1.02
                 Mean total reward: 165.68
               Mean episode length: 635.42
 Mean episode rew_tracking_lin_vel: 0.1258
 Mean episode rew_tracking_ang_vel: 0.0583
        Mean episode rew_lin_vel_z: -0.0232
      Mean episode rew_base_height: -0.7443
      Mean episode rew_action_rate: -0.0481
Mean episode rew_similar_to_default: -0.2594
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.3606
--------------------------------------------------------------------------------
                   Total timesteps: 347136
                    Iteration time: 0.18s
                        Total time: 37.13s
                               ETA: 45.2s

################################################################################
                      [1m Learning iteration 226/500 [0m

                       Computation: 8940 steps/s (collection: 0.142s, learning 0.029s)
               Value function loss: 14.1989
                    Surrogate loss: 0.0163
             Mean action noise std: 1.02
                 Mean total reward: 159.25
               Mean episode length: 609.86
 Mean episode rew_tracking_lin_vel: 0.1737
 Mean episode rew_tracking_ang_vel: 0.0826
        Mean episode rew_lin_vel_z: -0.0189
      Mean episode rew_base_height: -1.0469
      Mean episode rew_action_rate: -0.0662
Mean episode rew_similar_to_default: -0.3631
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.4683
--------------------------------------------------------------------------------
                   Total timesteps: 348672
                    Iteration time: 0.17s
                        Total time: 37.30s
                               ETA: 45.0s

################################################################################
                      [1m Learning iteration 227/500 [0m

                       Computation: 8975 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 7.8727
                    Surrogate loss: -0.0110
             Mean action noise std: 1.02
                 Mean total reward: 168.36
               Mean episode length: 643.86
 Mean episode rew_tracking_lin_vel: 0.2298
 Mean episode rew_tracking_ang_vel: 0.1083
        Mean episode rew_lin_vel_z: -0.0193
      Mean episode rew_base_height: -1.3928
      Mean episode rew_action_rate: -0.0887
Mean episode rew_similar_to_default: -0.4809
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.0025
--------------------------------------------------------------------------------
                   Total timesteps: 350208
                    Iteration time: 0.17s
                        Total time: 37.47s
                               ETA: 44.9s

################################################################################
                      [1m Learning iteration 228/500 [0m

                       Computation: 9191 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 0.0805
                    Surrogate loss: -0.0070
             Mean action noise std: 1.02
                 Mean total reward: 168.52
               Mean episode length: 643.86
 Mean episode rew_tracking_lin_vel: 0.3469
 Mean episode rew_tracking_ang_vel: 0.1652
        Mean episode rew_lin_vel_z: -0.0225
      Mean episode rew_base_height: -2.1106
      Mean episode rew_action_rate: -0.1348
Mean episode rew_similar_to_default: -0.7273
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0007
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.0475
--------------------------------------------------------------------------------
                   Total timesteps: 351744
                    Iteration time: 0.17s
                        Total time: 37.64s
                               ETA: 44.7s

################################################################################
                      [1m Learning iteration 229/500 [0m

                       Computation: 9197 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 1.6167
                    Surrogate loss: -0.0049
             Mean action noise std: 1.02
                 Mean total reward: 170.55
               Mean episode length: 651.17
 Mean episode rew_tracking_lin_vel: 0.3581
 Mean episode rew_tracking_ang_vel: 0.1690
        Mean episode rew_lin_vel_z: -0.0207
      Mean episode rew_base_height: -2.1816
      Mean episode rew_action_rate: -0.1375
Mean episode rew_similar_to_default: -0.7503
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.3179
--------------------------------------------------------------------------------
                   Total timesteps: 353280
                    Iteration time: 0.17s
                        Total time: 37.80s
                               ETA: 44.5s

################################################################################
                      [1m Learning iteration 230/500 [0m

                       Computation: 9072 steps/s (collection: 0.139s, learning 0.030s)
               Value function loss: 3.8266
                    Surrogate loss: -0.0020
             Mean action noise std: 1.02
                 Mean total reward: 168.06
               Mean episode length: 641.24
 Mean episode rew_tracking_lin_vel: 0.0908
 Mean episode rew_tracking_ang_vel: 0.0432
        Mean episode rew_lin_vel_z: -0.0124
      Mean episode rew_base_height: -0.5459
      Mean episode rew_action_rate: -0.0362
Mean episode rew_similar_to_default: -0.1888
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.9498
--------------------------------------------------------------------------------
                   Total timesteps: 354816
                    Iteration time: 0.17s
                        Total time: 37.97s
                               ETA: 44.4s

################################################################################
                      [1m Learning iteration 231/500 [0m

                       Computation: 9240 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 0.0653
                    Surrogate loss: -0.0053
             Mean action noise std: 1.02
                 Mean total reward: 168.06
               Mean episode length: 641.24
 Mean episode rew_tracking_lin_vel: 0.0029
 Mean episode rew_tracking_ang_vel: 0.0016
        Mean episode rew_lin_vel_z: -0.0073
      Mean episode rew_base_height: -0.0030
      Mean episode rew_action_rate: -0.0019
Mean episode rew_similar_to_default: -0.0017
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.1274
--------------------------------------------------------------------------------
                   Total timesteps: 356352
                    Iteration time: 0.17s
                        Total time: 38.14s
                               ETA: 44.2s

################################################################################
                      [1m Learning iteration 232/500 [0m

                       Computation: 8851 steps/s (collection: 0.143s, learning 0.030s)
               Value function loss: 4.6944
                    Surrogate loss: 0.0007
             Mean action noise std: 1.02
                 Mean total reward: 169.76
               Mean episode length: 647.47
 Mean episode rew_tracking_lin_vel: 0.2810
 Mean episode rew_tracking_ang_vel: 0.1348
        Mean episode rew_lin_vel_z: -0.0176
      Mean episode rew_base_height: -1.7149
      Mean episode rew_action_rate: -0.1115
Mean episode rew_similar_to_default: -0.5951
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.2120
--------------------------------------------------------------------------------
                   Total timesteps: 357888
                    Iteration time: 0.17s
                        Total time: 38.31s
                               ETA: 44.1s

################################################################################
                      [1m Learning iteration 233/500 [0m

                       Computation: 9087 steps/s (collection: 0.141s, learning 0.028s)
               Value function loss: 4.1424
                    Surrogate loss: -0.0018
             Mean action noise std: 1.02
                 Mean total reward: 166.38
               Mean episode length: 634.47
 Mean episode rew_tracking_lin_vel: 0.0035
 Mean episode rew_tracking_ang_vel: 0.0021
        Mean episode rew_lin_vel_z: -0.0130
      Mean episode rew_base_height: -0.0041
      Mean episode rew_action_rate: -0.0023
Mean episode rew_similar_to_default: -0.0028
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.1360
--------------------------------------------------------------------------------
                   Total timesteps: 359424
                    Iteration time: 0.17s
                        Total time: 38.48s
                               ETA: 43.9s

################################################################################
                      [1m Learning iteration 234/500 [0m

                       Computation: 9055 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 0.0705
                    Surrogate loss: -0.0100
             Mean action noise std: 1.02
                 Mean total reward: 168.66
               Mean episode length: 642.84
 Mean episode rew_tracking_lin_vel: 0.3654
 Mean episode rew_tracking_ang_vel: 0.1729
        Mean episode rew_lin_vel_z: -0.0218
      Mean episode rew_base_height: -2.2182
      Mean episode rew_action_rate: -0.1413
Mean episode rew_similar_to_default: -0.7701
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.1153
--------------------------------------------------------------------------------
                   Total timesteps: 360960
                    Iteration time: 0.17s
                        Total time: 38.65s
                               ETA: 43.8s

################################################################################
                      [1m Learning iteration 235/500 [0m

                       Computation: 9112 steps/s (collection: 0.139s, learning 0.030s)
               Value function loss: 2.8654
                    Surrogate loss: -0.0060
             Mean action noise std: 1.02
                 Mean total reward: 169.52
               Mean episode length: 645.82
 Mean episode rew_tracking_lin_vel: 0.2826
 Mean episode rew_tracking_ang_vel: 0.1338
        Mean episode rew_lin_vel_z: -0.0229
      Mean episode rew_base_height: -1.7155
      Mean episode rew_action_rate: -0.1090
Mean episode rew_similar_to_default: -0.5945
Mean episode rew_joint_pose_matching: 0.0017
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.3336
--------------------------------------------------------------------------------
                   Total timesteps: 362496
                    Iteration time: 0.17s
                        Total time: 38.82s
                               ETA: 43.6s

################################################################################
                      [1m Learning iteration 236/500 [0m

                       Computation: 9084 steps/s (collection: 0.139s, learning 0.030s)
               Value function loss: 0.0675
                    Surrogate loss: -0.0062
             Mean action noise std: 1.02
                 Mean total reward: 169.56
               Mean episode length: 645.82
 Mean episode rew_tracking_lin_vel: 0.3028
 Mean episode rew_tracking_ang_vel: 0.1458
        Mean episode rew_lin_vel_z: -0.0207
      Mean episode rew_base_height: -1.8399
      Mean episode rew_action_rate: -0.1228
Mean episode rew_similar_to_default: -0.6350
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.2030
--------------------------------------------------------------------------------
                   Total timesteps: 364032
                    Iteration time: 0.17s
                        Total time: 38.99s
                               ETA: 43.4s

################################################################################
                      [1m Learning iteration 237/500 [0m

                       Computation: 9014 steps/s (collection: 0.141s, learning 0.029s)
               Value function loss: 3.4574
                    Surrogate loss: -0.0070
             Mean action noise std: 1.02
                 Mean total reward: 170.26
               Mean episode length: 647.74
 Mean episode rew_tracking_lin_vel: 0.2509
 Mean episode rew_tracking_ang_vel: 0.1197
        Mean episode rew_lin_vel_z: -0.0181
      Mean episode rew_base_height: -1.5394
      Mean episode rew_action_rate: -0.1002
Mean episode rew_similar_to_default: -0.5307
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.9994
--------------------------------------------------------------------------------
                   Total timesteps: 365568
                    Iteration time: 0.17s
                        Total time: 39.16s
                               ETA: 43.3s

################################################################################
                      [1m Learning iteration 238/500 [0m

                       Computation: 8886 steps/s (collection: 0.143s, learning 0.030s)
               Value function loss: 1.8132
                    Surrogate loss: -0.0073
             Mean action noise std: 1.02
                 Mean total reward: 171.71
               Mean episode length: 652.87
 Mean episode rew_tracking_lin_vel: 0.2215
 Mean episode rew_tracking_ang_vel: 0.1050
        Mean episode rew_lin_vel_z: -0.0184
      Mean episode rew_base_height: -1.3510
      Mean episode rew_action_rate: -0.0891
Mean episode rew_similar_to_default: -0.4664
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.5985
--------------------------------------------------------------------------------
                   Total timesteps: 367104
                    Iteration time: 0.17s
                        Total time: 39.33s
                               ETA: 43.1s

################################################################################
                      [1m Learning iteration 239/500 [0m

                       Computation: 8797 steps/s (collection: 0.141s, learning 0.034s)
               Value function loss: 0.0578
                    Surrogate loss: -0.0059
             Mean action noise std: 1.02
                 Mean total reward: 171.81
               Mean episode length: 652.87
 Mean episode rew_tracking_lin_vel: 0.3667
 Mean episode rew_tracking_ang_vel: 0.1738
        Mean episode rew_lin_vel_z: -0.0218
      Mean episode rew_base_height: -2.2334
      Mean episode rew_action_rate: -0.1441
Mean episode rew_similar_to_default: -0.7693
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.8234
--------------------------------------------------------------------------------
                   Total timesteps: 368640
                    Iteration time: 0.17s
                        Total time: 39.51s
                               ETA: 43.0s

################################################################################
                      [1m Learning iteration 240/500 [0m

                       Computation: 8728 steps/s (collection: 0.147s, learning 0.029s)
               Value function loss: 0.0360
                    Surrogate loss: -0.0125
             Mean action noise std: 1.02
                 Mean total reward: 171.81
               Mean episode length: 652.87
 Mean episode rew_tracking_lin_vel: 0.3682
 Mean episode rew_tracking_ang_vel: 0.1748
        Mean episode rew_lin_vel_z: -0.0229
      Mean episode rew_base_height: -2.2199
      Mean episode rew_action_rate: -0.1446
Mean episode rew_similar_to_default: -0.7665
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.8145
--------------------------------------------------------------------------------
                   Total timesteps: 370176
                    Iteration time: 0.18s
                        Total time: 39.68s
                               ETA: 42.8s

################################################################################
                      [1m Learning iteration 241/500 [0m

                       Computation: 8852 steps/s (collection: 0.145s, learning 0.029s)
               Value function loss: 0.0599
                    Surrogate loss: -0.0069
             Mean action noise std: 1.02
                 Mean total reward: 173.87
               Mean episode length: 660.54
 Mean episode rew_tracking_lin_vel: 0.3655
 Mean episode rew_tracking_ang_vel: 0.1715
        Mean episode rew_lin_vel_z: -0.0201
      Mean episode rew_base_height: -2.2360
      Mean episode rew_action_rate: -0.1458
Mean episode rew_similar_to_default: -0.7719
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.8584
--------------------------------------------------------------------------------
                   Total timesteps: 371712
                    Iteration time: 0.17s
                        Total time: 39.86s
                               ETA: 42.7s

################################################################################
                      [1m Learning iteration 242/500 [0m

                       Computation: 8540 steps/s (collection: 0.148s, learning 0.031s)
               Value function loss: 0.0528
                    Surrogate loss: -0.0080
             Mean action noise std: 1.02
                 Mean total reward: 173.86
               Mean episode length: 660.54
 Mean episode rew_tracking_lin_vel: 0.3643
 Mean episode rew_tracking_ang_vel: 0.1720
        Mean episode rew_lin_vel_z: -0.0209
      Mean episode rew_base_height: -2.2455
      Mean episode rew_action_rate: -0.1448
Mean episode rew_similar_to_default: -0.7787
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.7628
--------------------------------------------------------------------------------
                   Total timesteps: 373248
                    Iteration time: 0.18s
                        Total time: 40.04s
                               ETA: 42.5s

################################################################################
                      [1m Learning iteration 243/500 [0m

                       Computation: 8378 steps/s (collection: 0.152s, learning 0.031s)
               Value function loss: 22.9034
                    Surrogate loss: -0.0056
             Mean action noise std: 1.02
                 Mean total reward: 166.14
               Mean episode length: 630.93
 Mean episode rew_tracking_lin_vel: 0.2180
 Mean episode rew_tracking_ang_vel: 0.1039
        Mean episode rew_lin_vel_z: -0.0223
      Mean episode rew_base_height: -1.3323
      Mean episode rew_action_rate: -0.0870
Mean episode rew_similar_to_default: -0.4641
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.3640
--------------------------------------------------------------------------------
                   Total timesteps: 374784
                    Iteration time: 0.18s
                        Total time: 40.22s
                               ETA: 42.4s

################################################################################
                      [1m Learning iteration 244/500 [0m

                       Computation: 8917 steps/s (collection: 0.144s, learning 0.028s)
               Value function loss: 0.0795
                    Surrogate loss: -0.0119
             Mean action noise std: 1.02
                 Mean total reward: 166.14
               Mean episode length: 630.93
 Mean episode rew_tracking_lin_vel: 0.0032
 Mean episode rew_tracking_ang_vel: 0.0019
        Mean episode rew_lin_vel_z: -0.0119
      Mean episode rew_base_height: -0.0032
      Mean episode rew_action_rate: -0.0017
Mean episode rew_similar_to_default: -0.0026
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.1470
--------------------------------------------------------------------------------
                   Total timesteps: 376320
                    Iteration time: 0.17s
                        Total time: 40.39s
                               ETA: 42.2s

################################################################################
                      [1m Learning iteration 245/500 [0m

                       Computation: 8578 steps/s (collection: 0.149s, learning 0.030s)
               Value function loss: 7.2236
                    Surrogate loss: 0.0041
             Mean action noise std: 1.02
                 Mean total reward: 167.93
               Mean episode length: 637.92
 Mean episode rew_tracking_lin_vel: 0.1033
 Mean episode rew_tracking_ang_vel: 0.0483
        Mean episode rew_lin_vel_z: -0.0214
      Mean episode rew_base_height: -0.6199
      Mean episode rew_action_rate: -0.0426
Mean episode rew_similar_to_default: -0.2158
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.4093
--------------------------------------------------------------------------------
                   Total timesteps: 377856
                    Iteration time: 0.18s
                        Total time: 40.57s
                               ETA: 42.1s

################################################################################
                      [1m Learning iteration 246/500 [0m

                       Computation: 8641 steps/s (collection: 0.150s, learning 0.028s)
               Value function loss: 0.0724
                    Surrogate loss: -0.0096
             Mean action noise std: 1.02
                 Mean total reward: 172.96
               Mean episode length: 657.02
 Mean episode rew_tracking_lin_vel: 0.2780
 Mean episode rew_tracking_ang_vel: 0.1313
        Mean episode rew_lin_vel_z: -0.0198
      Mean episode rew_base_height: -1.7097
      Mean episode rew_action_rate: -0.1134
Mean episode rew_similar_to_default: -0.5891
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.0259
--------------------------------------------------------------------------------
                   Total timesteps: 379392
                    Iteration time: 0.18s
                        Total time: 40.75s
                               ETA: 41.9s

################################################################################
                      [1m Learning iteration 247/500 [0m

                       Computation: 9239 steps/s (collection: 0.138s, learning 0.028s)
               Value function loss: 2.4018
                    Surrogate loss: -0.0009
             Mean action noise std: 1.02
                 Mean total reward: 172.89
               Mean episode length: 656.68
 Mean episode rew_tracking_lin_vel: 0.2449
 Mean episode rew_tracking_ang_vel: 0.1150
        Mean episode rew_lin_vel_z: -0.0195
      Mean episode rew_base_height: -1.5077
      Mean episode rew_action_rate: -0.0982
Mean episode rew_similar_to_default: -0.5218
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.6989
--------------------------------------------------------------------------------
                   Total timesteps: 380928
                    Iteration time: 0.17s
                        Total time: 40.91s
                               ETA: 41.7s

################################################################################
                      [1m Learning iteration 248/500 [0m

                       Computation: 9310 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 5.3929
                    Surrogate loss: -0.0067
             Mean action noise std: 1.02
                 Mean total reward: 171.07
               Mean episode length: 649.49
 Mean episode rew_tracking_lin_vel: 0.0702
 Mean episode rew_tracking_ang_vel: 0.0325
        Mean episode rew_lin_vel_z: -0.0118
      Mean episode rew_base_height: -0.4242
      Mean episode rew_action_rate: -0.0283
Mean episode rew_similar_to_default: -0.1478
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.1212
--------------------------------------------------------------------------------
                   Total timesteps: 382464
                    Iteration time: 0.16s
                        Total time: 41.08s
                               ETA: 41.6s

################################################################################
                      [1m Learning iteration 249/500 [0m

                       Computation: 9149 steps/s (collection: 0.140s, learning 0.028s)
               Value function loss: 9.4140
                    Surrogate loss: -0.0045
             Mean action noise std: 1.02
                 Mean total reward: 169.29
               Mean episode length: 642.27
 Mean episode rew_tracking_lin_vel: 0.1423
 Mean episode rew_tracking_ang_vel: 0.0676
        Mean episode rew_lin_vel_z: -0.0148
      Mean episode rew_base_height: -0.8799
      Mean episode rew_action_rate: -0.0577
Mean episode rew_similar_to_default: -0.3046
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.2517
--------------------------------------------------------------------------------
                   Total timesteps: 384000
                    Iteration time: 0.17s
                        Total time: 41.25s
                               ETA: 41.4s

################################################################################
                      [1m Learning iteration 250/500 [0m

                       Computation: 9036 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 8.8001
                    Surrogate loss: -0.0037
             Mean action noise std: 1.02
                 Mean total reward: 166.16
               Mean episode length: 630.02
 Mean episode rew_tracking_lin_vel: 0.1948
 Mean episode rew_tracking_ang_vel: 0.0920
        Mean episode rew_lin_vel_z: -0.0197
      Mean episode rew_base_height: -1.1940
      Mean episode rew_action_rate: -0.0794
Mean episode rew_similar_to_default: -0.4155
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.4668
--------------------------------------------------------------------------------
                   Total timesteps: 385536
                    Iteration time: 0.17s
                        Total time: 41.42s
                               ETA: 41.3s

################################################################################
                      [1m Learning iteration 251/500 [0m

                       Computation: 9413 steps/s (collection: 0.133s, learning 0.030s)
               Value function loss: 0.0726
                    Surrogate loss: -0.0047
             Mean action noise std: 1.02
                 Mean total reward: 166.16
               Mean episode length: 630.02
 Mean episode rew_tracking_lin_vel: 0.0225
 Mean episode rew_tracking_ang_vel: 0.0113
        Mean episode rew_lin_vel_z: -0.0199
      Mean episode rew_base_height: -0.1178
      Mean episode rew_action_rate: -0.0098
Mean episode rew_similar_to_default: -0.0442
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.8911
--------------------------------------------------------------------------------
                   Total timesteps: 387072
                    Iteration time: 0.16s
                        Total time: 41.58s
                               ETA: 41.1s

################################################################################
                      [1m Learning iteration 252/500 [0m

                       Computation: 9193 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 5.3041
                    Surrogate loss: -0.0105
             Mean action noise std: 1.02
                 Mean total reward: 167.01
               Mean episode length: 633.57
 Mean episode rew_tracking_lin_vel: 0.1858
 Mean episode rew_tracking_ang_vel: 0.0867
        Mean episode rew_lin_vel_z: -0.0219
      Mean episode rew_base_height: -1.1352
      Mean episode rew_action_rate: -0.0755
Mean episode rew_similar_to_default: -0.3934
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.0778
--------------------------------------------------------------------------------
                   Total timesteps: 388608
                    Iteration time: 0.17s
                        Total time: 41.75s
                               ETA: 40.9s

################################################################################
                      [1m Learning iteration 253/500 [0m

                       Computation: 9543 steps/s (collection: 0.134s, learning 0.027s)
               Value function loss: 0.0634
                    Surrogate loss: -0.0101
             Mean action noise std: 1.02
                 Mean total reward: 166.97
               Mean episode length: 633.57
 Mean episode rew_tracking_lin_vel: 0.2509
 Mean episode rew_tracking_ang_vel: 0.1163
        Mean episode rew_lin_vel_z: -0.0222
      Mean episode rew_base_height: -1.5450
      Mean episode rew_action_rate: -0.1047
Mean episode rew_similar_to_default: -0.5337
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.8771
--------------------------------------------------------------------------------
                   Total timesteps: 390144
                    Iteration time: 0.16s
                        Total time: 41.91s
                               ETA: 40.8s

################################################################################
                      [1m Learning iteration 254/500 [0m

                       Computation: 9438 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 0.0422
                    Surrogate loss: -0.0126
             Mean action noise std: 1.02
                 Mean total reward: 167.01
               Mean episode length: 633.57
 Mean episode rew_tracking_lin_vel: 0.3658
 Mean episode rew_tracking_ang_vel: 0.1714
        Mean episode rew_lin_vel_z: -0.0243
      Mean episode rew_base_height: -2.2561
      Mean episode rew_action_rate: -0.1509
Mean episode rew_similar_to_default: -0.7821
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.9264
--------------------------------------------------------------------------------
                   Total timesteps: 391680
                    Iteration time: 0.16s
                        Total time: 42.07s
                               ETA: 40.6s

################################################################################
                      [1m Learning iteration 255/500 [0m

                       Computation: 9459 steps/s (collection: 0.133s, learning 0.030s)
               Value function loss: 0.0588
                    Surrogate loss: -0.0083
             Mean action noise std: 1.02
                 Mean total reward: 167.01
               Mean episode length: 633.57
 Mean episode rew_tracking_lin_vel: 0.3656
 Mean episode rew_tracking_ang_vel: 0.1712
        Mean episode rew_lin_vel_z: -0.0244
      Mean episode rew_base_height: -2.2544
      Mean episode rew_action_rate: -0.1510
Mean episode rew_similar_to_default: -0.7825
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.9480
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 0.16s
                        Total time: 42.23s
                               ETA: 40.4s

################################################################################
                      [1m Learning iteration 256/500 [0m

                       Computation: 9522 steps/s (collection: 0.133s, learning 0.028s)
               Value function loss: 0.0595
                    Surrogate loss: -0.0077
             Mean action noise std: 1.02
                 Mean total reward: 167.01
               Mean episode length: 633.57
 Mean episode rew_tracking_lin_vel: 0.3656
 Mean episode rew_tracking_ang_vel: 0.1712
        Mean episode rew_lin_vel_z: -0.0244
      Mean episode rew_base_height: -2.2544
      Mean episode rew_action_rate: -0.1510
Mean episode rew_similar_to_default: -0.7825
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.9480
--------------------------------------------------------------------------------
                   Total timesteps: 394752
                    Iteration time: 0.16s
                        Total time: 42.40s
                               ETA: 40.3s

################################################################################
                      [1m Learning iteration 257/500 [0m

                       Computation: 8679 steps/s (collection: 0.148s, learning 0.029s)
               Value function loss: 2.8151
                    Surrogate loss: -0.0041
             Mean action noise std: 1.02
                 Mean total reward: 167.68
               Mean episode length: 635.86
 Mean episode rew_tracking_lin_vel: 0.3180
 Mean episode rew_tracking_ang_vel: 0.1493
        Mean episode rew_lin_vel_z: -0.0236
      Mean episode rew_base_height: -1.9669
      Mean episode rew_action_rate: -0.1307
Mean episode rew_similar_to_default: -0.6821
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.9487
--------------------------------------------------------------------------------
                   Total timesteps: 396288
                    Iteration time: 0.18s
                        Total time: 42.57s
                               ETA: 40.1s

################################################################################
                      [1m Learning iteration 258/500 [0m

                       Computation: 8754 steps/s (collection: 0.147s, learning 0.029s)
               Value function loss: 0.0750
                    Surrogate loss: -0.0073
             Mean action noise std: 1.02
                 Mean total reward: 170.52
               Mean episode length: 646.37
 Mean episode rew_tracking_lin_vel: 0.3103
 Mean episode rew_tracking_ang_vel: 0.1459
        Mean episode rew_lin_vel_z: -0.0241
      Mean episode rew_base_height: -1.9169
      Mean episode rew_action_rate: -0.1269
Mean episode rew_similar_to_default: -0.6645
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.6282
--------------------------------------------------------------------------------
                   Total timesteps: 397824
                    Iteration time: 0.18s
                        Total time: 42.75s
                               ETA: 39.9s

################################################################################
                      [1m Learning iteration 259/500 [0m

                       Computation: 8296 steps/s (collection: 0.152s, learning 0.033s)
               Value function loss: 3.0891
                    Surrogate loss: -0.0045
             Mean action noise std: 1.02
                 Mean total reward: 171.02
               Mean episode length: 648.36
 Mean episode rew_tracking_lin_vel: 0.2063
 Mean episode rew_tracking_ang_vel: 0.0963
        Mean episode rew_lin_vel_z: -0.0206
      Mean episode rew_base_height: -1.2685
      Mean episode rew_action_rate: -0.0848
Mean episode rew_similar_to_default: -0.4413
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.0652
--------------------------------------------------------------------------------
                   Total timesteps: 399360
                    Iteration time: 0.19s
                        Total time: 42.93s
                               ETA: 39.8s

################################################################################
                      [1m Learning iteration 260/500 [0m

                       Computation: 8825 steps/s (collection: 0.144s, learning 0.030s)
               Value function loss: 5.4920
                    Surrogate loss: 0.0001
             Mean action noise std: 1.02
                 Mean total reward: 171.41
               Mean episode length: 649.36
 Mean episode rew_tracking_lin_vel: 0.1389
 Mean episode rew_tracking_ang_vel: 0.0626
        Mean episode rew_lin_vel_z: -0.0218
      Mean episode rew_base_height: -0.8443
      Mean episode rew_action_rate: -0.0582
Mean episode rew_similar_to_default: -0.2930
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.1454
--------------------------------------------------------------------------------
                   Total timesteps: 400896
                    Iteration time: 0.17s
                        Total time: 43.11s
                               ETA: 39.6s

################################################################################
                      [1m Learning iteration 261/500 [0m

                       Computation: 8556 steps/s (collection: 0.148s, learning 0.032s)
               Value function loss: 1.4613
                    Surrogate loss: -0.0046
             Mean action noise std: 1.02
                 Mean total reward: 171.00
               Mean episode length: 647.60
 Mean episode rew_tracking_lin_vel: 0.3052
 Mean episode rew_tracking_ang_vel: 0.1424
        Mean episode rew_lin_vel_z: -0.0241
      Mean episode rew_base_height: -1.8760
      Mean episode rew_action_rate: -0.1260
Mean episode rew_similar_to_default: -0.6523
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.2667
--------------------------------------------------------------------------------
                   Total timesteps: 402432
                    Iteration time: 0.18s
                        Total time: 43.29s
                               ETA: 39.5s

################################################################################
                      [1m Learning iteration 262/500 [0m

                       Computation: 8382 steps/s (collection: 0.151s, learning 0.032s)
               Value function loss: 0.0879
                    Surrogate loss: -0.0086
             Mean action noise std: 1.02
                 Mean total reward: 171.01
               Mean episode length: 647.60
 Mean episode rew_tracking_lin_vel: 0.3562
 Mean episode rew_tracking_ang_vel: 0.1674
        Mean episode rew_lin_vel_z: -0.0270
      Mean episode rew_base_height: -2.2177
      Mean episode rew_action_rate: -0.1471
Mean episode rew_similar_to_default: -0.7681
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.6772
--------------------------------------------------------------------------------
                   Total timesteps: 403968
                    Iteration time: 0.18s
                        Total time: 43.47s
                               ETA: 39.3s

################################################################################
                      [1m Learning iteration 263/500 [0m

                       Computation: 8228 steps/s (collection: 0.157s, learning 0.030s)
               Value function loss: 3.8010
                    Surrogate loss: -0.0022
             Mean action noise std: 1.02
                 Mean total reward: 170.77
               Mean episode length: 646.22
 Mean episode rew_tracking_lin_vel: 0.2839
 Mean episode rew_tracking_ang_vel: 0.1339
        Mean episode rew_lin_vel_z: -0.0214
      Mean episode rew_base_height: -1.7570
      Mean episode rew_action_rate: -0.1184
Mean episode rew_similar_to_default: -0.6078
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.4339
--------------------------------------------------------------------------------
                   Total timesteps: 405504
                    Iteration time: 0.19s
                        Total time: 43.66s
                               ETA: 39.2s

################################################################################
                      [1m Learning iteration 264/500 [0m

                       Computation: 9384 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 0.0805
                    Surrogate loss: -0.0081
             Mean action noise std: 1.02
                 Mean total reward: 170.78
               Mean episode length: 646.22
 Mean episode rew_tracking_lin_vel: 0.3628
 Mean episode rew_tracking_ang_vel: 0.1711
        Mean episode rew_lin_vel_z: -0.0244
      Mean episode rew_base_height: -2.2650
      Mean episode rew_action_rate: -0.1512
Mean episode rew_similar_to_default: -0.7822
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.9251
--------------------------------------------------------------------------------
                   Total timesteps: 407040
                    Iteration time: 0.16s
                        Total time: 43.82s
                               ETA: 39.0s

################################################################################
                      [1m Learning iteration 265/500 [0m

                       Computation: 9342 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 2.4688
                    Surrogate loss: -0.0034
             Mean action noise std: 1.02
                 Mean total reward: 171.07
               Mean episode length: 647.30
 Mean episode rew_tracking_lin_vel: 0.1729
 Mean episode rew_tracking_ang_vel: 0.0813
        Mean episode rew_lin_vel_z: -0.0220
      Mean episode rew_base_height: -1.0693
      Mean episode rew_action_rate: -0.0691
Mean episode rew_similar_to_default: -0.3707
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.4967
--------------------------------------------------------------------------------
                   Total timesteps: 408576
                    Iteration time: 0.16s
                        Total time: 43.98s
                               ETA: 38.9s

################################################################################
                      [1m Learning iteration 266/500 [0m

                       Computation: 9363 steps/s (collection: 0.135s, learning 0.029s)
               Value function loss: 3.3352
                    Surrogate loss: -0.0025
             Mean action noise std: 1.02
                 Mean total reward: 168.16
               Mean episode length: 636.15
 Mean episode rew_tracking_lin_vel: 0.0939
 Mean episode rew_tracking_ang_vel: 0.0450
        Mean episode rew_lin_vel_z: -0.0162
      Mean episode rew_base_height: -0.5742
      Mean episode rew_action_rate: -0.0395
Mean episode rew_similar_to_default: -0.1997
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.1645
--------------------------------------------------------------------------------
                   Total timesteps: 410112
                    Iteration time: 0.16s
                        Total time: 44.15s
                               ETA: 38.7s

################################################################################
                      [1m Learning iteration 267/500 [0m

                       Computation: 9287 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 3.0743
                    Surrogate loss: -0.0015
             Mean action noise std: 1.02
                 Mean total reward: 169.69
               Mean episode length: 641.32
 Mean episode rew_tracking_lin_vel: 0.1642
 Mean episode rew_tracking_ang_vel: 0.0771
        Mean episode rew_lin_vel_z: -0.0190
      Mean episode rew_base_height: -1.0094
      Mean episode rew_action_rate: -0.0695
Mean episode rew_similar_to_default: -0.3510
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.3002
--------------------------------------------------------------------------------
                   Total timesteps: 411648
                    Iteration time: 0.17s
                        Total time: 44.31s
                               ETA: 38.5s

################################################################################
                      [1m Learning iteration 268/500 [0m

                       Computation: 9014 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 9.9054
                    Surrogate loss: -0.0007
             Mean action noise std: 1.02
                 Mean total reward: 173.65
               Mean episode length: 655.61
 Mean episode rew_tracking_lin_vel: 0.2462
 Mean episode rew_tracking_ang_vel: 0.1150
        Mean episode rew_lin_vel_z: -0.0223
      Mean episode rew_base_height: -1.5257
      Mean episode rew_action_rate: -0.1051
Mean episode rew_similar_to_default: -0.5275
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.9219
--------------------------------------------------------------------------------
                   Total timesteps: 413184
                    Iteration time: 0.17s
                        Total time: 44.48s
                               ETA: 38.4s

################################################################################
                      [1m Learning iteration 269/500 [0m

                       Computation: 8947 steps/s (collection: 0.142s, learning 0.030s)
               Value function loss: 9.7229
                    Surrogate loss: -0.0012
             Mean action noise std: 1.02
                 Mean total reward: 170.44
               Mean episode length: 642.24
 Mean episode rew_tracking_lin_vel: 0.2914
 Mean episode rew_tracking_ang_vel: 0.1368
        Mean episode rew_lin_vel_z: -0.0232
      Mean episode rew_base_height: -1.8165
      Mean episode rew_action_rate: -0.1247
Mean episode rew_similar_to_default: -0.6275
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.0501
--------------------------------------------------------------------------------
                   Total timesteps: 414720
                    Iteration time: 0.17s
                        Total time: 44.66s
                               ETA: 38.2s

################################################################################
                      [1m Learning iteration 270/500 [0m

                       Computation: 9271 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 6.9206
                    Surrogate loss: -0.0079
             Mean action noise std: 1.02
                 Mean total reward: 169.77
               Mean episode length: 639.61
 Mean episode rew_tracking_lin_vel: 0.0839
 Mean episode rew_tracking_ang_vel: 0.0389
        Mean episode rew_lin_vel_z: -0.0211
      Mean episode rew_base_height: -0.5077
      Mean episode rew_action_rate: -0.0358
Mean episode rew_similar_to_default: -0.1760
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7271
--------------------------------------------------------------------------------
                   Total timesteps: 416256
                    Iteration time: 0.17s
                        Total time: 44.82s
                               ETA: 38.0s

################################################################################
                      [1m Learning iteration 271/500 [0m

                       Computation: 9264 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 2.9534
                    Surrogate loss: -0.0074
             Mean action noise std: 1.02
                 Mean total reward: 167.68
               Mean episode length: 631.63
 Mean episode rew_tracking_lin_vel: 0.1904
 Mean episode rew_tracking_ang_vel: 0.0894
        Mean episode rew_lin_vel_z: -0.0232
      Mean episode rew_base_height: -1.1801
      Mean episode rew_action_rate: -0.0798
Mean episode rew_similar_to_default: -0.4079
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.2978
--------------------------------------------------------------------------------
                   Total timesteps: 417792
                    Iteration time: 0.17s
                        Total time: 44.99s
                               ETA: 37.9s

################################################################################
                      [1m Learning iteration 272/500 [0m

                       Computation: 9264 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 5.4350
                    Surrogate loss: -0.0049
             Mean action noise std: 1.02
                 Mean total reward: 168.24
               Mean episode length: 633.72
 Mean episode rew_tracking_lin_vel: 0.0681
 Mean episode rew_tracking_ang_vel: 0.0322
        Mean episode rew_lin_vel_z: -0.0131
      Mean episode rew_base_height: -0.4083
      Mean episode rew_action_rate: -0.0298
Mean episode rew_similar_to_default: -0.1427
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.9475
--------------------------------------------------------------------------------
                   Total timesteps: 419328
                    Iteration time: 0.17s
                        Total time: 45.15s
                               ETA: 37.7s

################################################################################
                      [1m Learning iteration 273/500 [0m

                       Computation: 9278 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 2.8780
                    Surrogate loss: -0.0047
             Mean action noise std: 1.02
                 Mean total reward: 166.23
               Mean episode length: 626.07
 Mean episode rew_tracking_lin_vel: 0.0626
 Mean episode rew_tracking_ang_vel: 0.0293
        Mean episode rew_lin_vel_z: -0.0172
      Mean episode rew_base_height: -0.3730
      Mean episode rew_action_rate: -0.0275
Mean episode rew_similar_to_default: -0.1292
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.7730
--------------------------------------------------------------------------------
                   Total timesteps: 420864
                    Iteration time: 0.17s
                        Total time: 45.32s
                               ETA: 37.5s

################################################################################
                      [1m Learning iteration 274/500 [0m

                       Computation: 9196 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 7.9596
                    Surrogate loss: -0.0061
             Mean action noise std: 1.02
                 Mean total reward: 162.00
               Mean episode length: 610.16
 Mean episode rew_tracking_lin_vel: 0.1373
 Mean episode rew_tracking_ang_vel: 0.0638
        Mean episode rew_lin_vel_z: -0.0197
      Mean episode rew_base_height: -0.8458
      Mean episode rew_action_rate: -0.0588
Mean episode rew_similar_to_default: -0.2914
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.0765
--------------------------------------------------------------------------------
                   Total timesteps: 422400
                    Iteration time: 0.17s
                        Total time: 45.49s
                               ETA: 37.4s

################################################################################
                      [1m Learning iteration 275/500 [0m

                       Computation: 9516 steps/s (collection: 0.133s, learning 0.028s)
               Value function loss: 3.6568
                    Surrogate loss: -0.0008
             Mean action noise std: 1.02
                 Mean total reward: 164.64
               Mean episode length: 619.74
 Mean episode rew_tracking_lin_vel: 0.3611
 Mean episode rew_tracking_ang_vel: 0.1693
        Mean episode rew_lin_vel_z: -0.0197
      Mean episode rew_base_height: -2.2569
      Mean episode rew_action_rate: -0.1534
Mean episode rew_similar_to_default: -0.7774
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.1220
--------------------------------------------------------------------------------
                   Total timesteps: 423936
                    Iteration time: 0.16s
                        Total time: 45.65s
                               ETA: 37.2s

################################################################################
                      [1m Learning iteration 276/500 [0m

                       Computation: 9252 steps/s (collection: 0.137s, learning 0.029s)
               Value function loss: 12.3050
                    Surrogate loss: -0.0037
             Mean action noise std: 1.02
                 Mean total reward: 161.83
               Mean episode length: 608.33
 Mean episode rew_tracking_lin_vel: 0.2455
 Mean episode rew_tracking_ang_vel: 0.1151
        Mean episode rew_lin_vel_z: -0.0218
      Mean episode rew_base_height: -1.5271
      Mean episode rew_action_rate: -0.1059
Mean episode rew_similar_to_default: -0.5273
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.9909
--------------------------------------------------------------------------------
                   Total timesteps: 425472
                    Iteration time: 0.17s
                        Total time: 45.81s
                               ETA: 37.0s

################################################################################
                      [1m Learning iteration 277/500 [0m

                       Computation: 9502 steps/s (collection: 0.134s, learning 0.028s)
               Value function loss: 5.6686
                    Surrogate loss: 0.0014
             Mean action noise std: 1.02
                 Mean total reward: 160.18
               Mean episode length: 601.77
 Mean episode rew_tracking_lin_vel: 0.0961
 Mean episode rew_tracking_ang_vel: 0.0442
        Mean episode rew_lin_vel_z: -0.0178
      Mean episode rew_base_height: -0.5811
      Mean episode rew_action_rate: -0.0424
Mean episode rew_similar_to_default: -0.2017
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.2485
--------------------------------------------------------------------------------
                   Total timesteps: 427008
                    Iteration time: 0.16s
                        Total time: 45.97s
                               ETA: 36.9s

################################################################################
                      [1m Learning iteration 278/500 [0m

                       Computation: 9181 steps/s (collection: 0.139s, learning 0.029s)
               Value function loss: 5.5826
                    Surrogate loss: -0.0080
             Mean action noise std: 1.02
                 Mean total reward: 162.06
               Mean episode length: 608.32
 Mean episode rew_tracking_lin_vel: 0.1136
 Mean episode rew_tracking_ang_vel: 0.0532
        Mean episode rew_lin_vel_z: -0.0165
      Mean episode rew_base_height: -0.6965
      Mean episode rew_action_rate: -0.0484
Mean episode rew_similar_to_default: -0.2393
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.0375
--------------------------------------------------------------------------------
                   Total timesteps: 428544
                    Iteration time: 0.17s
                        Total time: 46.14s
                               ETA: 36.7s

################################################################################
                      [1m Learning iteration 279/500 [0m

                       Computation: 9431 steps/s (collection: 0.136s, learning 0.027s)
               Value function loss: 6.8191
                    Surrogate loss: -0.0049
             Mean action noise std: 1.02
                 Mean total reward: 162.10
               Mean episode length: 608.54
 Mean episode rew_tracking_lin_vel: 0.1302
 Mean episode rew_tracking_ang_vel: 0.0609
        Mean episode rew_lin_vel_z: -0.0185
      Mean episode rew_base_height: -0.8002
      Mean episode rew_action_rate: -0.0569
Mean episode rew_similar_to_default: -0.2741
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.8765
--------------------------------------------------------------------------------
                   Total timesteps: 430080
                    Iteration time: 0.16s
                        Total time: 46.31s
                               ETA: 36.5s

################################################################################
                      [1m Learning iteration 280/500 [0m

                       Computation: 9448 steps/s (collection: 0.135s, learning 0.027s)
               Value function loss: 2.7585
                    Surrogate loss: -0.0086
             Mean action noise std: 1.02
                 Mean total reward: 160.50
               Mean episode length: 602.30
 Mean episode rew_tracking_lin_vel: 0.1235
 Mean episode rew_tracking_ang_vel: 0.0572
        Mean episode rew_lin_vel_z: -0.0227
      Mean episode rew_base_height: -0.7420
      Mean episode rew_action_rate: -0.0547
Mean episode rew_similar_to_default: -0.2527
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.5357
--------------------------------------------------------------------------------
                   Total timesteps: 431616
                    Iteration time: 0.16s
                        Total time: 46.47s
                               ETA: 36.4s

################################################################################
                      [1m Learning iteration 281/500 [0m

                       Computation: 9358 steps/s (collection: 0.137s, learning 0.027s)
               Value function loss: 9.4622
                    Surrogate loss: -0.0020
             Mean action noise std: 1.02
                 Mean total reward: 159.14
               Mean episode length: 596.13
 Mean episode rew_tracking_lin_vel: 0.0887
 Mean episode rew_tracking_ang_vel: 0.0412
        Mean episode rew_lin_vel_z: -0.0173
      Mean episode rew_base_height: -0.5392
      Mean episode rew_action_rate: -0.0397
Mean episode rew_similar_to_default: -0.1851
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.9923
--------------------------------------------------------------------------------
                   Total timesteps: 433152
                    Iteration time: 0.16s
                        Total time: 46.63s
                               ETA: 36.2s

################################################################################
                      [1m Learning iteration 282/500 [0m

                       Computation: 9395 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 4.4733
                    Surrogate loss: -0.0049
             Mean action noise std: 1.02
                 Mean total reward: 156.21
               Mean episode length: 584.84
 Mean episode rew_tracking_lin_vel: 0.1305
 Mean episode rew_tracking_ang_vel: 0.0588
        Mean episode rew_lin_vel_z: -0.0175
      Mean episode rew_base_height: -0.7774
      Mean episode rew_action_rate: -0.0580
Mean episode rew_similar_to_default: -0.2658
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.6950
--------------------------------------------------------------------------------
                   Total timesteps: 434688
                    Iteration time: 0.16s
                        Total time: 46.80s
                               ETA: 36.0s

################################################################################
                      [1m Learning iteration 283/500 [0m

                       Computation: 9362 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 0.1073
                    Surrogate loss: -0.0086
             Mean action noise std: 1.02
                 Mean total reward: 156.24
               Mean episode length: 584.84
 Mean episode rew_tracking_lin_vel: 0.3414
 Mean episode rew_tracking_ang_vel: 0.1603
        Mean episode rew_lin_vel_z: -0.0254
      Mean episode rew_base_height: -2.1372
      Mean episode rew_action_rate: -0.1488
Mean episode rew_similar_to_default: -0.7335
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.2943
--------------------------------------------------------------------------------
                   Total timesteps: 436224
                    Iteration time: 0.16s
                        Total time: 46.96s
                               ETA: 35.9s

################################################################################
                      [1m Learning iteration 284/500 [0m

                       Computation: 9240 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 3.2778
                    Surrogate loss: -0.0002
             Mean action noise std: 1.02
                 Mean total reward: 154.77
               Mean episode length: 579.22
 Mean episode rew_tracking_lin_vel: 0.0967
 Mean episode rew_tracking_ang_vel: 0.0449
        Mean episode rew_lin_vel_z: -0.0229
      Mean episode rew_base_height: -0.5815
      Mean episode rew_action_rate: -0.0431
Mean episode rew_similar_to_default: -0.2005
Mean episode rew_joint_pose_matching: 0.0018
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.3367
--------------------------------------------------------------------------------
                   Total timesteps: 437760
                    Iteration time: 0.17s
                        Total time: 47.13s
                               ETA: 35.7s

################################################################################
                      [1m Learning iteration 285/500 [0m

                       Computation: 9039 steps/s (collection: 0.138s, learning 0.032s)
               Value function loss: 4.5458
                    Surrogate loss: -0.0065
             Mean action noise std: 1.02
                 Mean total reward: 158.16
               Mean episode length: 591.73
 Mean episode rew_tracking_lin_vel: 0.1786
 Mean episode rew_tracking_ang_vel: 0.0828
        Mean episode rew_lin_vel_z: -0.0196
      Mean episode rew_base_height: -1.0993
      Mean episode rew_action_rate: -0.0772
Mean episode rew_similar_to_default: -0.3782
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.9685
--------------------------------------------------------------------------------
                   Total timesteps: 439296
                    Iteration time: 0.17s
                        Total time: 47.30s
                               ETA: 35.6s

################################################################################
                      [1m Learning iteration 286/500 [0m

                       Computation: 9307 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 3.0836
                    Surrogate loss: -0.0037
             Mean action noise std: 1.02
                 Mean total reward: 158.32
               Mean episode length: 592.15
 Mean episode rew_tracking_lin_vel: 0.0415
 Mean episode rew_tracking_ang_vel: 0.0199
        Mean episode rew_lin_vel_z: -0.0144
      Mean episode rew_base_height: -0.2473
      Mean episode rew_action_rate: -0.0187
Mean episode rew_similar_to_default: -0.0856
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 1.8772
--------------------------------------------------------------------------------
                   Total timesteps: 440832
                    Iteration time: 0.17s
                        Total time: 47.46s
                               ETA: 35.4s

################################################################################
                      [1m Learning iteration 287/500 [0m

                       Computation: 9298 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 4.3619
                    Surrogate loss: -0.0085
             Mean action noise std: 1.02
                 Mean total reward: 157.26
               Mean episode length: 587.96
 Mean episode rew_tracking_lin_vel: 0.0860
 Mean episode rew_tracking_ang_vel: 0.0406
        Mean episode rew_lin_vel_z: -0.0208
      Mean episode rew_base_height: -0.5103
      Mean episode rew_action_rate: -0.0380
Mean episode rew_similar_to_default: -0.1744
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7919
--------------------------------------------------------------------------------
                   Total timesteps: 442368
                    Iteration time: 0.17s
                        Total time: 47.63s
                               ETA: 35.2s

################################################################################
                      [1m Learning iteration 288/500 [0m

                       Computation: 9178 steps/s (collection: 0.139s, learning 0.028s)
               Value function loss: 6.3313
                    Surrogate loss: -0.0090
             Mean action noise std: 1.02
                 Mean total reward: 156.09
               Mean episode length: 583.29
 Mean episode rew_tracking_lin_vel: 0.2172
 Mean episode rew_tracking_ang_vel: 0.1023
        Mean episode rew_lin_vel_z: -0.0226
      Mean episode rew_base_height: -1.3544
      Mean episode rew_action_rate: -0.0967
Mean episode rew_similar_to_default: -0.4634
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.6698
--------------------------------------------------------------------------------
                   Total timesteps: 443904
                    Iteration time: 0.17s
                        Total time: 47.79s
                               ETA: 35.1s

################################################################################
                      [1m Learning iteration 289/500 [0m

                       Computation: 9456 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 3.1446
                    Surrogate loss: -0.0079
             Mean action noise std: 1.02
                 Mean total reward: 154.58
               Mean episode length: 577.05
 Mean episode rew_tracking_lin_vel: 0.2190
 Mean episode rew_tracking_ang_vel: 0.1009
        Mean episode rew_lin_vel_z: -0.0197
      Mean episode rew_base_height: -1.3547
      Mean episode rew_action_rate: -0.0970
Mean episode rew_similar_to_default: -0.4658
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.9528
--------------------------------------------------------------------------------
                   Total timesteps: 445440
                    Iteration time: 0.16s
                        Total time: 47.96s
                               ETA: 34.9s

################################################################################
                      [1m Learning iteration 290/500 [0m

                       Computation: 9526 steps/s (collection: 0.134s, learning 0.027s)
               Value function loss: 3.8067
                    Surrogate loss: -0.0025
             Mean action noise std: 1.02
                 Mean total reward: 154.13
               Mean episode length: 575.28
 Mean episode rew_tracking_lin_vel: 0.0797
 Mean episode rew_tracking_ang_vel: 0.0355
        Mean episode rew_lin_vel_z: -0.0210
      Mean episode rew_base_height: -0.4727
      Mean episode rew_action_rate: -0.0369
Mean episode rew_similar_to_default: -0.1628
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.5397
--------------------------------------------------------------------------------
                   Total timesteps: 446976
                    Iteration time: 0.16s
                        Total time: 48.12s
                               ETA: 34.7s

################################################################################
                      [1m Learning iteration 291/500 [0m

                       Computation: 9338 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 3.5748
                    Surrogate loss: -0.0079
             Mean action noise std: 1.02
                 Mean total reward: 152.35
               Mean episode length: 567.78
 Mean episode rew_tracking_lin_vel: 0.3170
 Mean episode rew_tracking_ang_vel: 0.1460
        Mean episode rew_lin_vel_z: -0.0214
      Mean episode rew_base_height: -1.9655
      Mean episode rew_action_rate: -0.1375
Mean episode rew_similar_to_default: -0.6701
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.2215
--------------------------------------------------------------------------------
                   Total timesteps: 448512
                    Iteration time: 0.16s
                        Total time: 48.28s
                               ETA: 34.6s

################################################################################
                      [1m Learning iteration 292/500 [0m

                       Computation: 9396 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 3.3583
                    Surrogate loss: -0.0045
             Mean action noise std: 1.02
                 Mean total reward: 149.75
               Mean episode length: 557.89
 Mean episode rew_tracking_lin_vel: 0.2129
 Mean episode rew_tracking_ang_vel: 0.1000
        Mean episode rew_lin_vel_z: -0.0224
      Mean episode rew_base_height: -1.3215
      Mean episode rew_action_rate: -0.0967
Mean episode rew_similar_to_default: -0.4517
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.5433
--------------------------------------------------------------------------------
                   Total timesteps: 450048
                    Iteration time: 0.16s
                        Total time: 48.44s
                               ETA: 34.4s

################################################################################
                      [1m Learning iteration 293/500 [0m

                       Computation: 9547 steps/s (collection: 0.132s, learning 0.029s)
               Value function loss: 0.0419
                    Surrogate loss: -0.0071
             Mean action noise std: 1.02
                 Mean total reward: 149.75
               Mean episode length: 557.89
 Mean episode rew_tracking_lin_vel: 0.1827
 Mean episode rew_tracking_ang_vel: 0.0860
        Mean episode rew_lin_vel_z: -0.0221
      Mean episode rew_base_height: -1.1338
      Mean episode rew_action_rate: -0.0835
Mean episode rew_similar_to_default: -0.3864
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.1709
--------------------------------------------------------------------------------
                   Total timesteps: 451584
                    Iteration time: 0.16s
                        Total time: 48.61s
                               ETA: 34.2s

################################################################################
                      [1m Learning iteration 294/500 [0m

                       Computation: 9280 steps/s (collection: 0.138s, learning 0.027s)
               Value function loss: 0.0633
                    Surrogate loss: -0.0049
             Mean action noise std: 1.02
                 Mean total reward: 153.51
               Mean episode length: 571.78
 Mean episode rew_tracking_lin_vel: 0.3387
 Mean episode rew_tracking_ang_vel: 0.1587
        Mean episode rew_lin_vel_z: -0.0240
      Mean episode rew_base_height: -2.1191
      Mean episode rew_action_rate: -0.1488
Mean episode rew_similar_to_default: -0.7212
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.1362
--------------------------------------------------------------------------------
                   Total timesteps: 453120
                    Iteration time: 0.17s
                        Total time: 48.77s
                               ETA: 34.1s

################################################################################
                      [1m Learning iteration 295/500 [0m

                       Computation: 9294 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 0.0515
                    Surrogate loss: -0.0055
             Mean action noise std: 1.02
                 Mean total reward: 154.34
               Mean episode length: 574.66
 Mean episode rew_tracking_lin_vel: 0.3637
 Mean episode rew_tracking_ang_vel: 0.1690
        Mean episode rew_lin_vel_z: -0.0220
      Mean episode rew_base_height: -2.2606
      Mean episode rew_action_rate: -0.1562
Mean episode rew_similar_to_default: -0.7721
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.2561
--------------------------------------------------------------------------------
                   Total timesteps: 454656
                    Iteration time: 0.17s
                        Total time: 48.94s
                               ETA: 33.9s

################################################################################
                      [1m Learning iteration 296/500 [0m

                       Computation: 8789 steps/s (collection: 0.142s, learning 0.033s)
               Value function loss: 10.0097
                    Surrogate loss: 0.0050
             Mean action noise std: 1.02
                 Mean total reward: 150.72
               Mean episode length: 561.14
 Mean episode rew_tracking_lin_vel: 0.2573
 Mean episode rew_tracking_ang_vel: 0.1222
        Mean episode rew_lin_vel_z: -0.0216
      Mean episode rew_base_height: -1.6004
      Mean episode rew_action_rate: -0.1117
Mean episode rew_similar_to_default: -0.5437
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.3957
--------------------------------------------------------------------------------
                   Total timesteps: 456192
                    Iteration time: 0.17s
                        Total time: 49.11s
                               ETA: 33.7s

################################################################################
                      [1m Learning iteration 297/500 [0m

                       Computation: 9045 steps/s (collection: 0.141s, learning 0.029s)
               Value function loss: 4.6296
                    Surrogate loss: -0.0091
             Mean action noise std: 1.02
                 Mean total reward: 147.14
               Mean episode length: 547.46
 Mean episode rew_tracking_lin_vel: 0.1958
 Mean episode rew_tracking_ang_vel: 0.0904
        Mean episode rew_lin_vel_z: -0.0212
      Mean episode rew_base_height: -1.1845
      Mean episode rew_action_rate: -0.0864
Mean episode rew_similar_to_default: -0.4053
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.5671
--------------------------------------------------------------------------------
                   Total timesteps: 457728
                    Iteration time: 0.17s
                        Total time: 49.28s
                               ETA: 33.6s

################################################################################
                      [1m Learning iteration 298/500 [0m

                       Computation: 9325 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 0.4661
                    Surrogate loss: -0.0037
             Mean action noise std: 1.02
                 Mean total reward: 145.09
               Mean episode length: 539.68
 Mean episode rew_tracking_lin_vel: 0.0793
 Mean episode rew_tracking_ang_vel: 0.0368
        Mean episode rew_lin_vel_z: -0.0194
      Mean episode rew_base_height: -0.4717
      Mean episode rew_action_rate: -0.0379
Mean episode rew_similar_to_default: -0.1621
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.5740
--------------------------------------------------------------------------------
                   Total timesteps: 459264
                    Iteration time: 0.16s
                        Total time: 49.45s
                               ETA: 33.4s

################################################################################
                      [1m Learning iteration 299/500 [0m

                       Computation: 9168 steps/s (collection: 0.138s, learning 0.030s)
               Value function loss: 0.0728
                    Surrogate loss: -0.0093
             Mean action noise std: 1.02
                 Mean total reward: 147.35
               Mean episode length: 548.08
 Mean episode rew_tracking_lin_vel: 0.3044
 Mean episode rew_tracking_ang_vel: 0.1400
        Mean episode rew_lin_vel_z: -0.0201
      Mean episode rew_base_height: -1.8940
      Mean episode rew_action_rate: -0.1364
Mean episode rew_similar_to_default: -0.6426
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0007
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.3862
--------------------------------------------------------------------------------
                   Total timesteps: 460800
                    Iteration time: 0.17s
                        Total time: 49.61s
                               ETA: 33.2s

################################################################################
                      [1m Learning iteration 300/500 [0m

                       Computation: 8936 steps/s (collection: 0.141s, learning 0.031s)
               Value function loss: 5.0157
                    Surrogate loss: -0.0006
             Mean action noise std: 1.02
                 Mean total reward: 150.07
               Mean episode length: 558.16
 Mean episode rew_tracking_lin_vel: 0.3314
 Mean episode rew_tracking_ang_vel: 0.1548
        Mean episode rew_lin_vel_z: -0.0226
      Mean episode rew_base_height: -2.0631
      Mean episode rew_action_rate: -0.1490
Mean episode rew_similar_to_default: -0.6995
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.6588
--------------------------------------------------------------------------------
                   Total timesteps: 462336
                    Iteration time: 0.17s
                        Total time: 49.78s
                               ETA: 33.1s

################################################################################
                      [1m Learning iteration 301/500 [0m

                       Computation: 8332 steps/s (collection: 0.152s, learning 0.032s)
               Value function loss: 0.1130
                    Surrogate loss: -0.0034
             Mean action noise std: 1.02
                 Mean total reward: 150.07
               Mean episode length: 558.16
 Mean episode rew_tracking_lin_vel: 0.3631
 Mean episode rew_tracking_ang_vel: 0.1716
        Mean episode rew_lin_vel_z: -0.0251
      Mean episode rew_base_height: -2.2648
      Mean episode rew_action_rate: -0.1651
Mean episode rew_similar_to_default: -0.7690
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.1066
--------------------------------------------------------------------------------
                   Total timesteps: 463872
                    Iteration time: 0.18s
                        Total time: 49.97s
                               ETA: 32.9s

################################################################################
                      [1m Learning iteration 302/500 [0m

                       Computation: 8964 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 2.4625
                    Surrogate loss: -0.0044
             Mean action noise std: 1.02
                 Mean total reward: 149.14
               Mean episode length: 554.35
 Mean episode rew_tracking_lin_vel: 0.1644
 Mean episode rew_tracking_ang_vel: 0.0780
        Mean episode rew_lin_vel_z: -0.0226
      Mean episode rew_base_height: -1.0116
      Mean episode rew_action_rate: -0.0736
Mean episode rew_similar_to_default: -0.3420
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.3313
--------------------------------------------------------------------------------
                   Total timesteps: 465408
                    Iteration time: 0.17s
                        Total time: 50.14s
                               ETA: 32.8s

################################################################################
                      [1m Learning iteration 303/500 [0m

                       Computation: 9269 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 0.0529
                    Surrogate loss: 0.0010
             Mean action noise std: 1.02
                 Mean total reward: 149.14
               Mean episode length: 554.35
 Mean episode rew_tracking_lin_vel: 0.0958
 Mean episode rew_tracking_ang_vel: 0.0458
        Mean episode rew_lin_vel_z: -0.0216
      Mean episode rew_base_height: -0.5775
      Mean episode rew_action_rate: -0.0439
Mean episode rew_similar_to_default: -0.1948
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.2152
--------------------------------------------------------------------------------
                   Total timesteps: 466944
                    Iteration time: 0.17s
                        Total time: 50.31s
                               ETA: 32.6s

################################################################################
                      [1m Learning iteration 304/500 [0m

                       Computation: 9427 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 0.0409
                    Surrogate loss: -0.0026
             Mean action noise std: 1.02
                 Mean total reward: 149.14
               Mean episode length: 554.35
 Mean episode rew_tracking_lin_vel: 0.0958
 Mean episode rew_tracking_ang_vel: 0.0458
        Mean episode rew_lin_vel_z: -0.0216
      Mean episode rew_base_height: -0.5775
      Mean episode rew_action_rate: -0.0439
Mean episode rew_similar_to_default: -0.1948
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.2152
--------------------------------------------------------------------------------
                   Total timesteps: 468480
                    Iteration time: 0.16s
                        Total time: 50.47s
                               ETA: 32.4s

################################################################################
                      [1m Learning iteration 305/500 [0m

                       Computation: 8978 steps/s (collection: 0.141s, learning 0.031s)
               Value function loss: 3.0380
                    Surrogate loss: -0.0017
             Mean action noise std: 1.02
                 Mean total reward: 151.39
               Mean episode length: 562.63
 Mean episode rew_tracking_lin_vel: 0.2861
 Mean episode rew_tracking_ang_vel: 0.1371
        Mean episode rew_lin_vel_z: -0.0238
      Mean episode rew_base_height: -1.7802
      Mean episode rew_action_rate: -0.1245
Mean episode rew_similar_to_default: -0.6002
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.5575
--------------------------------------------------------------------------------
                   Total timesteps: 470016
                    Iteration time: 0.17s
                        Total time: 50.64s
                               ETA: 32.3s

################################################################################
                      [1m Learning iteration 306/500 [0m

                       Computation: 8998 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 1.6428
                    Surrogate loss: -0.0041
             Mean action noise std: 1.02
                 Mean total reward: 148.91
               Mean episode length: 553.33
 Mean episode rew_tracking_lin_vel: 0.0233
 Mean episode rew_tracking_ang_vel: 0.0110
        Mean episode rew_lin_vel_z: -0.0112
      Mean episode rew_base_height: -0.1272
      Mean episode rew_action_rate: -0.0103
Mean episode rew_similar_to_default: -0.0440
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 1.0444
--------------------------------------------------------------------------------
                   Total timesteps: 471552
                    Iteration time: 0.17s
                        Total time: 50.81s
                               ETA: 32.1s

################################################################################
                      [1m Learning iteration 307/500 [0m

                       Computation: 9393 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 2.0388
                    Surrogate loss: -0.0067
             Mean action noise std: 1.02
                 Mean total reward: 147.51
               Mean episode length: 548.27
 Mean episode rew_tracking_lin_vel: 0.0142
 Mean episode rew_tracking_ang_vel: 0.0067
        Mean episode rew_lin_vel_z: -0.0186
      Mean episode rew_base_height: -0.0682
      Mean episode rew_action_rate: -0.0063
Mean episode rew_similar_to_default: -0.0252
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.7024
--------------------------------------------------------------------------------
                   Total timesteps: 473088
                    Iteration time: 0.16s
                        Total time: 50.97s
                               ETA: 31.9s

################################################################################
                      [1m Learning iteration 308/500 [0m

                       Computation: 8787 steps/s (collection: 0.145s, learning 0.030s)
               Value function loss: 1.3598
                    Surrogate loss: -0.0066
             Mean action noise std: 1.02
                 Mean total reward: 147.46
               Mean episode length: 547.88
 Mean episode rew_tracking_lin_vel: 0.3076
 Mean episode rew_tracking_ang_vel: 0.1474
        Mean episode rew_lin_vel_z: -0.0241
      Mean episode rew_base_height: -1.9315
      Mean episode rew_action_rate: -0.1411
Mean episode rew_similar_to_default: -0.6488
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.8047
--------------------------------------------------------------------------------
                   Total timesteps: 474624
                    Iteration time: 0.17s
                        Total time: 51.15s
                               ETA: 31.8s

################################################################################
                      [1m Learning iteration 309/500 [0m

                       Computation: 9375 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 0.0504
                    Surrogate loss: -0.0062
             Mean action noise std: 1.02
                 Mean total reward: 148.68
               Mean episode length: 552.35
 Mean episode rew_tracking_lin_vel: 0.3513
 Mean episode rew_tracking_ang_vel: 0.1682
        Mean episode rew_lin_vel_z: -0.0241
      Mean episode rew_base_height: -2.2088
      Mean episode rew_action_rate: -0.1619
Mean episode rew_similar_to_default: -0.7422
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.7169
--------------------------------------------------------------------------------
                   Total timesteps: 476160
                    Iteration time: 0.16s
                        Total time: 51.31s
                               ETA: 31.6s

################################################################################
                      [1m Learning iteration 310/500 [0m

                       Computation: 9225 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 1.9677
                    Surrogate loss: -0.0032
             Mean action noise std: 1.02
                 Mean total reward: 151.02
               Mean episode length: 560.99
 Mean episode rew_tracking_lin_vel: 0.3318
 Mean episode rew_tracking_ang_vel: 0.1564
        Mean episode rew_lin_vel_z: -0.0234
      Mean episode rew_base_height: -2.0619
      Mean episode rew_action_rate: -0.1478
Mean episode rew_similar_to_default: -0.6984
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.7644
--------------------------------------------------------------------------------
                   Total timesteps: 477696
                    Iteration time: 0.17s
                        Total time: 51.48s
                               ETA: 31.5s

################################################################################
                      [1m Learning iteration 311/500 [0m

                       Computation: 9032 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 11.7304
                    Surrogate loss: 0.0039
             Mean action noise std: 1.02
                 Mean total reward: 148.87
               Mean episode length: 553.33
 Mean episode rew_tracking_lin_vel: 0.1532
 Mean episode rew_tracking_ang_vel: 0.0725
        Mean episode rew_lin_vel_z: -0.0181
      Mean episode rew_base_height: -0.9475
      Mean episode rew_action_rate: -0.0683
Mean episode rew_similar_to_default: -0.3229
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.7614
--------------------------------------------------------------------------------
                   Total timesteps: 479232
                    Iteration time: 0.17s
                        Total time: 51.65s
                               ETA: 31.3s

################################################################################
                      [1m Learning iteration 312/500 [0m

                       Computation: 9092 steps/s (collection: 0.139s, learning 0.030s)
               Value function loss: 2.7659
                    Surrogate loss: -0.0076
             Mean action noise std: 1.02
                 Mean total reward: 148.37
               Mean episode length: 551.60
 Mean episode rew_tracking_lin_vel: 0.1661
 Mean episode rew_tracking_ang_vel: 0.0786
        Mean episode rew_lin_vel_z: -0.0215
      Mean episode rew_base_height: -1.0260
      Mean episode rew_action_rate: -0.0735
Mean episode rew_similar_to_default: -0.3501
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.2278
--------------------------------------------------------------------------------
                   Total timesteps: 480768
                    Iteration time: 0.17s
                        Total time: 51.82s
                               ETA: 31.1s

################################################################################
                      [1m Learning iteration 313/500 [0m

                       Computation: 9036 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 9.3887
                    Surrogate loss: 0.0008
             Mean action noise std: 1.02
                 Mean total reward: 149.72
               Mean episode length: 556.61
 Mean episode rew_tracking_lin_vel: 0.2447
 Mean episode rew_tracking_ang_vel: 0.1159
        Mean episode rew_lin_vel_z: -0.0197
      Mean episode rew_base_height: -1.5187
      Mean episode rew_action_rate: -0.1102
Mean episode rew_similar_to_default: -0.5168
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.7225
--------------------------------------------------------------------------------
                   Total timesteps: 482304
                    Iteration time: 0.17s
                        Total time: 51.99s
                               ETA: 31.0s

################################################################################
                      [1m Learning iteration 314/500 [0m

                       Computation: 9483 steps/s (collection: 0.132s, learning 0.030s)
               Value function loss: 2.3862
                    Surrogate loss: -0.0067
             Mean action noise std: 1.02
                 Mean total reward: 151.85
               Mean episode length: 564.50
 Mean episode rew_tracking_lin_vel: 0.1702
 Mean episode rew_tracking_ang_vel: 0.0804
        Mean episode rew_lin_vel_z: -0.0128
      Mean episode rew_base_height: -1.0559
      Mean episode rew_action_rate: -0.0793
Mean episode rew_similar_to_default: -0.3589
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.5589
--------------------------------------------------------------------------------
                   Total timesteps: 483840
                    Iteration time: 0.16s
                        Total time: 52.15s
                               ETA: 30.8s

################################################################################
                      [1m Learning iteration 315/500 [0m

                       Computation: 9367 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 7.3587
                    Surrogate loss: 0.0035
             Mean action noise std: 1.02
                 Mean total reward: 154.15
               Mean episode length: 572.63
 Mean episode rew_tracking_lin_vel: 0.3026
 Mean episode rew_tracking_ang_vel: 0.1429
        Mean episode rew_lin_vel_z: -0.0233
      Mean episode rew_base_height: -1.8916
      Mean episode rew_action_rate: -0.1358
Mean episode rew_similar_to_default: -0.6388
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5487
--------------------------------------------------------------------------------
                   Total timesteps: 485376
                    Iteration time: 0.16s
                        Total time: 52.31s
                               ETA: 30.6s

################################################################################
                      [1m Learning iteration 316/500 [0m

                       Computation: 9151 steps/s (collection: 0.137s, learning 0.031s)
               Value function loss: 7.7304
                    Surrogate loss: -0.0022
             Mean action noise std: 1.02
                 Mean total reward: 151.01
               Mean episode length: 561.07
 Mean episode rew_tracking_lin_vel: 0.2738
 Mean episode rew_tracking_ang_vel: 0.1295
        Mean episode rew_lin_vel_z: -0.0220
      Mean episode rew_base_height: -1.7051
      Mean episode rew_action_rate: -0.1248
Mean episode rew_similar_to_default: -0.5819
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.1638
--------------------------------------------------------------------------------
                   Total timesteps: 486912
                    Iteration time: 0.17s
                        Total time: 52.48s
                               ETA: 30.5s

################################################################################
                      [1m Learning iteration 317/500 [0m

                       Computation: 8245 steps/s (collection: 0.154s, learning 0.032s)
               Value function loss: 0.0910
                    Surrogate loss: -0.0069
             Mean action noise std: 1.02
                 Mean total reward: 152.98
               Mean episode length: 568.59
 Mean episode rew_tracking_lin_vel: 0.3653
 Mean episode rew_tracking_ang_vel: 0.1741
        Mean episode rew_lin_vel_z: -0.0236
      Mean episode rew_base_height: -2.2794
      Mean episode rew_action_rate: -0.1682
Mean episode rew_similar_to_default: -0.7754
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.2137
--------------------------------------------------------------------------------
                   Total timesteps: 488448
                    Iteration time: 0.19s
                        Total time: 52.67s
                               ETA: 30.3s

################################################################################
                      [1m Learning iteration 318/500 [0m

                       Computation: 9294 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 0.0996
                    Surrogate loss: 0.0036
             Mean action noise std: 1.02
                 Mean total reward: 156.61
               Mean episode length: 582.20
 Mean episode rew_tracking_lin_vel: 0.3628
 Mean episode rew_tracking_ang_vel: 0.1726
        Mean episode rew_lin_vel_z: -0.0245
      Mean episode rew_base_height: -2.2925
      Mean episode rew_action_rate: -0.1635
Mean episode rew_similar_to_default: -0.7758
Mean episode rew_joint_pose_matching: 0.0017
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.1122
--------------------------------------------------------------------------------
                   Total timesteps: 489984
                    Iteration time: 0.17s
                        Total time: 52.83s
                               ETA: 30.1s

################################################################################
                      [1m Learning iteration 319/500 [0m

                       Computation: 9360 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 1.5350
                    Surrogate loss: -0.0042
             Mean action noise std: 1.02
                 Mean total reward: 156.91
               Mean episode length: 583.38
 Mean episode rew_tracking_lin_vel: 0.0845
 Mean episode rew_tracking_ang_vel: 0.0414
        Mean episode rew_lin_vel_z: -0.0253
      Mean episode rew_base_height: -0.5231
      Mean episode rew_action_rate: -0.0366
Mean episode rew_similar_to_default: -0.1808
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7163
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 0.16s
                        Total time: 53.00s
                               ETA: 30.0s

################################################################################
                      [1m Learning iteration 320/500 [0m

                       Computation: 8942 steps/s (collection: 0.143s, learning 0.029s)
               Value function loss: 2.0929
                    Surrogate loss: -0.0072
             Mean action noise std: 1.02
                 Mean total reward: 159.91
               Mean episode length: 594.82
 Mean episode rew_tracking_lin_vel: 0.2079
 Mean episode rew_tracking_ang_vel: 0.0984
        Mean episode rew_lin_vel_z: -0.0212
      Mean episode rew_base_height: -1.2942
      Mean episode rew_action_rate: -0.0924
Mean episode rew_similar_to_default: -0.4412
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.1305
--------------------------------------------------------------------------------
                   Total timesteps: 493056
                    Iteration time: 0.17s
                        Total time: 53.17s
                               ETA: 29.8s

################################################################################
                      [1m Learning iteration 321/500 [0m

                       Computation: 9224 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 3.2067
                    Surrogate loss: -0.0085
             Mean action noise std: 1.02
                 Mean total reward: 161.63
               Mean episode length: 601.24
 Mean episode rew_tracking_lin_vel: 0.1630
 Mean episode rew_tracking_ang_vel: 0.0779
        Mean episode rew_lin_vel_z: -0.0178
      Mean episode rew_base_height: -1.0135
      Mean episode rew_action_rate: -0.0733
Mean episode rew_similar_to_default: -0.3455
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.2218
--------------------------------------------------------------------------------
                   Total timesteps: 494592
                    Iteration time: 0.17s
                        Total time: 53.34s
                               ETA: 29.6s

################################################################################
                      [1m Learning iteration 322/500 [0m

                       Computation: 9487 steps/s (collection: 0.132s, learning 0.029s)
               Value function loss: 2.3045
                    Surrogate loss: -0.0061
             Mean action noise std: 1.02
                 Mean total reward: 161.01
               Mean episode length: 599.20
 Mean episode rew_tracking_lin_vel: 0.2831
 Mean episode rew_tracking_ang_vel: 0.1365
        Mean episode rew_lin_vel_z: -0.0216
      Mean episode rew_base_height: -1.7749
      Mean episode rew_action_rate: -0.1249
Mean episode rew_similar_to_default: -0.6055
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.6145
--------------------------------------------------------------------------------
                   Total timesteps: 496128
                    Iteration time: 0.16s
                        Total time: 53.50s
                               ETA: 29.5s

################################################################################
                      [1m Learning iteration 323/500 [0m

                       Computation: 8503 steps/s (collection: 0.151s, learning 0.030s)
               Value function loss: 2.1826
                    Surrogate loss: -0.0069
             Mean action noise std: 1.02
                 Mean total reward: 165.80
               Mean episode length: 617.50
 Mean episode rew_tracking_lin_vel: 0.1834
 Mean episode rew_tracking_ang_vel: 0.0873
        Mean episode rew_lin_vel_z: -0.0182
      Mean episode rew_base_height: -1.1346
      Mean episode rew_action_rate: -0.0824
Mean episode rew_similar_to_default: -0.3882
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.1272
--------------------------------------------------------------------------------
                   Total timesteps: 497664
                    Iteration time: 0.18s
                        Total time: 53.68s
                               ETA: 29.3s

################################################################################
                      [1m Learning iteration 324/500 [0m

                       Computation: 8841 steps/s (collection: 0.144s, learning 0.030s)
               Value function loss: 6.2221
                    Surrogate loss: -0.0005
             Mean action noise std: 1.02
                 Mean total reward: 166.71
               Mean episode length: 620.90
 Mean episode rew_tracking_lin_vel: 0.1791
 Mean episode rew_tracking_ang_vel: 0.0848
        Mean episode rew_lin_vel_z: -0.0205
      Mean episode rew_base_height: -1.1075
      Mean episode rew_action_rate: -0.0781
Mean episode rew_similar_to_default: -0.3795
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.8688
--------------------------------------------------------------------------------
                   Total timesteps: 499200
                    Iteration time: 0.17s
                        Total time: 53.85s
                               ETA: 29.2s

################################################################################
                      [1m Learning iteration 325/500 [0m

                       Computation: 8989 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 0.5087
                    Surrogate loss: -0.0043
             Mean action noise std: 1.02
                 Mean total reward: 165.46
               Mean episode length: 616.38
 Mean episode rew_tracking_lin_vel: 0.2010
 Mean episode rew_tracking_ang_vel: 0.0955
        Mean episode rew_lin_vel_z: -0.0237
      Mean episode rew_base_height: -1.2473
      Mean episode rew_action_rate: -0.0896
Mean episode rew_similar_to_default: -0.4310
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.9384
--------------------------------------------------------------------------------
                   Total timesteps: 500736
                    Iteration time: 0.17s
                        Total time: 54.02s
                               ETA: 29.0s

################################################################################
                      [1m Learning iteration 326/500 [0m

                       Computation: 9180 steps/s (collection: 0.139s, learning 0.028s)
               Value function loss: 2.7147
                    Surrogate loss: -0.0051
             Mean action noise std: 1.02
                 Mean total reward: 166.71
               Mean episode length: 620.96
 Mean episode rew_tracking_lin_vel: 0.1886
 Mean episode rew_tracking_ang_vel: 0.0888
        Mean episode rew_lin_vel_z: -0.0193
      Mean episode rew_base_height: -1.1654
      Mean episode rew_action_rate: -0.0845
Mean episode rew_similar_to_default: -0.4040
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.3875
--------------------------------------------------------------------------------
                   Total timesteps: 502272
                    Iteration time: 0.17s
                        Total time: 54.19s
                               ETA: 28.8s

################################################################################
                      [1m Learning iteration 327/500 [0m

                       Computation: 9484 steps/s (collection: 0.135s, learning 0.027s)
               Value function loss: 3.0938
                    Surrogate loss: -0.0007
             Mean action noise std: 1.02
                 Mean total reward: 167.81
               Mean episode length: 625.18
 Mean episode rew_tracking_lin_vel: 0.2508
 Mean episode rew_tracking_ang_vel: 0.1182
        Mean episode rew_lin_vel_z: -0.0197
      Mean episode rew_base_height: -1.5658
      Mean episode rew_action_rate: -0.1135
Mean episode rew_similar_to_default: -0.5365
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.0540
--------------------------------------------------------------------------------
                   Total timesteps: 503808
                    Iteration time: 0.16s
                        Total time: 54.35s
                               ETA: 28.7s

################################################################################
                      [1m Learning iteration 328/500 [0m

                       Computation: 9127 steps/s (collection: 0.140s, learning 0.028s)
               Value function loss: 3.6453
                    Surrogate loss: -0.0052
             Mean action noise std: 1.02
                 Mean total reward: 167.61
               Mean episode length: 624.76
 Mean episode rew_tracking_lin_vel: 0.1516
 Mean episode rew_tracking_ang_vel: 0.0722
        Mean episode rew_lin_vel_z: -0.0243
      Mean episode rew_base_height: -0.9244
      Mean episode rew_action_rate: -0.0663
Mean episode rew_similar_to_default: -0.3204
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.6838
--------------------------------------------------------------------------------
                   Total timesteps: 505344
                    Iteration time: 0.17s
                        Total time: 54.52s
                               ETA: 28.5s

################################################################################
                      [1m Learning iteration 329/500 [0m

                       Computation: 9629 steps/s (collection: 0.132s, learning 0.028s)
               Value function loss: 0.0758
                    Surrogate loss: -0.0076
             Mean action noise std: 1.02
                 Mean total reward: 170.31
               Mean episode length: 634.66
 Mean episode rew_tracking_lin_vel: 0.3500
 Mean episode rew_tracking_ang_vel: 0.1628
        Mean episode rew_lin_vel_z: -0.0197
      Mean episode rew_base_height: -2.1905
      Mean episode rew_action_rate: -0.1516
Mean episode rew_similar_to_default: -0.7481
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.7574
--------------------------------------------------------------------------------
                   Total timesteps: 506880
                    Iteration time: 0.16s
                        Total time: 54.68s
                               ETA: 28.3s

################################################################################
                      [1m Learning iteration 330/500 [0m

                       Computation: 9459 steps/s (collection: 0.134s, learning 0.028s)
               Value function loss: 0.0567
                    Surrogate loss: -0.0073
             Mean action noise std: 1.02
                 Mean total reward: 172.19
               Mean episode length: 641.60
 Mean episode rew_tracking_lin_vel: 0.3649
 Mean episode rew_tracking_ang_vel: 0.1719
        Mean episode rew_lin_vel_z: -0.0195
      Mean episode rew_base_height: -2.2687
      Mean episode rew_action_rate: -0.1588
Mean episode rew_similar_to_default: -0.7791
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.2932
--------------------------------------------------------------------------------
                   Total timesteps: 508416
                    Iteration time: 0.16s
                        Total time: 54.84s
                               ETA: 28.2s

################################################################################
                      [1m Learning iteration 331/500 [0m

                       Computation: 9314 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 10.0465
                    Surrogate loss: -0.0007
             Mean action noise std: 1.02
                 Mean total reward: 175.63
               Mean episode length: 654.66
 Mean episode rew_tracking_lin_vel: 0.2847
 Mean episode rew_tracking_ang_vel: 0.1345
        Mean episode rew_lin_vel_z: -0.0240
      Mean episode rew_base_height: -1.7781
      Mean episode rew_action_rate: -0.1285
Mean episode rew_similar_to_default: -0.6090
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.5734
--------------------------------------------------------------------------------
                   Total timesteps: 509952
                    Iteration time: 0.16s
                        Total time: 55.01s
                               ETA: 28.0s

################################################################################
                      [1m Learning iteration 332/500 [0m

                       Computation: 9639 steps/s (collection: 0.132s, learning 0.028s)
               Value function loss: 0.0762
                    Surrogate loss: -0.0088
             Mean action noise std: 1.02
                 Mean total reward: 175.63
               Mean episode length: 654.66
 Mean episode rew_tracking_lin_vel: 0.1803
 Mean episode rew_tracking_ang_vel: 0.0840
        Mean episode rew_lin_vel_z: -0.0267
      Mean episode rew_base_height: -1.1229
      Mean episode rew_action_rate: -0.0762
Mean episode rew_similar_to_default: -0.3860
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.2197
--------------------------------------------------------------------------------
                   Total timesteps: 511488
                    Iteration time: 0.16s
                        Total time: 55.17s
                               ETA: 27.8s

################################################################################
                      [1m Learning iteration 333/500 [0m

                       Computation: 9399 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 0.0781
                    Surrogate loss: 0.0009
             Mean action noise std: 1.02
                 Mean total reward: 179.27
               Mean episode length: 668.28
 Mean episode rew_tracking_lin_vel: 0.3487
 Mean episode rew_tracking_ang_vel: 0.1659
        Mean episode rew_lin_vel_z: -0.0225
      Mean episode rew_base_height: -2.1948
      Mean episode rew_action_rate: -0.1530
Mean episode rew_similar_to_default: -0.7488
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.5318
--------------------------------------------------------------------------------
                   Total timesteps: 513024
                    Iteration time: 0.16s
                        Total time: 55.33s
                               ETA: 27.7s

################################################################################
                      [1m Learning iteration 334/500 [0m

                       Computation: 9129 steps/s (collection: 0.140s, learning 0.028s)
               Value function loss: 5.7948
                    Surrogate loss: 0.0073
             Mean action noise std: 1.02
                 Mean total reward: 177.29
               Mean episode length: 661.06
 Mean episode rew_tracking_lin_vel: 0.1694
 Mean episode rew_tracking_ang_vel: 0.0812
        Mean episode rew_lin_vel_z: -0.0211
      Mean episode rew_base_height: -1.0556
      Mean episode rew_action_rate: -0.0751
Mean episode rew_similar_to_default: -0.3627
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.5722
--------------------------------------------------------------------------------
                   Total timesteps: 514560
                    Iteration time: 0.17s
                        Total time: 55.50s
                               ETA: 27.5s

################################################################################
                      [1m Learning iteration 335/500 [0m

                       Computation: 9459 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 0.0546
                    Surrogate loss: -0.0044
             Mean action noise std: 1.02
                 Mean total reward: 177.29
               Mean episode length: 661.06
 Mean episode rew_tracking_lin_vel: 0.0906
 Mean episode rew_tracking_ang_vel: 0.0411
        Mean episode rew_lin_vel_z: -0.0222
      Mean episode rew_base_height: -0.5380
      Mean episode rew_action_rate: -0.0387
Mean episode rew_similar_to_default: -0.1891
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.9658
--------------------------------------------------------------------------------
                   Total timesteps: 516096
                    Iteration time: 0.16s
                        Total time: 55.66s
                               ETA: 27.3s

################################################################################
                      [1m Learning iteration 336/500 [0m

                       Computation: 9432 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 0.0622
                    Surrogate loss: -0.0034
             Mean action noise std: 1.02
                 Mean total reward: 177.24
               Mean episode length: 661.06
 Mean episode rew_tracking_lin_vel: 0.1356
 Mean episode rew_tracking_ang_vel: 0.0629
        Mean episode rew_lin_vel_z: -0.0214
      Mean episode rew_base_height: -0.8270
      Mean episode rew_action_rate: -0.0588
Mean episode rew_similar_to_default: -0.2876
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.9883
--------------------------------------------------------------------------------
                   Total timesteps: 517632
                    Iteration time: 0.16s
                        Total time: 55.82s
                               ETA: 27.2s

################################################################################
                      [1m Learning iteration 337/500 [0m

                       Computation: 9218 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 5.8288
                    Surrogate loss: 0.0005
             Mean action noise std: 1.02
                 Mean total reward: 176.45
               Mean episode length: 658.12
 Mean episode rew_tracking_lin_vel: 0.2893
 Mean episode rew_tracking_ang_vel: 0.1381
        Mean episode rew_lin_vel_z: -0.0209
      Mean episode rew_base_height: -1.8145
      Mean episode rew_action_rate: -0.1255
Mean episode rew_similar_to_default: -0.6239
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.9046
--------------------------------------------------------------------------------
                   Total timesteps: 519168
                    Iteration time: 0.17s
                        Total time: 55.99s
                               ETA: 27.0s

################################################################################
                      [1m Learning iteration 338/500 [0m

                       Computation: 8876 steps/s (collection: 0.143s, learning 0.030s)
               Value function loss: 4.7429
                    Surrogate loss: -0.0031
             Mean action noise std: 1.02
                 Mean total reward: 176.10
               Mean episode length: 656.98
 Mean episode rew_tracking_lin_vel: 0.2141
 Mean episode rew_tracking_ang_vel: 0.1019
        Mean episode rew_lin_vel_z: -0.0191
      Mean episode rew_base_height: -1.3412
      Mean episode rew_action_rate: -0.0944
Mean episode rew_similar_to_default: -0.4604
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.4634
--------------------------------------------------------------------------------
                   Total timesteps: 520704
                    Iteration time: 0.17s
                        Total time: 56.16s
                               ETA: 26.8s

################################################################################
                      [1m Learning iteration 339/500 [0m

                       Computation: 9113 steps/s (collection: 0.140s, learning 0.028s)
               Value function loss: 2.5081
                    Surrogate loss: -0.0077
             Mean action noise std: 1.02
                 Mean total reward: 178.43
               Mean episode length: 665.50
 Mean episode rew_tracking_lin_vel: 0.2804
 Mean episode rew_tracking_ang_vel: 0.1348
        Mean episode rew_lin_vel_z: -0.0228
      Mean episode rew_base_height: -1.7710
      Mean episode rew_action_rate: -0.1222
Mean episode rew_similar_to_default: -0.6074
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.5094
--------------------------------------------------------------------------------
                   Total timesteps: 522240
                    Iteration time: 0.17s
                        Total time: 56.33s
                               ETA: 26.7s

################################################################################
                      [1m Learning iteration 340/500 [0m

                       Computation: 8788 steps/s (collection: 0.147s, learning 0.028s)
               Value function loss: 0.0771
                    Surrogate loss: -0.0088
             Mean action noise std: 1.02
                 Mean total reward: 178.43
               Mean episode length: 665.50
 Mean episode rew_tracking_lin_vel: 0.3642
 Mean episode rew_tracking_ang_vel: 0.1780
        Mean episode rew_lin_vel_z: -0.0238
      Mean episode rew_base_height: -2.3235
      Mean episode rew_action_rate: -0.1590
Mean episode rew_similar_to_default: -0.7929
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.2633
--------------------------------------------------------------------------------
                   Total timesteps: 523776
                    Iteration time: 0.17s
                        Total time: 56.51s
                               ETA: 26.5s

################################################################################
                      [1m Learning iteration 341/500 [0m

                       Computation: 8823 steps/s (collection: 0.143s, learning 0.031s)
               Value function loss: 3.7344
                    Surrogate loss: -0.0057
             Mean action noise std: 1.02
                 Mean total reward: 177.88
               Mean episode length: 663.45
 Mean episode rew_tracking_lin_vel: 0.0426
 Mean episode rew_tracking_ang_vel: 0.0198
        Mean episode rew_lin_vel_z: -0.0228
      Mean episode rew_base_height: -0.2421
      Mean episode rew_action_rate: -0.0178
Mean episode rew_similar_to_default: -0.0852
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 1.7830
--------------------------------------------------------------------------------
                   Total timesteps: 525312
                    Iteration time: 0.17s
                        Total time: 56.68s
                               ETA: 26.4s

################################################################################
                      [1m Learning iteration 342/500 [0m

                       Computation: 7779 steps/s (collection: 0.160s, learning 0.037s)
               Value function loss: 0.0901
                    Surrogate loss: -0.0054
             Mean action noise std: 1.02
                 Mean total reward: 178.53
               Mean episode length: 665.72
 Mean episode rew_tracking_lin_vel: 0.3642
 Mean episode rew_tracking_ang_vel: 0.1744
        Mean episode rew_lin_vel_z: -0.0233
      Mean episode rew_base_height: -2.2996
      Mean episode rew_action_rate: -0.1574
Mean episode rew_similar_to_default: -0.7873
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0007
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.2549
--------------------------------------------------------------------------------
                   Total timesteps: 526848
                    Iteration time: 0.20s
                        Total time: 56.88s
                               ETA: 26.2s

################################################################################
                      [1m Learning iteration 343/500 [0m

                       Computation: 9005 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 0.9480
                    Surrogate loss: -0.0030
             Mean action noise std: 1.02
                 Mean total reward: 178.70
               Mean episode length: 666.33
 Mean episode rew_tracking_lin_vel: 0.3590
 Mean episode rew_tracking_ang_vel: 0.1709
        Mean episode rew_lin_vel_z: -0.0207
      Mean episode rew_base_height: -2.2640
      Mean episode rew_action_rate: -0.1550
Mean episode rew_similar_to_default: -0.7779
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0009
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.0058
--------------------------------------------------------------------------------
                   Total timesteps: 528384
                    Iteration time: 0.17s
                        Total time: 57.05s
                               ETA: 26.0s

################################################################################
                      [1m Learning iteration 344/500 [0m

                       Computation: 8685 steps/s (collection: 0.145s, learning 0.032s)
               Value function loss: 0.0737
                    Surrogate loss: -0.0074
             Mean action noise std: 1.02
                 Mean total reward: 178.70
               Mean episode length: 666.33
 Mean episode rew_tracking_lin_vel: 0.3588
 Mean episode rew_tracking_ang_vel: 0.1707
        Mean episode rew_lin_vel_z: -0.0205
      Mean episode rew_base_height: -2.2620
      Mean episode rew_action_rate: -0.1550
Mean episode rew_similar_to_default: -0.7775
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0009
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.9936
--------------------------------------------------------------------------------
                   Total timesteps: 529920
                    Iteration time: 0.18s
                        Total time: 57.23s
                               ETA: 25.9s

################################################################################
                      [1m Learning iteration 345/500 [0m

                       Computation: 8420 steps/s (collection: 0.152s, learning 0.031s)
               Value function loss: 17.4053
                    Surrogate loss: 0.0061
             Mean action noise std: 1.02
                 Mean total reward: 172.37
               Mean episode length: 642.43
 Mean episode rew_tracking_lin_vel: 0.1934
 Mean episode rew_tracking_ang_vel: 0.0927
        Mean episode rew_lin_vel_z: -0.0228
      Mean episode rew_base_height: -1.2044
      Mean episode rew_action_rate: -0.0831
Mean episode rew_similar_to_default: -0.4161
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.6342
--------------------------------------------------------------------------------
                   Total timesteps: 531456
                    Iteration time: 0.18s
                        Total time: 57.41s
                               ETA: 25.7s

################################################################################
                      [1m Learning iteration 346/500 [0m

                       Computation: 8049 steps/s (collection: 0.153s, learning 0.038s)
               Value function loss: 14.4098
                    Surrogate loss: -0.0048
             Mean action noise std: 1.02
                 Mean total reward: 171.61
               Mean episode length: 639.31
 Mean episode rew_tracking_lin_vel: 0.1713
 Mean episode rew_tracking_ang_vel: 0.0828
        Mean episode rew_lin_vel_z: -0.0210
      Mean episode rew_base_height: -1.0779
      Mean episode rew_action_rate: -0.0719
Mean episode rew_similar_to_default: -0.3688
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.7086
--------------------------------------------------------------------------------
                   Total timesteps: 532992
                    Iteration time: 0.19s
                        Total time: 57.60s
                               ETA: 25.6s

################################################################################
                      [1m Learning iteration 347/500 [0m

                       Computation: 8663 steps/s (collection: 0.147s, learning 0.031s)
               Value function loss: 10.7264
                    Surrogate loss: -0.0048
             Mean action noise std: 1.02
                 Mean total reward: 163.43
               Mean episode length: 608.27
 Mean episode rew_tracking_lin_vel: 0.1250
 Mean episode rew_tracking_ang_vel: 0.0593
        Mean episode rew_lin_vel_z: -0.0226
      Mean episode rew_base_height: -0.7836
      Mean episode rew_action_rate: -0.0540
Mean episode rew_similar_to_default: -0.2682
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.6808
--------------------------------------------------------------------------------
                   Total timesteps: 534528
                    Iteration time: 0.18s
                        Total time: 57.78s
                               ETA: 25.4s

################################################################################
                      [1m Learning iteration 348/500 [0m

                       Computation: 8759 steps/s (collection: 0.143s, learning 0.032s)
               Value function loss: 2.7707
                    Surrogate loss: -0.0054
             Mean action noise std: 1.02
                 Mean total reward: 164.04
               Mean episode length: 610.52
 Mean episode rew_tracking_lin_vel: 0.0566
 Mean episode rew_tracking_ang_vel: 0.0269
        Mean episode rew_lin_vel_z: -0.0166
      Mean episode rew_base_height: -0.3386
      Mean episode rew_action_rate: -0.0259
Mean episode rew_similar_to_default: -0.1166
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.5047
--------------------------------------------------------------------------------
                   Total timesteps: 536064
                    Iteration time: 0.18s
                        Total time: 57.95s
                               ETA: 25.2s

################################################################################
                      [1m Learning iteration 349/500 [0m

                       Computation: 8777 steps/s (collection: 0.144s, learning 0.031s)
               Value function loss: 2.4472
                    Surrogate loss: -0.0037
             Mean action noise std: 1.02
                 Mean total reward: 166.24
               Mean episode length: 618.35
 Mean episode rew_tracking_lin_vel: 0.1939
 Mean episode rew_tracking_ang_vel: 0.0936
        Mean episode rew_lin_vel_z: -0.0195
      Mean episode rew_base_height: -1.2199
      Mean episode rew_action_rate: -0.0843
Mean episode rew_similar_to_default: -0.4192
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.6746
--------------------------------------------------------------------------------
                   Total timesteps: 537600
                    Iteration time: 0.17s
                        Total time: 58.13s
                               ETA: 25.1s

################################################################################
                      [1m Learning iteration 350/500 [0m

                       Computation: 8913 steps/s (collection: 0.142s, learning 0.030s)
               Value function loss: 0.0635
                    Surrogate loss: -0.0030
             Mean action noise std: 1.02
                 Mean total reward: 166.24
               Mean episode length: 618.35
 Mean episode rew_tracking_lin_vel: 0.3653
 Mean episode rew_tracking_ang_vel: 0.1744
        Mean episode rew_lin_vel_z: -0.0237
      Mean episode rew_base_height: -2.3019
      Mean episode rew_action_rate: -0.1589
Mean episode rew_similar_to_default: -0.7959
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.4451
--------------------------------------------------------------------------------
                   Total timesteps: 539136
                    Iteration time: 0.17s
                        Total time: 58.30s
                               ETA: 24.9s

################################################################################
                      [1m Learning iteration 351/500 [0m

                       Computation: 9031 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 2.5858
                    Surrogate loss: -0.0036
             Mean action noise std: 1.02
                 Mean total reward: 168.62
               Mean episode length: 626.93
 Mean episode rew_tracking_lin_vel: 0.2739
 Mean episode rew_tracking_ang_vel: 0.1309
        Mean episode rew_lin_vel_z: -0.0240
      Mean episode rew_base_height: -1.7218
      Mean episode rew_action_rate: -0.1187
Mean episode rew_similar_to_default: -0.5940
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.2299
--------------------------------------------------------------------------------
                   Total timesteps: 540672
                    Iteration time: 0.17s
                        Total time: 58.47s
                               ETA: 24.7s

################################################################################
                      [1m Learning iteration 352/500 [0m

                       Computation: 9023 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 2.6105
                    Surrogate loss: -0.0027
             Mean action noise std: 1.02
                 Mean total reward: 171.05
               Mean episode length: 635.66
 Mean episode rew_tracking_lin_vel: 0.2118
 Mean episode rew_tracking_ang_vel: 0.1021
        Mean episode rew_lin_vel_z: -0.0254
      Mean episode rew_base_height: -1.3394
      Mean episode rew_action_rate: -0.0907
Mean episode rew_similar_to_default: -0.4566
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.4482
--------------------------------------------------------------------------------
                   Total timesteps: 542208
                    Iteration time: 0.17s
                        Total time: 58.64s
                               ETA: 24.6s

################################################################################
                      [1m Learning iteration 353/500 [0m

                       Computation: 8930 steps/s (collection: 0.142s, learning 0.030s)
               Value function loss: 4.3838
                    Surrogate loss: -0.0050
             Mean action noise std: 1.02
                 Mean total reward: 170.94
               Mean episode length: 635.03
 Mean episode rew_tracking_lin_vel: 0.2129
 Mean episode rew_tracking_ang_vel: 0.1016
        Mean episode rew_lin_vel_z: -0.0185
      Mean episode rew_base_height: -1.3410
      Mean episode rew_action_rate: -0.0916
Mean episode rew_similar_to_default: -0.4605
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.5539
--------------------------------------------------------------------------------
                   Total timesteps: 543744
                    Iteration time: 0.17s
                        Total time: 58.81s
                               ETA: 24.4s

################################################################################
                      [1m Learning iteration 354/500 [0m

                       Computation: 8901 steps/s (collection: 0.143s, learning 0.030s)
               Value function loss: 5.6795
                    Surrogate loss: -0.0028
             Mean action noise std: 1.02
                 Mean total reward: 167.38
               Mean episode length: 622.04
 Mean episode rew_tracking_lin_vel: 0.1217
 Mean episode rew_tracking_ang_vel: 0.0583
        Mean episode rew_lin_vel_z: -0.0158
      Mean episode rew_base_height: -0.7713
      Mean episode rew_action_rate: -0.0524
Mean episode rew_similar_to_default: -0.2612
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.4333
--------------------------------------------------------------------------------
                   Total timesteps: 545280
                    Iteration time: 0.17s
                        Total time: 58.98s
                               ETA: 24.3s

################################################################################
                      [1m Learning iteration 355/500 [0m

                       Computation: 8971 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 4.2856
                    Surrogate loss: -0.0037
             Mean action noise std: 1.02
                 Mean total reward: 163.25
               Mean episode length: 606.84
 Mean episode rew_tracking_lin_vel: 0.1678
 Mean episode rew_tracking_ang_vel: 0.0806
        Mean episode rew_lin_vel_z: -0.0117
      Mean episode rew_base_height: -1.0670
      Mean episode rew_action_rate: -0.0725
Mean episode rew_similar_to_default: -0.3624
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.4353
--------------------------------------------------------------------------------
                   Total timesteps: 546816
                    Iteration time: 0.17s
                        Total time: 59.16s
                               ETA: 24.1s

################################################################################
                      [1m Learning iteration 356/500 [0m

                       Computation: 9062 steps/s (collection: 0.139s, learning 0.030s)
               Value function loss: 3.1488
                    Surrogate loss: -0.0082
             Mean action noise std: 1.02
                 Mean total reward: 159.84
               Mean episode length: 594.12
 Mean episode rew_tracking_lin_vel: 0.0988
 Mean episode rew_tracking_ang_vel: 0.0478
        Mean episode rew_lin_vel_z: -0.0162
      Mean episode rew_base_height: -0.6191
      Mean episode rew_action_rate: -0.0445
Mean episode rew_similar_to_default: -0.2089
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.3036
--------------------------------------------------------------------------------
                   Total timesteps: 548352
                    Iteration time: 0.17s
                        Total time: 59.32s
                               ETA: 23.9s

################################################################################
                      [1m Learning iteration 357/500 [0m

                       Computation: 9039 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 5.6865
                    Surrogate loss: -0.0034
             Mean action noise std: 1.02
                 Mean total reward: 158.22
               Mean episode length: 587.81
 Mean episode rew_tracking_lin_vel: 0.2104
 Mean episode rew_tracking_ang_vel: 0.1020
        Mean episode rew_lin_vel_z: -0.0219
      Mean episode rew_base_height: -1.3449
      Mean episode rew_action_rate: -0.0918
Mean episode rew_similar_to_default: -0.4566
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.3769
--------------------------------------------------------------------------------
                   Total timesteps: 549888
                    Iteration time: 0.17s
                        Total time: 59.49s
                               ETA: 23.8s

################################################################################
                      [1m Learning iteration 358/500 [0m

                       Computation: 8755 steps/s (collection: 0.143s, learning 0.033s)
               Value function loss: 6.6809
                    Surrogate loss: -0.0122
             Mean action noise std: 1.02
                 Mean total reward: 154.66
               Mean episode length: 574.69
 Mean episode rew_tracking_lin_vel: 0.1196
 Mean episode rew_tracking_ang_vel: 0.0569
        Mean episode rew_lin_vel_z: -0.0243
      Mean episode rew_base_height: -0.7511
      Mean episode rew_action_rate: -0.0512
Mean episode rew_similar_to_default: -0.2569
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.3213
--------------------------------------------------------------------------------
                   Total timesteps: 551424
                    Iteration time: 0.18s
                        Total time: 59.67s
                               ETA: 23.6s

################################################################################
                      [1m Learning iteration 359/500 [0m

                       Computation: 9371 steps/s (collection: 0.135s, learning 0.029s)
               Value function loss: 0.0961
                    Surrogate loss: -0.0082
             Mean action noise std: 1.02
                 Mean total reward: 154.66
               Mean episode length: 574.69
 Mean episode rew_tracking_lin_vel: 0.0381
 Mean episode rew_tracking_ang_vel: 0.0181
        Mean episode rew_lin_vel_z: -0.0254
      Mean episode rew_base_height: -0.2327
      Mean episode rew_action_rate: -0.0183
Mean episode rew_similar_to_default: -0.0802
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 1.6470
--------------------------------------------------------------------------------
                   Total timesteps: 552960
                    Iteration time: 0.16s
                        Total time: 59.83s
                               ETA: 23.4s

################################################################################
                      [1m Learning iteration 360/500 [0m

                       Computation: 9170 steps/s (collection: 0.139s, learning 0.029s)
               Value function loss: 1.5294
                    Surrogate loss: -0.0014
             Mean action noise std: 1.02
                 Mean total reward: 156.80
               Mean episode length: 582.13
 Mean episode rew_tracking_lin_vel: 0.2916
 Mean episode rew_tracking_ang_vel: 0.1379
        Mean episode rew_lin_vel_z: -0.0232
      Mean episode rew_base_height: -1.8527
      Mean episode rew_action_rate: -0.1228
Mean episode rew_similar_to_default: -0.6309
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.1693
--------------------------------------------------------------------------------
                   Total timesteps: 554496
                    Iteration time: 0.17s
                        Total time: 60.00s
                               ETA: 23.3s

################################################################################
                      [1m Learning iteration 361/500 [0m

                       Computation: 9162 steps/s (collection: 0.136s, learning 0.031s)
               Value function loss: 0.1008
                    Surrogate loss: -0.0010
             Mean action noise std: 1.02
                 Mean total reward: 159.43
               Mean episode length: 592.03
 Mean episode rew_tracking_lin_vel: 0.3628
 Mean episode rew_tracking_ang_vel: 0.1745
        Mean episode rew_lin_vel_z: -0.0249
      Mean episode rew_base_height: -2.3321
      Mean episode rew_action_rate: -0.1531
Mean episode rew_similar_to_default: -0.7908
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.3893
--------------------------------------------------------------------------------
                   Total timesteps: 556032
                    Iteration time: 0.17s
                        Total time: 60.17s
                               ETA: 23.1s

################################################################################
                      [1m Learning iteration 362/500 [0m

                       Computation: 8861 steps/s (collection: 0.143s, learning 0.030s)
               Value function loss: 13.2185
                    Surrogate loss: -0.0052
             Mean action noise std: 1.02
                 Mean total reward: 159.46
               Mean episode length: 591.84
 Mean episode rew_tracking_lin_vel: 0.2687
 Mean episode rew_tracking_ang_vel: 0.1299
        Mean episode rew_lin_vel_z: -0.0248
      Mean episode rew_base_height: -1.7197
      Mean episode rew_action_rate: -0.1155
Mean episode rew_similar_to_default: -0.5835
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.9641
--------------------------------------------------------------------------------
                   Total timesteps: 557568
                    Iteration time: 0.17s
                        Total time: 60.34s
                               ETA: 22.9s

################################################################################
                      [1m Learning iteration 363/500 [0m

                       Computation: 8772 steps/s (collection: 0.144s, learning 0.031s)
               Value function loss: 1.9366
                    Surrogate loss: -0.0021
             Mean action noise std: 1.02
                 Mean total reward: 156.53
               Mean episode length: 580.74
 Mean episode rew_tracking_lin_vel: 0.1120
 Mean episode rew_tracking_ang_vel: 0.0559
        Mean episode rew_lin_vel_z: -0.0218
      Mean episode rew_base_height: -0.7212
      Mean episode rew_action_rate: -0.0495
Mean episode rew_similar_to_default: -0.2431
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.0113
--------------------------------------------------------------------------------
                   Total timesteps: 559104
                    Iteration time: 0.18s
                        Total time: 60.52s
                               ETA: 22.8s

################################################################################
                      [1m Learning iteration 364/500 [0m

                       Computation: 8473 steps/s (collection: 0.152s, learning 0.029s)
               Value function loss: 6.5236
                    Surrogate loss: -0.0066
             Mean action noise std: 1.02
                 Mean total reward: 152.40
               Mean episode length: 564.88
 Mean episode rew_tracking_lin_vel: 0.0741
 Mean episode rew_tracking_ang_vel: 0.0359
        Mean episode rew_lin_vel_z: -0.0227
      Mean episode rew_base_height: -0.4668
      Mean episode rew_action_rate: -0.0326
Mean episode rew_similar_to_default: -0.1580
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.3444
--------------------------------------------------------------------------------
                   Total timesteps: 560640
                    Iteration time: 0.18s
                        Total time: 60.70s
                               ETA: 22.6s

################################################################################
                      [1m Learning iteration 365/500 [0m

                       Computation: 9346 steps/s (collection: 0.135s, learning 0.029s)
               Value function loss: 1.3686
                    Surrogate loss: -0.0021
             Mean action noise std: 1.02
                 Mean total reward: 153.28
               Mean episode length: 568.17
 Mean episode rew_tracking_lin_vel: 0.1842
 Mean episode rew_tracking_ang_vel: 0.0895
        Mean episode rew_lin_vel_z: -0.0251
      Mean episode rew_base_height: -1.1902
      Mean episode rew_action_rate: -0.0785
Mean episode rew_similar_to_default: -0.4048
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.3206
--------------------------------------------------------------------------------
                   Total timesteps: 562176
                    Iteration time: 0.16s
                        Total time: 60.86s
                               ETA: 22.4s

################################################################################
                      [1m Learning iteration 366/500 [0m

                       Computation: 9296 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 0.1077
                    Surrogate loss: -0.0075
             Mean action noise std: 1.02
                 Mean total reward: 153.34
               Mean episode length: 568.17
 Mean episode rew_tracking_lin_vel: 0.2525
 Mean episode rew_tracking_ang_vel: 0.1220
        Mean episode rew_lin_vel_z: -0.0251
      Mean episode rew_base_height: -1.6260
      Mean episode rew_action_rate: -0.1076
Mean episode rew_similar_to_default: -0.5514
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.4635
--------------------------------------------------------------------------------
                   Total timesteps: 563712
                    Iteration time: 0.17s
                        Total time: 61.03s
                               ETA: 22.3s

################################################################################
                      [1m Learning iteration 367/500 [0m

                       Computation: 9567 steps/s (collection: 0.133s, learning 0.027s)
               Value function loss: 3.2541
                    Surrogate loss: -0.0070
             Mean action noise std: 1.02
                 Mean total reward: 154.02
               Mean episode length: 570.73
 Mean episode rew_tracking_lin_vel: 0.3475
 Mean episode rew_tracking_ang_vel: 0.1672
        Mean episode rew_lin_vel_z: -0.0245
      Mean episode rew_base_height: -2.2368
      Mean episode rew_action_rate: -0.1503
Mean episode rew_similar_to_default: -0.7567
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.9080
--------------------------------------------------------------------------------
                   Total timesteps: 565248
                    Iteration time: 0.16s
                        Total time: 61.19s
                               ETA: 22.1s

################################################################################
                      [1m Learning iteration 368/500 [0m

                       Computation: 9286 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 5.2456
                    Surrogate loss: -0.0057
             Mean action noise std: 1.02
                 Mean total reward: 150.78
               Mean episode length: 558.37
 Mean episode rew_tracking_lin_vel: 0.2755
 Mean episode rew_tracking_ang_vel: 0.1334
        Mean episode rew_lin_vel_z: -0.0219
      Mean episode rew_base_height: -1.7654
      Mean episode rew_action_rate: -0.1168
Mean episode rew_similar_to_default: -0.5972
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.3001
--------------------------------------------------------------------------------
                   Total timesteps: 566784
                    Iteration time: 0.17s
                        Total time: 61.35s
                               ETA: 21.9s

################################################################################
                      [1m Learning iteration 369/500 [0m

                       Computation: 9338 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.0881
                    Surrogate loss: -0.0053
             Mean action noise std: 1.02
                 Mean total reward: 152.11
               Mean episode length: 563.43
 Mean episode rew_tracking_lin_vel: 0.3443
 Mean episode rew_tracking_ang_vel: 0.1648
        Mean episode rew_lin_vel_z: -0.0249
      Mean episode rew_base_height: -2.2193
      Mean episode rew_action_rate: -0.1468
Mean episode rew_similar_to_default: -0.7501
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.3756
--------------------------------------------------------------------------------
                   Total timesteps: 568320
                    Iteration time: 0.16s
                        Total time: 61.52s
                               ETA: 21.8s

################################################################################
                      [1m Learning iteration 370/500 [0m

                       Computation: 9587 steps/s (collection: 0.131s, learning 0.030s)
               Value function loss: 0.0989
                    Surrogate loss: 0.0060
             Mean action noise std: 1.02
                 Mean total reward: 152.11
               Mean episode length: 563.43
 Mean episode rew_tracking_lin_vel: 0.3638
 Mean episode rew_tracking_ang_vel: 0.1755
        Mean episode rew_lin_vel_z: -0.0263
      Mean episode rew_base_height: -2.3473
      Mean episode rew_action_rate: -0.1545
Mean episode rew_similar_to_default: -0.7933
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.3708
--------------------------------------------------------------------------------
                   Total timesteps: 569856
                    Iteration time: 0.16s
                        Total time: 61.68s
                               ETA: 21.6s

################################################################################
                      [1m Learning iteration 371/500 [0m

                       Computation: 9483 steps/s (collection: 0.132s, learning 0.030s)
               Value function loss: 0.0750
                    Surrogate loss: 0.0065
             Mean action noise std: 1.02
                 Mean total reward: 152.11
               Mean episode length: 563.43
 Mean episode rew_tracking_lin_vel: 0.3638
 Mean episode rew_tracking_ang_vel: 0.1755
        Mean episode rew_lin_vel_z: -0.0263
      Mean episode rew_base_height: -2.3473
      Mean episode rew_action_rate: -0.1545
Mean episode rew_similar_to_default: -0.7933
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.3708
--------------------------------------------------------------------------------
                   Total timesteps: 571392
                    Iteration time: 0.16s
                        Total time: 61.84s
                               ETA: 21.4s

################################################################################
                      [1m Learning iteration 372/500 [0m

                       Computation: 9171 steps/s (collection: 0.138s, learning 0.029s)
               Value function loss: 3.7128
                    Surrogate loss: 0.0003
             Mean action noise std: 1.02
                 Mean total reward: 152.96
               Mean episode length: 566.16
 Mean episode rew_tracking_lin_vel: 0.2044
 Mean episode rew_tracking_ang_vel: 0.0975
        Mean episode rew_lin_vel_z: -0.0242
      Mean episode rew_base_height: -1.3178
      Mean episode rew_action_rate: -0.0886
Mean episode rew_similar_to_default: -0.4479
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.2571
--------------------------------------------------------------------------------
                   Total timesteps: 572928
                    Iteration time: 0.17s
                        Total time: 62.01s
                               ETA: 21.3s

################################################################################
                      [1m Learning iteration 373/500 [0m

                       Computation: 8895 steps/s (collection: 0.143s, learning 0.030s)
               Value function loss: 15.4364
                    Surrogate loss: -0.0062
             Mean action noise std: 1.02
                 Mean total reward: 151.33
               Mean episode length: 559.59
 Mean episode rew_tracking_lin_vel: 0.1807
 Mean episode rew_tracking_ang_vel: 0.0869
        Mean episode rew_lin_vel_z: -0.0210
      Mean episode rew_base_height: -1.1656
      Mean episode rew_action_rate: -0.0784
Mean episode rew_similar_to_default: -0.3953
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.1358
--------------------------------------------------------------------------------
                   Total timesteps: 574464
                    Iteration time: 0.17s
                        Total time: 62.18s
                               ETA: 21.1s

################################################################################
                      [1m Learning iteration 374/500 [0m

                       Computation: 9174 steps/s (collection: 0.138s, learning 0.029s)
               Value function loss: 6.1666
                    Surrogate loss: -0.0058
             Mean action noise std: 1.02
                 Mean total reward: 147.33
               Mean episode length: 544.85
 Mean episode rew_tracking_lin_vel: 0.0096
 Mean episode rew_tracking_ang_vel: 0.0045
        Mean episode rew_lin_vel_z: -0.0246
      Mean episode rew_base_height: -0.0453
      Mean episode rew_action_rate: -0.0055
Mean episode rew_similar_to_default: -0.0177
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.4787
--------------------------------------------------------------------------------
                   Total timesteps: 576000
                    Iteration time: 0.17s
                        Total time: 62.35s
                               ETA: 20.9s

################################################################################
                      [1m Learning iteration 375/500 [0m

                       Computation: 9082 steps/s (collection: 0.140s, learning 0.029s)
               Value function loss: 5.1315
                    Surrogate loss: -0.0070
             Mean action noise std: 1.02
                 Mean total reward: 148.50
               Mean episode length: 548.72
 Mean episode rew_tracking_lin_vel: 0.1260
 Mean episode rew_tracking_ang_vel: 0.0598
        Mean episode rew_lin_vel_z: -0.0260
      Mean episode rew_base_height: -0.8087
      Mean episode rew_action_rate: -0.0542
Mean episode rew_similar_to_default: -0.2777
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.7889
--------------------------------------------------------------------------------
                   Total timesteps: 577536
                    Iteration time: 0.17s
                        Total time: 62.52s
                               ETA: 20.8s

################################################################################
                      [1m Learning iteration 376/500 [0m

                       Computation: 9248 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 3.5517
                    Surrogate loss: -0.0053
             Mean action noise std: 1.02
                 Mean total reward: 145.94
               Mean episode length: 539.30
 Mean episode rew_tracking_lin_vel: 0.0544
 Mean episode rew_tracking_ang_vel: 0.0260
        Mean episode rew_lin_vel_z: -0.0269
      Mean episode rew_base_height: -0.3436
      Mean episode rew_action_rate: -0.0229
Mean episode rew_similar_to_default: -0.1218
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.6188
--------------------------------------------------------------------------------
                   Total timesteps: 579072
                    Iteration time: 0.17s
                        Total time: 62.68s
                               ETA: 20.6s

################################################################################
                      [1m Learning iteration 377/500 [0m

                       Computation: 9205 steps/s (collection: 0.137s, learning 0.029s)
               Value function loss: 2.3319
                    Surrogate loss: -0.0039
             Mean action noise std: 1.02
                 Mean total reward: 145.06
               Mean episode length: 535.98
 Mean episode rew_tracking_lin_vel: 0.1870
 Mean episode rew_tracking_ang_vel: 0.0892
        Mean episode rew_lin_vel_z: -0.0246
      Mean episode rew_base_height: -1.2160
      Mean episode rew_action_rate: -0.0803
Mean episode rew_similar_to_default: -0.4160
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.5329
--------------------------------------------------------------------------------
                   Total timesteps: 580608
                    Iteration time: 0.17s
                        Total time: 62.85s
                               ETA: 20.5s

################################################################################
                      [1m Learning iteration 378/500 [0m

                       Computation: 9283 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 2.6279
                    Surrogate loss: -0.0032
             Mean action noise std: 1.02
                 Mean total reward: 142.60
               Mean episode length: 526.82
 Mean episode rew_tracking_lin_vel: 0.1244
 Mean episode rew_tracking_ang_vel: 0.0594
        Mean episode rew_lin_vel_z: -0.0245
      Mean episode rew_base_height: -0.8019
      Mean episode rew_action_rate: -0.0542
Mean episode rew_similar_to_default: -0.2755
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.6910
--------------------------------------------------------------------------------
                   Total timesteps: 582144
                    Iteration time: 0.17s
                        Total time: 63.02s
                               ETA: 20.3s

################################################################################
                      [1m Learning iteration 379/500 [0m

                       Computation: 8861 steps/s (collection: 0.145s, learning 0.029s)
               Value function loss: 12.9675
                    Surrogate loss: 0.0038
             Mean action noise std: 1.02
                 Mean total reward: 142.59
               Mean episode length: 526.72
 Mean episode rew_tracking_lin_vel: 0.1925
 Mean episode rew_tracking_ang_vel: 0.0928
        Mean episode rew_lin_vel_z: -0.0236
      Mean episode rew_base_height: -1.2536
      Mean episode rew_action_rate: -0.0837
Mean episode rew_similar_to_default: -0.4253
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.7256
--------------------------------------------------------------------------------
                   Total timesteps: 583680
                    Iteration time: 0.17s
                        Total time: 63.19s
                               ETA: 20.1s

################################################################################
                      [1m Learning iteration 380/500 [0m

                       Computation: 8989 steps/s (collection: 0.139s, learning 0.031s)
               Value function loss: 0.1935
                    Surrogate loss: -0.0043
             Mean action noise std: 1.02
                 Mean total reward: 145.28
               Mean episode length: 536.64
 Mean episode rew_tracking_lin_vel: 0.0335
 Mean episode rew_tracking_ang_vel: 0.0165
        Mean episode rew_lin_vel_z: -0.0182
      Mean episode rew_base_height: -0.2030
      Mean episode rew_action_rate: -0.0156
Mean episode rew_similar_to_default: -0.0709
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 1.5184
--------------------------------------------------------------------------------
                   Total timesteps: 585216
                    Iteration time: 0.17s
                        Total time: 63.36s
                               ETA: 20.0s

################################################################################
                      [1m Learning iteration 381/500 [0m

                       Computation: 8911 steps/s (collection: 0.140s, learning 0.033s)
               Value function loss: 9.7381
                    Surrogate loss: -0.0057
             Mean action noise std: 1.02
                 Mean total reward: 143.67
               Mean episode length: 530.88
 Mean episode rew_tracking_lin_vel: 0.3020
 Mean episode rew_tracking_ang_vel: 0.1444
        Mean episode rew_lin_vel_z: -0.0263
      Mean episode rew_base_height: -1.9771
      Mean episode rew_action_rate: -0.1329
Mean episode rew_similar_to_default: -0.6713
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5741
--------------------------------------------------------------------------------
                   Total timesteps: 586752
                    Iteration time: 0.17s
                        Total time: 63.53s
                               ETA: 19.8s

################################################################################
                      [1m Learning iteration 382/500 [0m

                       Computation: 9122 steps/s (collection: 0.141s, learning 0.027s)
               Value function loss: 3.1311
                    Surrogate loss: -0.0062
             Mean action noise std: 1.02
                 Mean total reward: 143.88
               Mean episode length: 531.52
 Mean episode rew_tracking_lin_vel: 0.1792
 Mean episode rew_tracking_ang_vel: 0.0869
        Mean episode rew_lin_vel_z: -0.0258
      Mean episode rew_base_height: -1.1695
      Mean episode rew_action_rate: -0.0775
Mean episode rew_similar_to_default: -0.4028
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.1399
--------------------------------------------------------------------------------
                   Total timesteps: 588288
                    Iteration time: 0.17s
                        Total time: 63.70s
                               ETA: 19.6s

################################################################################
                      [1m Learning iteration 383/500 [0m

                       Computation: 9322 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 3.4743
                    Surrogate loss: -0.0054
             Mean action noise std: 1.02
                 Mean total reward: 147.44
               Mean episode length: 544.71
 Mean episode rew_tracking_lin_vel: 0.2479
 Mean episode rew_tracking_ang_vel: 0.1204
        Mean episode rew_lin_vel_z: -0.0247
      Mean episode rew_base_height: -1.6266
      Mean episode rew_action_rate: -0.1060
Mean episode rew_similar_to_default: -0.5567
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.2451
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 0.16s
                        Total time: 63.87s
                               ETA: 19.5s

################################################################################
                      [1m Learning iteration 384/500 [0m

                       Computation: 9291 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 0.1025
                    Surrogate loss: -0.0055
             Mean action noise std: 1.02
                 Mean total reward: 150.21
               Mean episode length: 554.62
 Mean episode rew_tracking_lin_vel: 0.3472
 Mean episode rew_tracking_ang_vel: 0.1672
        Mean episode rew_lin_vel_z: -0.0263
      Mean episode rew_base_height: -2.2839
      Mean episode rew_action_rate: -0.1503
Mean episode rew_similar_to_default: -0.7812
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.0135
--------------------------------------------------------------------------------
                   Total timesteps: 591360
                    Iteration time: 0.17s
                        Total time: 64.03s
                               ETA: 19.3s

################################################################################
                      [1m Learning iteration 385/500 [0m

                       Computation: 9227 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 2.9996
                    Surrogate loss: -0.0090
             Mean action noise std: 1.03
                 Mean total reward: 150.72
               Mean episode length: 556.31
 Mean episode rew_tracking_lin_vel: 0.3260
 Mean episode rew_tracking_ang_vel: 0.1567
        Mean episode rew_lin_vel_z: -0.0265
      Mean episode rew_base_height: -2.1481
      Mean episode rew_action_rate: -0.1417
Mean episode rew_similar_to_default: -0.7351
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.0811
--------------------------------------------------------------------------------
                   Total timesteps: 592896
                    Iteration time: 0.17s
                        Total time: 64.20s
                               ETA: 19.1s

################################################################################
                      [1m Learning iteration 386/500 [0m

                       Computation: 9207 steps/s (collection: 0.138s, learning 0.028s)
               Value function loss: 3.6551
                    Surrogate loss: -0.0078
             Mean action noise std: 1.03
                 Mean total reward: 152.71
               Mean episode length: 563.47
 Mean episode rew_tracking_lin_vel: 0.2699
 Mean episode rew_tracking_ang_vel: 0.1313
        Mean episode rew_lin_vel_z: -0.0239
      Mean episode rew_base_height: -1.7742
      Mean episode rew_action_rate: -0.1131
Mean episode rew_similar_to_default: -0.6050
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.2407
--------------------------------------------------------------------------------
                   Total timesteps: 594432
                    Iteration time: 0.17s
                        Total time: 64.36s
                               ETA: 19.0s

################################################################################
                      [1m Learning iteration 387/500 [0m

                       Computation: 9077 steps/s (collection: 0.140s, learning 0.029s)
               Value function loss: 0.0867
                    Surrogate loss: -0.0072
             Mean action noise std: 1.03
                 Mean total reward: 155.66
               Mean episode length: 574.14
 Mean episode rew_tracking_lin_vel: 0.3642
 Mean episode rew_tracking_ang_vel: 0.1754
        Mean episode rew_lin_vel_z: -0.0241
      Mean episode rew_base_height: -2.3978
      Mean episode rew_action_rate: -0.1546
Mean episode rew_similar_to_default: -0.8194
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.5378
--------------------------------------------------------------------------------
                   Total timesteps: 595968
                    Iteration time: 0.17s
                        Total time: 64.53s
                               ETA: 18.8s

################################################################################
                      [1m Learning iteration 388/500 [0m

                       Computation: 9255 steps/s (collection: 0.137s, learning 0.029s)
               Value function loss: 5.3552
                    Surrogate loss: -0.0098
             Mean action noise std: 1.03
                 Mean total reward: 154.43
               Mean episode length: 569.34
 Mean episode rew_tracking_lin_vel: 0.2247
 Mean episode rew_tracking_ang_vel: 0.1083
        Mean episode rew_lin_vel_z: -0.0239
      Mean episode rew_base_height: -1.4724
      Mean episode rew_action_rate: -0.0980
Mean episode rew_similar_to_default: -0.5081
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.1395
--------------------------------------------------------------------------------
                   Total timesteps: 597504
                    Iteration time: 0.17s
                        Total time: 64.70s
                               ETA: 18.6s

################################################################################
                      [1m Learning iteration 389/500 [0m

                       Computation: 9586 steps/s (collection: 0.132s, learning 0.029s)
               Value function loss: 0.1063
                    Surrogate loss: 0.0057
             Mean action noise std: 1.03
                 Mean total reward: 154.43
               Mean episode length: 569.34
 Mean episode rew_tracking_lin_vel: 0.3610
 Mean episode rew_tracking_ang_vel: 0.1725
        Mean episode rew_lin_vel_z: -0.0242
      Mean episode rew_base_height: -2.3652
      Mean episode rew_action_rate: -0.1522
Mean episode rew_similar_to_default: -0.8063
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 599040
                    Iteration time: 0.16s
                        Total time: 64.86s
                               ETA: 18.5s

################################################################################
                      [1m Learning iteration 390/500 [0m

                       Computation: 9278 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 8.6924
                    Surrogate loss: 0.0082
             Mean action noise std: 1.03
                 Mean total reward: 148.71
               Mean episode length: 548.04
 Mean episode rew_tracking_lin_vel: 0.2090
 Mean episode rew_tracking_ang_vel: 0.0996
        Mean episode rew_lin_vel_z: -0.0244
      Mean episode rew_base_height: -1.3614
      Mean episode rew_action_rate: -0.0888
Mean episode rew_similar_to_default: -0.4664
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.5906
--------------------------------------------------------------------------------
                   Total timesteps: 600576
                    Iteration time: 0.17s
                        Total time: 65.03s
                               ETA: 18.3s

################################################################################
                      [1m Learning iteration 391/500 [0m

                       Computation: 9373 steps/s (collection: 0.135s, learning 0.029s)
               Value function loss: 2.8708
                    Surrogate loss: -0.0092
             Mean action noise std: 1.03
                 Mean total reward: 148.73
               Mean episode length: 548.12
 Mean episode rew_tracking_lin_vel: 0.0840
 Mean episode rew_tracking_ang_vel: 0.0396
        Mean episode rew_lin_vel_z: -0.0238
      Mean episode rew_base_height: -0.5349
      Mean episode rew_action_rate: -0.0379
Mean episode rew_similar_to_default: -0.1901
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.8129
--------------------------------------------------------------------------------
                   Total timesteps: 602112
                    Iteration time: 0.16s
                        Total time: 65.19s
                               ETA: 18.1s

################################################################################
                      [1m Learning iteration 392/500 [0m

                       Computation: 9270 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 1.2382
                    Surrogate loss: -0.0031
             Mean action noise std: 1.03
                 Mean total reward: 149.54
               Mean episode length: 551.08
 Mean episode rew_tracking_lin_vel: 0.1080
 Mean episode rew_tracking_ang_vel: 0.0524
        Mean episode rew_lin_vel_z: -0.0250
      Mean episode rew_base_height: -0.7061
      Mean episode rew_action_rate: -0.0455
Mean episode rew_similar_to_default: -0.2485
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.8988
--------------------------------------------------------------------------------
                   Total timesteps: 603648
                    Iteration time: 0.17s
                        Total time: 65.35s
                               ETA: 18.0s

################################################################################
                      [1m Learning iteration 393/500 [0m

                       Computation: 9055 steps/s (collection: 0.141s, learning 0.029s)
               Value function loss: 3.9447
                    Surrogate loss: -0.0042
             Mean action noise std: 1.03
                 Mean total reward: 153.72
               Mean episode length: 565.93
 Mean episode rew_tracking_lin_vel: 0.2363
 Mean episode rew_tracking_ang_vel: 0.1140
        Mean episode rew_lin_vel_z: -0.0246
      Mean episode rew_base_height: -1.5531
      Mean episode rew_action_rate: -0.1012
Mean episode rew_similar_to_default: -0.5374
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.7040
--------------------------------------------------------------------------------
                   Total timesteps: 605184
                    Iteration time: 0.17s
                        Total time: 65.52s
                               ETA: 17.8s

################################################################################
                      [1m Learning iteration 394/500 [0m

                       Computation: 9384 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 1.8434
                    Surrogate loss: -0.0060
             Mean action noise std: 1.03
                 Mean total reward: 153.79
               Mean episode length: 565.98
 Mean episode rew_tracking_lin_vel: 0.2587
 Mean episode rew_tracking_ang_vel: 0.1244
        Mean episode rew_lin_vel_z: -0.0228
      Mean episode rew_base_height: -1.7106
      Mean episode rew_action_rate: -0.1110
Mean episode rew_similar_to_default: -0.5839
Mean episode rew_joint_pose_matching: 0.0015
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.8619
--------------------------------------------------------------------------------
                   Total timesteps: 606720
                    Iteration time: 0.16s
                        Total time: 65.69s
                               ETA: 17.6s

################################################################################
                      [1m Learning iteration 395/500 [0m

                       Computation: 9001 steps/s (collection: 0.140s, learning 0.031s)
               Value function loss: 2.5287
                    Surrogate loss: -0.0079
             Mean action noise std: 1.03
                 Mean total reward: 159.43
               Mean episode length: 586.33
 Mean episode rew_tracking_lin_vel: 0.2993
 Mean episode rew_tracking_ang_vel: 0.1434
        Mean episode rew_lin_vel_z: -0.0253
      Mean episode rew_base_height: -1.9764
      Mean episode rew_action_rate: -0.1293
Mean episode rew_similar_to_default: -0.6797
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.5646
--------------------------------------------------------------------------------
                   Total timesteps: 608256
                    Iteration time: 0.17s
                        Total time: 65.86s
                               ETA: 17.5s

################################################################################
                      [1m Learning iteration 396/500 [0m

                       Computation: 9095 steps/s (collection: 0.140s, learning 0.029s)
               Value function loss: 3.4628
                    Surrogate loss: -0.0021
             Mean action noise std: 1.03
                 Mean total reward: 161.20
               Mean episode length: 592.61
 Mean episode rew_tracking_lin_vel: 0.2736
 Mean episode rew_tracking_ang_vel: 0.1300
        Mean episode rew_lin_vel_z: -0.0252
      Mean episode rew_base_height: -1.8030
      Mean episode rew_action_rate: -0.1192
Mean episode rew_similar_to_default: -0.6208
Mean episode rew_joint_pose_matching: 0.0019
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.4708
--------------------------------------------------------------------------------
                   Total timesteps: 609792
                    Iteration time: 0.17s
                        Total time: 66.03s
                               ETA: 17.3s

################################################################################
                      [1m Learning iteration 397/500 [0m

                       Computation: 9109 steps/s (collection: 0.138s, learning 0.030s)
               Value function loss: 3.0858
                    Surrogate loss: -0.0075
             Mean action noise std: 1.03
                 Mean total reward: 161.83
               Mean episode length: 594.53
 Mean episode rew_tracking_lin_vel: 0.2076
 Mean episode rew_tracking_ang_vel: 0.1000
        Mean episode rew_lin_vel_z: -0.0241
      Mean episode rew_base_height: -1.3713
      Mean episode rew_action_rate: -0.0904
Mean episode rew_similar_to_default: -0.4738
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.5851
--------------------------------------------------------------------------------
                   Total timesteps: 611328
                    Iteration time: 0.17s
                        Total time: 66.20s
                               ETA: 17.1s

################################################################################
                      [1m Learning iteration 398/500 [0m

                       Computation: 9340 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 0.0772
                    Surrogate loss: -0.0028
             Mean action noise std: 1.03
                 Mean total reward: 161.83
               Mean episode length: 594.53
 Mean episode rew_tracking_lin_vel: 0.3640
 Mean episode rew_tracking_ang_vel: 0.1750
        Mean episode rew_lin_vel_z: -0.0255
      Mean episode rew_base_height: -2.4136
      Mean episode rew_action_rate: -0.1559
Mean episode rew_similar_to_default: -0.8295
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.5887
--------------------------------------------------------------------------------
                   Total timesteps: 612864
                    Iteration time: 0.16s
                        Total time: 66.36s
                               ETA: 17.0s

################################################################################
                      [1m Learning iteration 399/500 [0m

                       Computation: 9402 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 0.0755
                    Surrogate loss: -0.0019
             Mean action noise std: 1.03
                 Mean total reward: 164.58
               Mean episode length: 604.01
 Mean episode rew_tracking_lin_vel: 0.3640
 Mean episode rew_tracking_ang_vel: 0.1744
        Mean episode rew_lin_vel_z: -0.0253
      Mean episode rew_base_height: -2.4129
      Mean episode rew_action_rate: -0.1565
Mean episode rew_similar_to_default: -0.8304
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.7230
--------------------------------------------------------------------------------
                   Total timesteps: 614400
                    Iteration time: 0.16s
                        Total time: 66.52s
                               ETA: 16.8s

################################################################################
                      [1m Learning iteration 400/500 [0m

                       Computation: 9138 steps/s (collection: 0.138s, learning 0.030s)
               Value function loss: 1.6554
                    Surrogate loss: -0.0008
             Mean action noise std: 1.03
                 Mean total reward: 165.81
               Mean episode length: 608.03
 Mean episode rew_tracking_lin_vel: 0.3178
 Mean episode rew_tracking_ang_vel: 0.1518
        Mean episode rew_lin_vel_z: -0.0251
      Mean episode rew_base_height: -2.1102
      Mean episode rew_action_rate: -0.1389
Mean episode rew_similar_to_default: -0.7302
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.8415
--------------------------------------------------------------------------------
                   Total timesteps: 615936
                    Iteration time: 0.17s
                        Total time: 66.69s
                               ETA: 16.6s

################################################################################
                      [1m Learning iteration 401/500 [0m

                       Computation: 9339 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 0.0449
                    Surrogate loss: -0.0058
             Mean action noise std: 1.03
                 Mean total reward: 166.46
               Mean episode length: 610.50
 Mean episode rew_tracking_lin_vel: 0.3629
 Mean episode rew_tracking_ang_vel: 0.1732
        Mean episode rew_lin_vel_z: -0.0271
      Mean episode rew_base_height: -2.4116
      Mean episode rew_action_rate: -0.1590
Mean episode rew_similar_to_default: -0.8336
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.8682
--------------------------------------------------------------------------------
                   Total timesteps: 617472
                    Iteration time: 0.16s
                        Total time: 66.86s
                               ETA: 16.5s

################################################################################
                      [1m Learning iteration 402/500 [0m

                       Computation: 8898 steps/s (collection: 0.140s, learning 0.033s)
               Value function loss: 8.5927
                    Surrogate loss: 0.0010
             Mean action noise std: 1.03
                 Mean total reward: 163.85
               Mean episode length: 600.39
 Mean episode rew_tracking_lin_vel: 0.2751
 Mean episode rew_tracking_ang_vel: 0.1310
        Mean episode rew_lin_vel_z: -0.0253
      Mean episode rew_base_height: -1.8203
      Mean episode rew_action_rate: -0.1229
Mean episode rew_similar_to_default: -0.6265
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.5646
--------------------------------------------------------------------------------
                   Total timesteps: 619008
                    Iteration time: 0.17s
                        Total time: 67.03s
                               ETA: 16.3s

################################################################################
                      [1m Learning iteration 403/500 [0m

                       Computation: 9311 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 0.1164
                    Surrogate loss: 0.0001
             Mean action noise std: 1.03
                 Mean total reward: 164.38
               Mean episode length: 602.25
 Mean episode rew_tracking_lin_vel: 0.1394
 Mean episode rew_tracking_ang_vel: 0.0678
        Mean episode rew_lin_vel_z: -0.0251
      Mean episode rew_base_height: -0.9098
      Mean episode rew_action_rate: -0.0619
Mean episode rew_similar_to_default: -0.3162
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.3357
--------------------------------------------------------------------------------
                   Total timesteps: 620544
                    Iteration time: 0.16s
                        Total time: 67.19s
                               ETA: 16.1s

################################################################################
                      [1m Learning iteration 404/500 [0m

                       Computation: 9178 steps/s (collection: 0.136s, learning 0.031s)
               Value function loss: 2.7910
                    Surrogate loss: -0.0032
             Mean action noise std: 1.03
                 Mean total reward: 168.13
               Mean episode length: 615.62
 Mean episode rew_tracking_lin_vel: 0.3136
 Mean episode rew_tracking_ang_vel: 0.1514
        Mean episode rew_lin_vel_z: -0.0266
      Mean episode rew_base_height: -2.0728
      Mean episode rew_action_rate: -0.1373
Mean episode rew_similar_to_default: -0.7163
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.3258
--------------------------------------------------------------------------------
                   Total timesteps: 622080
                    Iteration time: 0.17s
                        Total time: 67.36s
                               ETA: 16.0s

################################################################################
                      [1m Learning iteration 405/500 [0m

                       Computation: 9325 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 3.6803
                    Surrogate loss: -0.0075
             Mean action noise std: 1.03
                 Mean total reward: 168.28
               Mean episode length: 616.25
 Mean episode rew_tracking_lin_vel: 0.3298
 Mean episode rew_tracking_ang_vel: 0.1595
        Mean episode rew_lin_vel_z: -0.0261
      Mean episode rew_base_height: -2.1762
      Mean episode rew_action_rate: -0.1418
Mean episode rew_similar_to_default: -0.7533
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.9112
--------------------------------------------------------------------------------
                   Total timesteps: 623616
                    Iteration time: 0.16s
                        Total time: 67.53s
                               ETA: 15.8s

################################################################################
                      [1m Learning iteration 406/500 [0m

                       Computation: 9391 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 0.0910
                    Surrogate loss: -0.0073
             Mean action noise std: 1.03
                 Mean total reward: 173.71
               Mean episode length: 635.86
 Mean episode rew_tracking_lin_vel: 0.2864
 Mean episode rew_tracking_ang_vel: 0.1378
        Mean episode rew_lin_vel_z: -0.0258
      Mean episode rew_base_height: -1.8929
      Mean episode rew_action_rate: -0.1235
Mean episode rew_similar_to_default: -0.6566
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.1063
--------------------------------------------------------------------------------
                   Total timesteps: 625152
                    Iteration time: 0.16s
                        Total time: 67.69s
                               ETA: 15.6s

################################################################################
                      [1m Learning iteration 407/500 [0m

                       Computation: 9399 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 4.2558
                    Surrogate loss: -0.0071
             Mean action noise std: 1.03
                 Mean total reward: 170.51
               Mean episode length: 624.03
 Mean episode rew_tracking_lin_vel: 0.1239
 Mean episode rew_tracking_ang_vel: 0.0598
        Mean episode rew_lin_vel_z: -0.0211
      Mean episode rew_base_height: -0.8054
      Mean episode rew_action_rate: -0.0557
Mean episode rew_similar_to_default: -0.2808
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.7371
--------------------------------------------------------------------------------
                   Total timesteps: 626688
                    Iteration time: 0.16s
                        Total time: 67.85s
                               ETA: 15.5s

################################################################################
                      [1m Learning iteration 408/500 [0m

                       Computation: 9266 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 5.5734
                    Surrogate loss: -0.0035
             Mean action noise std: 1.03
                 Mean total reward: 169.09
               Mean episode length: 618.47
 Mean episode rew_tracking_lin_vel: 0.2078
 Mean episode rew_tracking_ang_vel: 0.0990
        Mean episode rew_lin_vel_z: -0.0234
      Mean episode rew_base_height: -1.3671
      Mean episode rew_action_rate: -0.0905
Mean episode rew_similar_to_default: -0.4754
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.5967
--------------------------------------------------------------------------------
                   Total timesteps: 628224
                    Iteration time: 0.17s
                        Total time: 68.02s
                               ETA: 15.3s

################################################################################
                      [1m Learning iteration 409/500 [0m

                       Computation: 9176 steps/s (collection: 0.138s, learning 0.029s)
               Value function loss: 8.7992
                    Surrogate loss: -0.0066
             Mean action noise std: 1.03
                 Mean total reward: 166.86
               Mean episode length: 609.82
 Mean episode rew_tracking_lin_vel: 0.0861
 Mean episode rew_tracking_ang_vel: 0.0403
        Mean episode rew_lin_vel_z: -0.0242
      Mean episode rew_base_height: -0.5534
      Mean episode rew_action_rate: -0.0398
Mean episode rew_similar_to_default: -0.1949
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.9698
--------------------------------------------------------------------------------
                   Total timesteps: 629760
                    Iteration time: 0.17s
                        Total time: 68.19s
                               ETA: 15.1s

################################################################################
                      [1m Learning iteration 410/500 [0m

                       Computation: 9252 steps/s (collection: 0.138s, learning 0.028s)
               Value function loss: 5.4771
                    Surrogate loss: -0.0024
             Mean action noise std: 1.03
                 Mean total reward: 166.20
               Mean episode length: 606.62
 Mean episode rew_tracking_lin_vel: 0.2612
 Mean episode rew_tracking_ang_vel: 0.1239
        Mean episode rew_lin_vel_z: -0.0268
      Mean episode rew_base_height: -1.7305
      Mean episode rew_action_rate: -0.1162
Mean episode rew_similar_to_default: -0.6004
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.0661
--------------------------------------------------------------------------------
                   Total timesteps: 631296
                    Iteration time: 0.17s
                        Total time: 68.35s
                               ETA: 15.0s

################################################################################
                      [1m Learning iteration 411/500 [0m

                       Computation: 9407 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 0.0918
                    Surrogate loss: -0.0091
             Mean action noise std: 1.03
                 Mean total reward: 166.17
               Mean episode length: 606.62
 Mean episode rew_tracking_lin_vel: 0.3630
 Mean episode rew_tracking_ang_vel: 0.1728
        Mean episode rew_lin_vel_z: -0.0271
      Mean episode rew_base_height: -2.4108
      Mean episode rew_action_rate: -0.1624
Mean episode rew_similar_to_default: -0.8364
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.7412
--------------------------------------------------------------------------------
                   Total timesteps: 632832
                    Iteration time: 0.16s
                        Total time: 68.52s
                               ETA: 14.8s

################################################################################
                      [1m Learning iteration 412/500 [0m

                       Computation: 9419 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 5.0767
                    Surrogate loss: -0.0084
             Mean action noise std: 1.03
                 Mean total reward: 164.51
               Mean episode length: 600.25
 Mean episode rew_tracking_lin_vel: 0.2455
 Mean episode rew_tracking_ang_vel: 0.1178
        Mean episode rew_lin_vel_z: -0.0252
      Mean episode rew_base_height: -1.6196
      Mean episode rew_action_rate: -0.1078
Mean episode rew_similar_to_default: -0.5619
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.2552
--------------------------------------------------------------------------------
                   Total timesteps: 634368
                    Iteration time: 0.16s
                        Total time: 68.68s
                               ETA: 14.6s

################################################################################
                      [1m Learning iteration 413/500 [0m

                       Computation: 9417 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 3.4540
                    Surrogate loss: -0.0059
             Mean action noise std: 1.03
                 Mean total reward: 163.59
               Mean episode length: 596.69
 Mean episode rew_tracking_lin_vel: 0.1634
 Mean episode rew_tracking_ang_vel: 0.0783
        Mean episode rew_lin_vel_z: -0.0245
      Mean episode rew_base_height: -1.0663
      Mean episode rew_action_rate: -0.0724
Mean episode rew_similar_to_default: -0.3699
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.5269
--------------------------------------------------------------------------------
                   Total timesteps: 635904
                    Iteration time: 0.16s
                        Total time: 68.84s
                               ETA: 14.5s

################################################################################
                      [1m Learning iteration 414/500 [0m

                       Computation: 9371 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 2.3628
                    Surrogate loss: -0.0059
             Mean action noise std: 1.03
                 Mean total reward: 162.53
               Mean episode length: 592.34
 Mean episode rew_tracking_lin_vel: 0.2161
 Mean episode rew_tracking_ang_vel: 0.1021
        Mean episode rew_lin_vel_z: -0.0230
      Mean episode rew_base_height: -1.4225
      Mean episode rew_action_rate: -0.0980
Mean episode rew_similar_to_default: -0.4941
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.0695
--------------------------------------------------------------------------------
                   Total timesteps: 637440
                    Iteration time: 0.16s
                        Total time: 69.01s
                               ETA: 14.3s

################################################################################
                      [1m Learning iteration 415/500 [0m

                       Computation: 9039 steps/s (collection: 0.138s, learning 0.032s)
               Value function loss: 0.0952
                    Surrogate loss: -0.0047
             Mean action noise std: 1.03
                 Mean total reward: 169.02
               Mean episode length: 615.86
 Mean episode rew_tracking_lin_vel: 0.3630
 Mean episode rew_tracking_ang_vel: 0.1736
        Mean episode rew_lin_vel_z: -0.0265
      Mean episode rew_base_height: -2.4057
      Mean episode rew_action_rate: -0.1594
Mean episode rew_similar_to_default: -0.8350
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.6724
--------------------------------------------------------------------------------
                   Total timesteps: 638976
                    Iteration time: 0.17s
                        Total time: 69.18s
                               ETA: 14.1s

################################################################################
                      [1m Learning iteration 416/500 [0m

                       Computation: 9013 steps/s (collection: 0.136s, learning 0.035s)
               Value function loss: 3.5316
                    Surrogate loss: -0.0086
             Mean action noise std: 1.03
                 Mean total reward: 172.77
               Mean episode length: 629.48
 Mean episode rew_tracking_lin_vel: 0.2920
 Mean episode rew_tracking_ang_vel: 0.1401
        Mean episode rew_lin_vel_z: -0.0259
      Mean episode rew_base_height: -1.9259
      Mean episode rew_action_rate: -0.1254
Mean episode rew_similar_to_default: -0.6699
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.3992
--------------------------------------------------------------------------------
                   Total timesteps: 640512
                    Iteration time: 0.17s
                        Total time: 69.35s
                               ETA: 14.0s

################################################################################
                      [1m Learning iteration 417/500 [0m

                       Computation: 9011 steps/s (collection: 0.138s, learning 0.032s)
               Value function loss: 0.1055
                    Surrogate loss: -0.0030
             Mean action noise std: 1.03
                 Mean total reward: 175.41
               Mean episode length: 638.98
 Mean episode rew_tracking_lin_vel: 0.3647
 Mean episode rew_tracking_ang_vel: 0.1719
        Mean episode rew_lin_vel_z: -0.0283
      Mean episode rew_base_height: -2.4077
      Mean episode rew_action_rate: -0.1572
Mean episode rew_similar_to_default: -0.8343
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.7784
--------------------------------------------------------------------------------
                   Total timesteps: 642048
                    Iteration time: 0.17s
                        Total time: 69.52s
                               ETA: 13.8s

################################################################################
                      [1m Learning iteration 418/500 [0m

                       Computation: 9649 steps/s (collection: 0.131s, learning 0.029s)
               Value function loss: 0.0811
                    Surrogate loss: -0.0008
             Mean action noise std: 1.03
                 Mean total reward: 175.41
               Mean episode length: 638.98
 Mean episode rew_tracking_lin_vel: 0.3647
 Mean episode rew_tracking_ang_vel: 0.1719
        Mean episode rew_lin_vel_z: -0.0283
      Mean episode rew_base_height: -2.4077
      Mean episode rew_action_rate: -0.1572
Mean episode rew_similar_to_default: -0.8343
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.7784
--------------------------------------------------------------------------------
                   Total timesteps: 643584
                    Iteration time: 0.16s
                        Total time: 69.68s
                               ETA: 13.6s

################################################################################
                      [1m Learning iteration 419/500 [0m

                       Computation: 9475 steps/s (collection: 0.132s, learning 0.030s)
               Value function loss: 5.6573
                    Surrogate loss: -0.0040
             Mean action noise std: 1.03
                 Mean total reward: 173.69
               Mean episode length: 632.54
 Mean episode rew_tracking_lin_vel: 0.2825
 Mean episode rew_tracking_ang_vel: 0.1325
        Mean episode rew_lin_vel_z: -0.0273
      Mean episode rew_base_height: -1.8611
      Mean episode rew_action_rate: -0.1233
Mean episode rew_similar_to_default: -0.6454
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.0251
--------------------------------------------------------------------------------
                   Total timesteps: 645120
                    Iteration time: 0.16s
                        Total time: 69.84s
                               ETA: 13.5s

################################################################################
                      [1m Learning iteration 420/500 [0m

                       Computation: 9288 steps/s (collection: 0.138s, learning 0.027s)
               Value function loss: 10.0126
                    Surrogate loss: -0.0046
             Mean action noise std: 1.03
                 Mean total reward: 177.36
               Mean episode length: 645.83
 Mean episode rew_tracking_lin_vel: 0.3103
 Mean episode rew_tracking_ang_vel: 0.1479
        Mean episode rew_lin_vel_z: -0.0273
      Mean episode rew_base_height: -2.0480
      Mean episode rew_action_rate: -0.1381
Mean episode rew_similar_to_default: -0.7127
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.2119
--------------------------------------------------------------------------------
                   Total timesteps: 646656
                    Iteration time: 0.17s
                        Total time: 70.00s
                               ETA: 13.3s

################################################################################
                      [1m Learning iteration 421/500 [0m

                       Computation: 9250 steps/s (collection: 0.137s, learning 0.029s)
               Value function loss: 7.2472
                    Surrogate loss: -0.0042
             Mean action noise std: 1.03
                 Mean total reward: 184.18
               Mean episode length: 670.47
 Mean episode rew_tracking_lin_vel: 0.2863
 Mean episode rew_tracking_ang_vel: 0.1353
        Mean episode rew_lin_vel_z: -0.0271
      Mean episode rew_base_height: -1.8821
      Mean episode rew_action_rate: -0.1263
Mean episode rew_similar_to_default: -0.6549
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.0630
--------------------------------------------------------------------------------
                   Total timesteps: 648192
                    Iteration time: 0.17s
                        Total time: 70.17s
                               ETA: 13.1s

################################################################################
                      [1m Learning iteration 422/500 [0m

                       Computation: 9772 steps/s (collection: 0.129s, learning 0.029s)
               Value function loss: 0.0974
                    Surrogate loss: -0.0049
             Mean action noise std: 1.03
                 Mean total reward: 184.18
               Mean episode length: 670.47
 Mean episode rew_tracking_lin_vel: 0.3641
 Mean episode rew_tracking_ang_vel: 0.1735
        Mean episode rew_lin_vel_z: -0.0273
      Mean episode rew_base_height: -2.4006
      Mean episode rew_action_rate: -0.1610
Mean episode rew_similar_to_default: -0.8369
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.5272
--------------------------------------------------------------------------------
                   Total timesteps: 649728
                    Iteration time: 0.16s
                        Total time: 70.33s
                               ETA: 13.0s

################################################################################
                      [1m Learning iteration 423/500 [0m

                       Computation: 9261 steps/s (collection: 0.138s, learning 0.028s)
               Value function loss: 6.9283
                    Surrogate loss: -0.0010
             Mean action noise std: 1.03
                 Mean total reward: 183.38
               Mean episode length: 667.20
 Mean episode rew_tracking_lin_vel: 0.3137
 Mean episode rew_tracking_ang_vel: 0.1506
        Mean episode rew_lin_vel_z: -0.0275
      Mean episode rew_base_height: -2.0712
      Mean episode rew_action_rate: -0.1404
Mean episode rew_similar_to_default: -0.7195
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.2875
--------------------------------------------------------------------------------
                   Total timesteps: 651264
                    Iteration time: 0.17s
                        Total time: 70.49s
                               ETA: 12.8s

################################################################################
                      [1m Learning iteration 424/500 [0m

                       Computation: 8481 steps/s (collection: 0.141s, learning 0.040s)
               Value function loss: 8.5827
                    Surrogate loss: 0.0005
             Mean action noise std: 1.03
                 Mean total reward: 176.43
               Mean episode length: 641.52
 Mean episode rew_tracking_lin_vel: 0.0790
 Mean episode rew_tracking_ang_vel: 0.0380
        Mean episode rew_lin_vel_z: -0.0255
      Mean episode rew_base_height: -0.5090
      Mean episode rew_action_rate: -0.0353
Mean episode rew_similar_to_default: -0.1780
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7420
--------------------------------------------------------------------------------
                   Total timesteps: 652800
                    Iteration time: 0.18s
                        Total time: 70.67s
                               ETA: 12.6s

################################################################################
                      [1m Learning iteration 425/500 [0m

                       Computation: 9340 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 2.5056
                    Surrogate loss: -0.0021
             Mean action noise std: 1.03
                 Mean total reward: 176.45
               Mean episode length: 641.51
 Mean episode rew_tracking_lin_vel: 0.1748
 Mean episode rew_tracking_ang_vel: 0.0836
        Mean episode rew_lin_vel_z: -0.0206
      Mean episode rew_base_height: -1.1456
      Mean episode rew_action_rate: -0.0780
Mean episode rew_similar_to_default: -0.3975
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.0359
--------------------------------------------------------------------------------
                   Total timesteps: 654336
                    Iteration time: 0.16s
                        Total time: 70.84s
                               ETA: 12.5s

################################################################################
                      [1m Learning iteration 426/500 [0m

                       Computation: 8674 steps/s (collection: 0.143s, learning 0.034s)
               Value function loss: 0.0955
                    Surrogate loss: -0.0051
             Mean action noise std: 1.03
                 Mean total reward: 176.45
               Mean episode length: 641.51
 Mean episode rew_tracking_lin_vel: 0.0033
 Mean episode rew_tracking_ang_vel: 0.0019
        Mean episode rew_lin_vel_z: -0.0127
      Mean episode rew_base_height: -0.0032
      Mean episode rew_action_rate: -0.0027
Mean episode rew_similar_to_default: -0.0029
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.1560
--------------------------------------------------------------------------------
                   Total timesteps: 655872
                    Iteration time: 0.18s
                        Total time: 71.01s
                               ETA: 12.3s

################################################################################
                      [1m Learning iteration 427/500 [0m

                       Computation: 8989 steps/s (collection: 0.141s, learning 0.030s)
               Value function loss: 8.7019
                    Surrogate loss: 0.0018
             Mean action noise std: 1.03
                 Mean total reward: 172.14
               Mean episode length: 625.17
 Mean episode rew_tracking_lin_vel: 0.0932
 Mean episode rew_tracking_ang_vel: 0.0438
        Mean episode rew_lin_vel_z: -0.0221
      Mean episode rew_base_height: -0.5980
      Mean episode rew_action_rate: -0.0425
Mean episode rew_similar_to_default: -0.2087
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.3587
--------------------------------------------------------------------------------
                   Total timesteps: 657408
                    Iteration time: 0.17s
                        Total time: 71.19s
                               ETA: 12.1s

################################################################################
                      [1m Learning iteration 428/500 [0m

                       Computation: 9430 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 2.5691
                    Surrogate loss: -0.0087
             Mean action noise std: 1.03
                 Mean total reward: 171.27
               Mean episode length: 621.94
 Mean episode rew_tracking_lin_vel: 0.2263
 Mean episode rew_tracking_ang_vel: 0.1078
        Mean episode rew_lin_vel_z: -0.0238
      Mean episode rew_base_height: -1.4909
      Mean episode rew_action_rate: -0.1021
Mean episode rew_similar_to_default: -0.5172
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.4570
--------------------------------------------------------------------------------
                   Total timesteps: 658944
                    Iteration time: 0.16s
                        Total time: 71.35s
                               ETA: 12.0s

################################################################################
                      [1m Learning iteration 429/500 [0m

                       Computation: 9078 steps/s (collection: 0.139s, learning 0.031s)
               Value function loss: 5.7018
                    Surrogate loss: -0.0052
             Mean action noise std: 1.03
                 Mean total reward: 176.20
               Mean episode length: 639.80
 Mean episode rew_tracking_lin_vel: 0.2923
 Mean episode rew_tracking_ang_vel: 0.1391
        Mean episode rew_lin_vel_z: -0.0268
      Mean episode rew_base_height: -1.9222
      Mean episode rew_action_rate: -0.1288
Mean episode rew_similar_to_default: -0.6640
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.3859
--------------------------------------------------------------------------------
                   Total timesteps: 660480
                    Iteration time: 0.17s
                        Total time: 71.52s
                               ETA: 11.8s

################################################################################
                      [1m Learning iteration 430/500 [0m

                       Computation: 8443 steps/s (collection: 0.154s, learning 0.028s)
               Value function loss: 16.9833
                    Surrogate loss: 0.0072
             Mean action noise std: 1.03
                 Mean total reward: 168.69
               Mean episode length: 611.80
 Mean episode rew_tracking_lin_vel: 0.0807
 Mean episode rew_tracking_ang_vel: 0.0385
        Mean episode rew_lin_vel_z: -0.0238
      Mean episode rew_base_height: -0.5200
      Mean episode rew_action_rate: -0.0372
Mean episode rew_similar_to_default: -0.1809
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7760
--------------------------------------------------------------------------------
                   Total timesteps: 662016
                    Iteration time: 0.18s
                        Total time: 71.70s
                               ETA: 11.6s

################################################################################
                      [1m Learning iteration 431/500 [0m

                       Computation: 8992 steps/s (collection: 0.140s, learning 0.031s)
               Value function loss: 3.2464
                    Surrogate loss: -0.0063
             Mean action noise std: 1.03
                 Mean total reward: 170.53
               Mean episode length: 618.18
 Mean episode rew_tracking_lin_vel: 0.0611
 Mean episode rew_tracking_ang_vel: 0.0291
        Mean episode rew_lin_vel_z: -0.0194
      Mean episode rew_base_height: -0.3907
      Mean episode rew_action_rate: -0.0285
Mean episode rew_similar_to_default: -0.1356
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 2.9313
--------------------------------------------------------------------------------
                   Total timesteps: 663552
                    Iteration time: 0.17s
                        Total time: 71.87s
                               ETA: 11.5s

################################################################################
                      [1m Learning iteration 432/500 [0m

                       Computation: 9058 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 0.9082
                    Surrogate loss: -0.0019
             Mean action noise std: 1.03
                 Mean total reward: 167.87
               Mean episode length: 608.24
 Mean episode rew_tracking_lin_vel: 0.2376
 Mean episode rew_tracking_ang_vel: 0.1111
        Mean episode rew_lin_vel_z: -0.0194
      Mean episode rew_base_height: -1.5636
      Mean episode rew_action_rate: -0.1028
Mean episode rew_similar_to_default: -0.5387
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.9681
--------------------------------------------------------------------------------
                   Total timesteps: 665088
                    Iteration time: 0.17s
                        Total time: 72.04s
                               ETA: 11.3s

################################################################################
                      [1m Learning iteration 433/500 [0m

                       Computation: 9011 steps/s (collection: 0.138s, learning 0.032s)
               Value function loss: 3.4001
                    Surrogate loss: -0.0068
             Mean action noise std: 1.03
                 Mean total reward: 168.02
               Mean episode length: 608.46
 Mean episode rew_tracking_lin_vel: 0.3093
 Mean episode rew_tracking_ang_vel: 0.1460
        Mean episode rew_lin_vel_z: -0.0276
      Mean episode rew_base_height: -2.0418
      Mean episode rew_action_rate: -0.1395
Mean episode rew_similar_to_default: -0.7044
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.3076
--------------------------------------------------------------------------------
                   Total timesteps: 666624
                    Iteration time: 0.17s
                        Total time: 72.21s
                               ETA: 11.1s

################################################################################
                      [1m Learning iteration 434/500 [0m

                       Computation: 9454 steps/s (collection: 0.133s, learning 0.029s)
               Value function loss: 0.1235
                    Surrogate loss: -0.0041
             Mean action noise std: 1.03
                 Mean total reward: 168.02
               Mean episode length: 608.46
 Mean episode rew_tracking_lin_vel: 0.1490
 Mean episode rew_tracking_ang_vel: 0.0706
        Mean episode rew_lin_vel_z: -0.0288
      Mean episode rew_base_height: -0.9723
      Mean episode rew_action_rate: -0.0717
Mean episode rew_similar_to_default: -0.3335
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.8896
--------------------------------------------------------------------------------
                   Total timesteps: 668160
                    Iteration time: 0.16s
                        Total time: 72.37s
                               ETA: 11.0s

################################################################################
                      [1m Learning iteration 435/500 [0m

                       Computation: 9365 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 0.0991
                    Surrogate loss: 0.0069
             Mean action noise std: 1.03
                 Mean total reward: 168.05
               Mean episode length: 608.46
 Mean episode rew_tracking_lin_vel: 0.2384
 Mean episode rew_tracking_ang_vel: 0.1115
        Mean episode rew_lin_vel_z: -0.0286
      Mean episode rew_base_height: -1.5660
      Mean episode rew_action_rate: -0.1100
Mean episode rew_similar_to_default: -0.5385
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.9926
--------------------------------------------------------------------------------
                   Total timesteps: 669696
                    Iteration time: 0.16s
                        Total time: 72.54s
                               ETA: 10.8s

################################################################################
                      [1m Learning iteration 436/500 [0m

                       Computation: 9384 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 3.4820
                    Surrogate loss: -0.0056
             Mean action noise std: 1.03
                 Mean total reward: 171.50
               Mean episode length: 620.65
 Mean episode rew_tracking_lin_vel: 0.3443
 Mean episode rew_tracking_ang_vel: 0.1602
        Mean episode rew_lin_vel_z: -0.0279
      Mean episode rew_base_height: -2.2715
      Mean episode rew_action_rate: -0.1552
Mean episode rew_similar_to_default: -0.7821
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.8923
--------------------------------------------------------------------------------
                   Total timesteps: 671232
                    Iteration time: 0.16s
                        Total time: 72.70s
                               ETA: 10.6s

################################################################################
                      [1m Learning iteration 437/500 [0m

                       Computation: 9191 steps/s (collection: 0.139s, learning 0.028s)
               Value function loss: 2.6372
                    Surrogate loss: -0.0053
             Mean action noise std: 1.03
                 Mean total reward: 169.98
               Mean episode length: 614.98
 Mean episode rew_tracking_lin_vel: 0.3036
 Mean episode rew_tracking_ang_vel: 0.1428
        Mean episode rew_lin_vel_z: -0.0255
      Mean episode rew_base_height: -2.0020
      Mean episode rew_action_rate: -0.1352
Mean episode rew_similar_to_default: -0.6890
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.1126
--------------------------------------------------------------------------------
                   Total timesteps: 672768
                    Iteration time: 0.17s
                        Total time: 72.87s
                               ETA: 10.5s

################################################################################
                      [1m Learning iteration 438/500 [0m

                       Computation: 8908 steps/s (collection: 0.143s, learning 0.030s)
               Value function loss: 5.1132
                    Surrogate loss: -0.0073
             Mean action noise std: 1.03
                 Mean total reward: 169.17
               Mean episode length: 611.64
 Mean episode rew_tracking_lin_vel: 0.2219
 Mean episode rew_tracking_ang_vel: 0.1053
        Mean episode rew_lin_vel_z: -0.0243
      Mean episode rew_base_height: -1.4608
      Mean episode rew_action_rate: -0.1029
Mean episode rew_similar_to_default: -0.5023
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.3651
--------------------------------------------------------------------------------
                   Total timesteps: 674304
                    Iteration time: 0.17s
                        Total time: 73.04s
                               ETA: 10.3s

################################################################################
                      [1m Learning iteration 439/500 [0m

                       Computation: 9234 steps/s (collection: 0.138s, learning 0.028s)
               Value function loss: 0.5834
                    Surrogate loss: -0.0021
             Mean action noise std: 1.03
                 Mean total reward: 169.95
               Mean episode length: 614.22
 Mean episode rew_tracking_lin_vel: 0.1681
 Mean episode rew_tracking_ang_vel: 0.0803
        Mean episode rew_lin_vel_z: -0.0231
      Mean episode rew_base_height: -1.1031
      Mean episode rew_action_rate: -0.0773
Mean episode rew_similar_to_default: -0.3794
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.0517
--------------------------------------------------------------------------------
                   Total timesteps: 675840
                    Iteration time: 0.17s
                        Total time: 73.21s
                               ETA: 10.1s

################################################################################
                      [1m Learning iteration 440/500 [0m

                       Computation: 9275 steps/s (collection: 0.136s, learning 0.029s)
               Value function loss: 10.1028
                    Surrogate loss: 0.0030
             Mean action noise std: 1.03
                 Mean total reward: 168.09
               Mean episode length: 606.87
 Mean episode rew_tracking_lin_vel: 0.1917
 Mean episode rew_tracking_ang_vel: 0.0907
        Mean episode rew_lin_vel_z: -0.0247
      Mean episode rew_base_height: -1.2582
      Mean episode rew_action_rate: -0.0887
Mean episode rew_similar_to_default: -0.4332
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.1705
--------------------------------------------------------------------------------
                   Total timesteps: 677376
                    Iteration time: 0.17s
                        Total time: 73.37s
                               ETA: 10.0s

################################################################################
                      [1m Learning iteration 441/500 [0m

                       Computation: 9299 steps/s (collection: 0.138s, learning 0.027s)
               Value function loss: 6.1959
                    Surrogate loss: -0.0088
             Mean action noise std: 1.03
                 Mean total reward: 168.09
               Mean episode length: 606.66
 Mean episode rew_tracking_lin_vel: 0.1328
 Mean episode rew_tracking_ang_vel: 0.0627
        Mean episode rew_lin_vel_z: -0.0245
      Mean episode rew_base_height: -0.8691
      Mean episode rew_action_rate: -0.0617
Mean episode rew_similar_to_default: -0.2988
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.2134
--------------------------------------------------------------------------------
                   Total timesteps: 678912
                    Iteration time: 0.17s
                        Total time: 73.54s
                               ETA: 9.8s

################################################################################
                      [1m Learning iteration 442/500 [0m

                       Computation: 9037 steps/s (collection: 0.139s, learning 0.031s)
               Value function loss: 2.5159
                    Surrogate loss: -0.0072
             Mean action noise std: 1.03
                 Mean total reward: 168.35
               Mean episode length: 607.46
 Mean episode rew_tracking_lin_vel: 0.2546
 Mean episode rew_tracking_ang_vel: 0.1205
        Mean episode rew_lin_vel_z: -0.0261
      Mean episode rew_base_height: -1.6770
      Mean episode rew_action_rate: -0.1160
Mean episode rew_similar_to_default: -0.5748
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 11.9178
--------------------------------------------------------------------------------
                   Total timesteps: 680448
                    Iteration time: 0.17s
                        Total time: 73.71s
                               ETA: 9.7s

################################################################################
                      [1m Learning iteration 443/500 [0m

                       Computation: 9028 steps/s (collection: 0.140s, learning 0.030s)
               Value function loss: 3.2410
                    Surrogate loss: -0.0064
             Mean action noise std: 1.03
                 Mean total reward: 168.92
               Mean episode length: 608.49
 Mean episode rew_tracking_lin_vel: 0.2550
 Mean episode rew_tracking_ang_vel: 0.1211
        Mean episode rew_lin_vel_z: -0.0268
      Mean episode rew_base_height: -1.6850
      Mean episode rew_action_rate: -0.1177
Mean episode rew_similar_to_default: -0.5760
Mean episode rew_joint_pose_matching: 0.0009
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.0072
--------------------------------------------------------------------------------
                   Total timesteps: 681984
                    Iteration time: 0.17s
                        Total time: 73.88s
                               ETA: 9.5s

################################################################################
                      [1m Learning iteration 444/500 [0m

                       Computation: 9395 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 2.8515
                    Surrogate loss: -0.0060
             Mean action noise std: 1.03
                 Mean total reward: 166.19
               Mean episode length: 598.62
 Mean episode rew_tracking_lin_vel: 0.2326
 Mean episode rew_tracking_ang_vel: 0.1093
        Mean episode rew_lin_vel_z: -0.0262
      Mean episode rew_base_height: -1.5312
      Mean episode rew_action_rate: -0.1087
Mean episode rew_similar_to_default: -0.5250
Mean episode rew_joint_pose_matching: 0.0017
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.8093
--------------------------------------------------------------------------------
                   Total timesteps: 683520
                    Iteration time: 0.16s
                        Total time: 74.04s
                               ETA: 9.3s

################################################################################
                      [1m Learning iteration 445/500 [0m

                       Computation: 9396 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 0.0859
                    Surrogate loss: -0.0090
             Mean action noise std: 1.03
                 Mean total reward: 166.19
               Mean episode length: 598.62
 Mean episode rew_tracking_lin_vel: 0.3622
 Mean episode rew_tracking_ang_vel: 0.1699
        Mean episode rew_lin_vel_z: -0.0267
      Mean episode rew_base_height: -2.3973
      Mean episode rew_action_rate: -0.1665
Mean episode rew_similar_to_default: -0.8247
Mean episode rew_joint_pose_matching: 0.0021
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.8105
--------------------------------------------------------------------------------
                   Total timesteps: 685056
                    Iteration time: 0.16s
                        Total time: 74.20s
                               ETA: 9.2s

################################################################################
                      [1m Learning iteration 446/500 [0m

                       Computation: 9383 steps/s (collection: 0.136s, learning 0.028s)
               Value function loss: 3.3617
                    Surrogate loss: -0.0066
             Mean action noise std: 1.03
                 Mean total reward: 166.52
               Mean episode length: 599.75
 Mean episode rew_tracking_lin_vel: 0.3490
 Mean episode rew_tracking_ang_vel: 0.1636
        Mean episode rew_lin_vel_z: -0.0267
      Mean episode rew_base_height: -2.3089
      Mean episode rew_action_rate: -0.1604
Mean episode rew_similar_to_default: -0.7943
Mean episode rew_joint_pose_matching: 0.0020
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.2022
--------------------------------------------------------------------------------
                   Total timesteps: 686592
                    Iteration time: 0.16s
                        Total time: 74.37s
                               ETA: 9.0s

################################################################################
                      [1m Learning iteration 447/500 [0m

                       Computation: 9378 steps/s (collection: 0.133s, learning 0.031s)
               Value function loss: 2.9395
                    Surrogate loss: -0.0085
             Mean action noise std: 1.03
                 Mean total reward: 167.11
               Mean episode length: 601.85
 Mean episode rew_tracking_lin_vel: 0.0631
 Mean episode rew_tracking_ang_vel: 0.0294
        Mean episode rew_lin_vel_z: -0.0255
      Mean episode rew_base_height: -0.4025
      Mean episode rew_action_rate: -0.0299
Mean episode rew_similar_to_default: -0.1388
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.0603
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 0.16s
                        Total time: 74.53s
                               ETA: 8.8s

################################################################################
                      [1m Learning iteration 448/500 [0m

                       Computation: 9459 steps/s (collection: 0.132s, learning 0.030s)
               Value function loss: 0.1162
                    Surrogate loss: -0.0082
             Mean action noise std: 1.03
                 Mean total reward: 167.11
               Mean episode length: 601.85
 Mean episode rew_tracking_lin_vel: 0.0789
 Mean episode rew_tracking_ang_vel: 0.0369
        Mean episode rew_lin_vel_z: -0.0254
      Mean episode rew_base_height: -0.5104
      Mean episode rew_action_rate: -0.0378
Mean episode rew_similar_to_default: -0.1747
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7789
--------------------------------------------------------------------------------
                   Total timesteps: 689664
                    Iteration time: 0.16s
                        Total time: 74.69s
                               ETA: 8.7s

################################################################################
                      [1m Learning iteration 449/500 [0m

                       Computation: 9697 steps/s (collection: 0.131s, learning 0.027s)
               Value function loss: 0.0950
                    Surrogate loss: -0.0119
             Mean action noise std: 1.03
                 Mean total reward: 167.11
               Mean episode length: 601.85
 Mean episode rew_tracking_lin_vel: 0.0789
 Mean episode rew_tracking_ang_vel: 0.0369
        Mean episode rew_lin_vel_z: -0.0254
      Mean episode rew_base_height: -0.5104
      Mean episode rew_action_rate: -0.0378
Mean episode rew_similar_to_default: -0.1747
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7789
--------------------------------------------------------------------------------
                   Total timesteps: 691200
                    Iteration time: 0.16s
                        Total time: 74.85s
                               ETA: 8.5s

################################################################################
                      [1m Learning iteration 450/500 [0m

                       Computation: 9600 steps/s (collection: 0.133s, learning 0.027s)
               Value function loss: 5.1811
                    Surrogate loss: -0.0082
             Mean action noise std: 1.03
                 Mean total reward: 166.06
               Mean episode length: 597.73
 Mean episode rew_tracking_lin_vel: 0.2613
 Mean episode rew_tracking_ang_vel: 0.1232
        Mean episode rew_lin_vel_z: -0.0257
      Mean episode rew_base_height: -1.7224
      Mean episode rew_action_rate: -0.1195
Mean episode rew_similar_to_default: -0.5894
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.2559
--------------------------------------------------------------------------------
                   Total timesteps: 692736
                    Iteration time: 0.16s
                        Total time: 75.01s
                               ETA: 8.3s

################################################################################
                      [1m Learning iteration 451/500 [0m

                       Computation: 9444 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 0.2098
                    Surrogate loss: 0.0025
             Mean action noise std: 1.03
                 Mean total reward: 171.32
               Mean episode length: 615.82
 Mean episode rew_tracking_lin_vel: 0.3619
 Mean episode rew_tracking_ang_vel: 0.1704
        Mean episode rew_lin_vel_z: -0.0252
      Mean episode rew_base_height: -2.3993
      Mean episode rew_action_rate: -0.1632
Mean episode rew_similar_to_default: -0.8189
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 17.0505
--------------------------------------------------------------------------------
                   Total timesteps: 694272
                    Iteration time: 0.16s
                        Total time: 75.18s
                               ETA: 8.1s

################################################################################
                      [1m Learning iteration 452/500 [0m

                       Computation: 9380 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 0.1639
                    Surrogate loss: 0.0048
             Mean action noise std: 1.03
                 Mean total reward: 175.08
               Mean episode length: 629.01
 Mean episode rew_tracking_lin_vel: 0.3621
 Mean episode rew_tracking_ang_vel: 0.1711
        Mean episode rew_lin_vel_z: -0.0267
      Mean episode rew_base_height: -2.4024
      Mean episode rew_action_rate: -0.1628
Mean episode rew_similar_to_default: -0.8201
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 17.1248
--------------------------------------------------------------------------------
                   Total timesteps: 695808
                    Iteration time: 0.16s
                        Total time: 75.34s
                               ETA: 8.0s

################################################################################
                      [1m Learning iteration 453/500 [0m

                       Computation: 9395 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 2.0566
                    Surrogate loss: -0.0056
             Mean action noise std: 1.03
                 Mean total reward: 175.60
               Mean episode length: 630.49
 Mean episode rew_tracking_lin_vel: 0.1586
 Mean episode rew_tracking_ang_vel: 0.0740
        Mean episode rew_lin_vel_z: -0.0261
      Mean episode rew_base_height: -1.0392
      Mean episode rew_action_rate: -0.0761
Mean episode rew_similar_to_default: -0.3563
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.6468
--------------------------------------------------------------------------------
                   Total timesteps: 697344
                    Iteration time: 0.16s
                        Total time: 75.50s
                               ETA: 7.8s

################################################################################
                      [1m Learning iteration 454/500 [0m

                       Computation: 8756 steps/s (collection: 0.140s, learning 0.036s)
               Value function loss: 3.4498
                    Surrogate loss: -0.0050
             Mean action noise std: 1.03
                 Mean total reward: 176.46
               Mean episode length: 633.23
 Mean episode rew_tracking_lin_vel: 0.1123
 Mean episode rew_tracking_ang_vel: 0.0519
        Mean episode rew_lin_vel_z: -0.0258
      Mean episode rew_base_height: -0.7279
      Mean episode rew_action_rate: -0.0553
Mean episode rew_similar_to_default: -0.2502
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.5159
--------------------------------------------------------------------------------
                   Total timesteps: 698880
                    Iteration time: 0.18s
                        Total time: 75.68s
                               ETA: 7.7s

################################################################################
                      [1m Learning iteration 455/500 [0m

                       Computation: 9102 steps/s (collection: 0.140s, learning 0.029s)
               Value function loss: 3.2270
                    Surrogate loss: -0.0067
             Mean action noise std: 1.03
                 Mean total reward: 177.41
               Mean episode length: 635.65
 Mean episode rew_tracking_lin_vel: 0.2623
 Mean episode rew_tracking_ang_vel: 0.1229
        Mean episode rew_lin_vel_z: -0.0273
      Mean episode rew_base_height: -1.7331
      Mean episode rew_action_rate: -0.1211
Mean episode rew_similar_to_default: -0.5910
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.5198
--------------------------------------------------------------------------------
                   Total timesteps: 700416
                    Iteration time: 0.17s
                        Total time: 75.85s
                               ETA: 7.5s

################################################################################
                      [1m Learning iteration 456/500 [0m

                       Computation: 9344 steps/s (collection: 0.135s, learning 0.029s)
               Value function loss: 0.1014
                    Surrogate loss: -0.0001
             Mean action noise std: 1.03
                 Mean total reward: 179.56
               Mean episode length: 642.91
 Mean episode rew_tracking_lin_vel: 0.3622
 Mean episode rew_tracking_ang_vel: 0.1710
        Mean episode rew_lin_vel_z: -0.0277
      Mean episode rew_base_height: -2.4017
      Mean episode rew_action_rate: -0.1636
Mean episode rew_similar_to_default: -0.8162
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.9597
--------------------------------------------------------------------------------
                   Total timesteps: 701952
                    Iteration time: 0.16s
                        Total time: 76.01s
                               ETA: 7.3s

################################################################################
                      [1m Learning iteration 457/500 [0m

                       Computation: 9380 steps/s (collection: 0.132s, learning 0.032s)
               Value function loss: 0.1417
                    Surrogate loss: -0.0046
             Mean action noise std: 1.03
                 Mean total reward: 179.63
               Mean episode length: 642.91
 Mean episode rew_tracking_lin_vel: 0.3620
 Mean episode rew_tracking_ang_vel: 0.1722
        Mean episode rew_lin_vel_z: -0.0287
      Mean episode rew_base_height: -2.4083
      Mean episode rew_action_rate: -0.1653
Mean episode rew_similar_to_default: -0.8162
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 17.1225
--------------------------------------------------------------------------------
                   Total timesteps: 703488
                    Iteration time: 0.16s
                        Total time: 76.17s
                               ETA: 7.2s

################################################################################
                      [1m Learning iteration 458/500 [0m

                       Computation: 8808 steps/s (collection: 0.144s, learning 0.031s)
               Value function loss: 1.0172
                    Surrogate loss: -0.0061
             Mean action noise std: 1.03
                 Mean total reward: 179.73
               Mean episode length: 642.22
 Mean episode rew_tracking_lin_vel: 0.2798
 Mean episode rew_tracking_ang_vel: 0.1301
        Mean episode rew_lin_vel_z: -0.0276
      Mean episode rew_base_height: -1.8522
      Mean episode rew_action_rate: -0.1294
Mean episode rew_similar_to_default: -0.6329
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4473
--------------------------------------------------------------------------------
                   Total timesteps: 705024
                    Iteration time: 0.17s
                        Total time: 76.35s
                               ETA: 7.0s

################################################################################
                      [1m Learning iteration 459/500 [0m

                       Computation: 9194 steps/s (collection: 0.137s, learning 0.030s)
               Value function loss: 9.2037
                    Surrogate loss: -0.0008
             Mean action noise std: 1.03
                 Mean total reward: 176.54
               Mean episode length: 630.20
 Mean episode rew_tracking_lin_vel: 0.1854
 Mean episode rew_tracking_ang_vel: 0.0865
        Mean episode rew_lin_vel_z: -0.0270
      Mean episode rew_base_height: -1.2217
      Mean episode rew_action_rate: -0.0860
Mean episode rew_similar_to_default: -0.4187
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.8509
--------------------------------------------------------------------------------
                   Total timesteps: 706560
                    Iteration time: 0.17s
                        Total time: 76.52s
                               ETA: 6.8s

################################################################################
                      [1m Learning iteration 460/500 [0m

                       Computation: 9217 steps/s (collection: 0.135s, learning 0.032s)
               Value function loss: 9.5472
                    Surrogate loss: -0.0053
             Mean action noise std: 1.03
                 Mean total reward: 174.87
               Mean episode length: 623.40
 Mean episode rew_tracking_lin_vel: 0.0777
 Mean episode rew_tracking_ang_vel: 0.0356
        Mean episode rew_lin_vel_z: -0.0265
      Mean episode rew_base_height: -0.4967
      Mean episode rew_action_rate: -0.0377
Mean episode rew_similar_to_default: -0.1733
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.7229
--------------------------------------------------------------------------------
                   Total timesteps: 708096
                    Iteration time: 0.17s
                        Total time: 76.68s
                               ETA: 6.7s

################################################################################
                      [1m Learning iteration 461/500 [0m

                       Computation: 8744 steps/s (collection: 0.145s, learning 0.031s)
               Value function loss: 18.9244
                    Surrogate loss: -0.0097
             Mean action noise std: 1.03
                 Mean total reward: 168.55
               Mean episode length: 599.11
 Mean episode rew_tracking_lin_vel: 0.1482
 Mean episode rew_tracking_ang_vel: 0.0696
        Mean episode rew_lin_vel_z: -0.0262
      Mean episode rew_base_height: -0.9706
      Mean episode rew_action_rate: -0.0691
Mean episode rew_similar_to_default: -0.3332
Mean episode rew_joint_pose_matching: 0.0003
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.0120
--------------------------------------------------------------------------------
                   Total timesteps: 709632
                    Iteration time: 0.18s
                        Total time: 76.86s
                               ETA: 6.5s

################################################################################
                      [1m Learning iteration 462/500 [0m

                       Computation: 9110 steps/s (collection: 0.137s, learning 0.031s)
               Value function loss: 0.1768
                    Surrogate loss: -0.0057
             Mean action noise std: 1.03
                 Mean total reward: 171.57
               Mean episode length: 609.07
 Mean episode rew_tracking_lin_vel: 0.3384
 Mean episode rew_tracking_ang_vel: 0.1583
        Mean episode rew_lin_vel_z: -0.0270
      Mean episode rew_base_height: -2.2546
      Mean episode rew_action_rate: -0.1604
Mean episode rew_similar_to_default: -0.7684
Mean episode rew_joint_pose_matching: 0.0006
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.0765
--------------------------------------------------------------------------------
                   Total timesteps: 711168
                    Iteration time: 0.17s
                        Total time: 77.03s
                               ETA: 6.3s

################################################################################
                      [1m Learning iteration 463/500 [0m

                       Computation: 8806 steps/s (collection: 0.144s, learning 0.031s)
               Value function loss: 1.9453
                    Surrogate loss: 0.0110
             Mean action noise std: 1.03
                 Mean total reward: 172.17
               Mean episode length: 610.95
 Mean episode rew_tracking_lin_vel: 0.2200
 Mean episode rew_tracking_ang_vel: 0.1010
        Mean episode rew_lin_vel_z: -0.0268
      Mean episode rew_base_height: -1.4594
      Mean episode rew_action_rate: -0.1037
Mean episode rew_similar_to_default: -0.5000
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.5931
--------------------------------------------------------------------------------
                   Total timesteps: 712704
                    Iteration time: 0.17s
                        Total time: 77.20s
                               ETA: 6.2s

################################################################################
                      [1m Learning iteration 464/500 [0m

                       Computation: 8909 steps/s (collection: 0.142s, learning 0.030s)
               Value function loss: 10.1189
                    Surrogate loss: 0.0065
             Mean action noise std: 1.03
                 Mean total reward: 172.65
               Mean episode length: 611.46
 Mean episode rew_tracking_lin_vel: 0.2535
 Mean episode rew_tracking_ang_vel: 0.1154
        Mean episode rew_lin_vel_z: -0.0280
      Mean episode rew_base_height: -1.6778
      Mean episode rew_action_rate: -0.1195
Mean episode rew_similar_to_default: -0.5752
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.2110
--------------------------------------------------------------------------------
                   Total timesteps: 714240
                    Iteration time: 0.17s
                        Total time: 77.37s
                               ETA: 6.0s

################################################################################
                      [1m Learning iteration 465/500 [0m

                       Computation: 9498 steps/s (collection: 0.134s, learning 0.028s)
               Value function loss: 1.8095
                    Surrogate loss: -0.0039
             Mean action noise std: 1.03
                 Mean total reward: 175.57
               Mean episode length: 620.98
 Mean episode rew_tracking_lin_vel: 0.1335
 Mean episode rew_tracking_ang_vel: 0.0610
        Mean episode rew_lin_vel_z: -0.0258
      Mean episode rew_base_height: -0.8756
      Mean episode rew_action_rate: -0.0643
Mean episode rew_similar_to_default: -0.3028
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.4798
--------------------------------------------------------------------------------
                   Total timesteps: 715776
                    Iteration time: 0.16s
                        Total time: 77.54s
                               ETA: 5.8s

################################################################################
                      [1m Learning iteration 466/500 [0m

                       Computation: 9189 steps/s (collection: 0.139s, learning 0.028s)
               Value function loss: 17.2368
                    Surrogate loss: -0.0060
             Mean action noise std: 1.03
                 Mean total reward: 177.26
               Mean episode length: 624.73
 Mean episode rew_tracking_lin_vel: 0.1580
 Mean episode rew_tracking_ang_vel: 0.0727
        Mean episode rew_lin_vel_z: -0.0171
      Mean episode rew_base_height: -1.0461
      Mean episode rew_action_rate: -0.0756
Mean episode rew_similar_to_default: -0.3574
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.6989
--------------------------------------------------------------------------------
                   Total timesteps: 717312
                    Iteration time: 0.17s
                        Total time: 77.70s
                               ETA: 5.7s

################################################################################
                      [1m Learning iteration 467/500 [0m

                       Computation: 9451 steps/s (collection: 0.135s, learning 0.027s)
               Value function loss: 7.2198
                    Surrogate loss: -0.0085
             Mean action noise std: 1.03
                 Mean total reward: 177.49
               Mean episode length: 624.64
 Mean episode rew_tracking_lin_vel: 0.1562
 Mean episode rew_tracking_ang_vel: 0.0714
        Mean episode rew_lin_vel_z: -0.0256
      Mean episode rew_base_height: -1.0286
      Mean episode rew_action_rate: -0.0769
Mean episode rew_similar_to_default: -0.3547
Mean episode rew_joint_pose_matching: 0.0013
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.5859
--------------------------------------------------------------------------------
                   Total timesteps: 718848
                    Iteration time: 0.16s
                        Total time: 77.87s
                               ETA: 5.5s

################################################################################
                      [1m Learning iteration 468/500 [0m

                       Computation: 8904 steps/s (collection: 0.142s, learning 0.031s)
               Value function loss: 9.8231
                    Surrogate loss: 0.0005
             Mean action noise std: 1.03
                 Mean total reward: 173.68
               Mean episode length: 610.47
 Mean episode rew_tracking_lin_vel: 0.0759
 Mean episode rew_tracking_ang_vel: 0.0346
        Mean episode rew_lin_vel_z: -0.0259
      Mean episode rew_base_height: -0.4902
      Mean episode rew_action_rate: -0.0379
Mean episode rew_similar_to_default: -0.1729
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.6915
--------------------------------------------------------------------------------
                   Total timesteps: 720384
                    Iteration time: 0.17s
                        Total time: 78.04s
                               ETA: 5.3s

################################################################################
                      [1m Learning iteration 469/500 [0m

                       Computation: 9086 steps/s (collection: 0.141s, learning 0.028s)
               Value function loss: 7.9468
                    Surrogate loss: 0.0009
             Mean action noise std: 1.03
                 Mean total reward: 174.62
               Mean episode length: 612.97
 Mean episode rew_tracking_lin_vel: 0.1104
 Mean episode rew_tracking_ang_vel: 0.0512
        Mean episode rew_lin_vel_z: -0.0251
      Mean episode rew_base_height: -0.7211
      Mean episode rew_action_rate: -0.0535
Mean episode rew_similar_to_default: -0.2503
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.3602
--------------------------------------------------------------------------------
                   Total timesteps: 721920
                    Iteration time: 0.17s
                        Total time: 78.21s
                               ETA: 5.2s

################################################################################
                      [1m Learning iteration 470/500 [0m

                       Computation: 8554 steps/s (collection: 0.146s, learning 0.034s)
               Value function loss: 0.9295
                    Surrogate loss: -0.0011
             Mean action noise std: 1.03
                 Mean total reward: 177.33
               Mean episode length: 622.20
 Mean episode rew_tracking_lin_vel: 0.2027
 Mean episode rew_tracking_ang_vel: 0.0928
        Mean episode rew_lin_vel_z: -0.0166
      Mean episode rew_base_height: -1.3414
      Mean episode rew_action_rate: -0.0945
Mean episode rew_similar_to_default: -0.4618
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.8038
--------------------------------------------------------------------------------
                   Total timesteps: 723456
                    Iteration time: 0.18s
                        Total time: 78.39s
                               ETA: 5.0s

################################################################################
                      [1m Learning iteration 471/500 [0m

                       Computation: 8664 steps/s (collection: 0.146s, learning 0.031s)
               Value function loss: 6.4290
                    Surrogate loss: -0.0024
             Mean action noise std: 1.03
                 Mean total reward: 176.81
               Mean episode length: 619.91
 Mean episode rew_tracking_lin_vel: 0.2186
 Mean episode rew_tracking_ang_vel: 0.1009
        Mean episode rew_lin_vel_z: -0.0269
      Mean episode rew_base_height: -1.4469
      Mean episode rew_action_rate: -0.1018
Mean episode rew_similar_to_default: -0.5012
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.5633
--------------------------------------------------------------------------------
                   Total timesteps: 724992
                    Iteration time: 0.18s
                        Total time: 78.56s
                               ETA: 4.8s

################################################################################
                      [1m Learning iteration 472/500 [0m

                       Computation: 8757 steps/s (collection: 0.144s, learning 0.031s)
               Value function loss: 2.0132
                    Surrogate loss: -0.0056
             Mean action noise std: 1.03
                 Mean total reward: 176.70
               Mean episode length: 618.06
 Mean episode rew_tracking_lin_vel: 0.2781
 Mean episode rew_tracking_ang_vel: 0.1266
        Mean episode rew_lin_vel_z: -0.0277
      Mean episode rew_base_height: -1.8417
      Mean episode rew_action_rate: -0.1361
Mean episode rew_similar_to_default: -0.6377
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.3918
--------------------------------------------------------------------------------
                   Total timesteps: 726528
                    Iteration time: 0.18s
                        Total time: 78.74s
                               ETA: 4.7s

################################################################################
                      [1m Learning iteration 473/500 [0m

                       Computation: 9104 steps/s (collection: 0.137s, learning 0.032s)
               Value function loss: 3.8575
                    Surrogate loss: -0.0085
             Mean action noise std: 1.03
                 Mean total reward: 174.74
               Mean episode length: 610.78
 Mean episode rew_tracking_lin_vel: 0.1288
 Mean episode rew_tracking_ang_vel: 0.0584
        Mean episode rew_lin_vel_z: -0.0273
      Mean episode rew_base_height: -0.8505
      Mean episode rew_action_rate: -0.0623
Mean episode rew_similar_to_default: -0.2986
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.3183
--------------------------------------------------------------------------------
                   Total timesteps: 728064
                    Iteration time: 0.17s
                        Total time: 78.91s
                               ETA: 4.5s

################################################################################
                      [1m Learning iteration 474/500 [0m

                       Computation: 8179 steps/s (collection: 0.157s, learning 0.031s)
               Value function loss: 0.6024
                    Surrogate loss: -0.0046
             Mean action noise std: 1.03
                 Mean total reward: 174.96
               Mean episode length: 610.90
 Mean episode rew_tracking_lin_vel: 0.3315
 Mean episode rew_tracking_ang_vel: 0.1520
        Mean episode rew_lin_vel_z: -0.0281
      Mean episode rew_base_height: -2.2045
      Mean episode rew_action_rate: -0.1560
Mean episode rew_similar_to_default: -0.7644
Mean episode rew_joint_pose_matching: 0.0015
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.1141
--------------------------------------------------------------------------------
                   Total timesteps: 729600
                    Iteration time: 0.19s
                        Total time: 79.10s
                               ETA: 4.3s

################################################################################
                      [1m Learning iteration 475/500 [0m

                       Computation: 9166 steps/s (collection: 0.140s, learning 0.028s)
               Value function loss: 0.1305
                    Surrogate loss: -0.0080
             Mean action noise std: 1.03
                 Mean total reward: 175.09
               Mean episode length: 610.90
 Mean episode rew_tracking_lin_vel: 0.3619
 Mean episode rew_tracking_ang_vel: 0.1652
        Mean episode rew_lin_vel_z: -0.0278
      Mean episode rew_base_height: -2.3974
      Mean episode rew_action_rate: -0.1700
Mean episode rew_similar_to_default: -0.8295
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 17.5334
--------------------------------------------------------------------------------
                   Total timesteps: 731136
                    Iteration time: 0.17s
                        Total time: 79.26s
                               ETA: 4.2s

################################################################################
                      [1m Learning iteration 476/500 [0m

                       Computation: 9524 steps/s (collection: 0.133s, learning 0.028s)
               Value function loss: 7.0754
                    Surrogate loss: 0.0016
             Mean action noise std: 1.03
                 Mean total reward: 177.11
               Mean episode length: 617.53
 Mean episode rew_tracking_lin_vel: 0.3090
 Mean episode rew_tracking_ang_vel: 0.1399
        Mean episode rew_lin_vel_z: -0.0271
      Mean episode rew_base_height: -2.0521
      Mean episode rew_action_rate: -0.1487
Mean episode rew_similar_to_default: -0.7121
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0006
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.0555
--------------------------------------------------------------------------------
                   Total timesteps: 732672
                    Iteration time: 0.16s
                        Total time: 79.42s
                               ETA: 4.0s

################################################################################
                      [1m Learning iteration 477/500 [0m

                       Computation: 9263 steps/s (collection: 0.137s, learning 0.029s)
               Value function loss: 3.1807
                    Surrogate loss: -0.0062
             Mean action noise std: 1.03
                 Mean total reward: 175.67
               Mean episode length: 611.41
 Mean episode rew_tracking_lin_vel: 0.1575
 Mean episode rew_tracking_ang_vel: 0.0714
        Mean episode rew_lin_vel_z: -0.0260
      Mean episode rew_base_height: -1.0435
      Mean episode rew_action_rate: -0.0773
Mean episode rew_similar_to_default: -0.3698
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.7220
--------------------------------------------------------------------------------
                   Total timesteps: 734208
                    Iteration time: 0.17s
                        Total time: 79.59s
                               ETA: 3.8s

################################################################################
                      [1m Learning iteration 478/500 [0m

                       Computation: 8786 steps/s (collection: 0.147s, learning 0.028s)
               Value function loss: 0.1268
                    Surrogate loss: -0.0067
             Mean action noise std: 1.03
                 Mean total reward: 175.67
               Mean episode length: 611.41
 Mean episode rew_tracking_lin_vel: 0.1386
 Mean episode rew_tracking_ang_vel: 0.0628
        Mean episode rew_lin_vel_z: -0.0257
      Mean episode rew_base_height: -0.9195
      Mean episode rew_action_rate: -0.0680
Mean episode rew_similar_to_default: -0.3272
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 6.8203
--------------------------------------------------------------------------------
                   Total timesteps: 735744
                    Iteration time: 0.17s
                        Total time: 79.76s
                               ETA: 3.7s

################################################################################
                      [1m Learning iteration 479/500 [0m

                       Computation: 9162 steps/s (collection: 0.138s, learning 0.030s)
               Value function loss: 4.8115
                    Surrogate loss: -0.0028
             Mean action noise std: 1.03
                 Mean total reward: 179.43
               Mean episode length: 623.53
 Mean episode rew_tracking_lin_vel: 0.2657
 Mean episode rew_tracking_ang_vel: 0.1192
        Mean episode rew_lin_vel_z: -0.0280
      Mean episode rew_base_height: -1.7695
      Mean episode rew_action_rate: -0.1301
Mean episode rew_similar_to_default: -0.6170
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.1285
--------------------------------------------------------------------------------
                   Total timesteps: 737280
                    Iteration time: 0.17s
                        Total time: 79.93s
                               ETA: 3.5s

################################################################################
                      [1m Learning iteration 480/500 [0m

                       Computation: 9353 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.1354
                    Surrogate loss: -0.0009
             Mean action noise std: 1.03
                 Mean total reward: 182.61
               Mean episode length: 633.59
 Mean episode rew_tracking_lin_vel: 0.2727
 Mean episode rew_tracking_ang_vel: 0.1230
        Mean episode rew_lin_vel_z: -0.0275
      Mean episode rew_base_height: -1.8166
      Mean episode rew_action_rate: -0.1347
Mean episode rew_similar_to_default: -0.6354
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.4415
--------------------------------------------------------------------------------
                   Total timesteps: 738816
                    Iteration time: 0.16s
                        Total time: 80.10s
                               ETA: 3.3s

################################################################################
                      [1m Learning iteration 481/500 [0m

                       Computation: 9112 steps/s (collection: 0.137s, learning 0.031s)
               Value function loss: 1.8930
                    Surrogate loss: -0.0015
             Mean action noise std: 1.03
                 Mean total reward: 180.51
               Mean episode length: 625.89
 Mean episode rew_tracking_lin_vel: 0.1172
 Mean episode rew_tracking_ang_vel: 0.0532
        Mean episode rew_lin_vel_z: -0.0266
      Mean episode rew_base_height: -0.7705
      Mean episode rew_action_rate: -0.0603
Mean episode rew_similar_to_default: -0.2725
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 5.7144
--------------------------------------------------------------------------------
                   Total timesteps: 740352
                    Iteration time: 0.17s
                        Total time: 80.27s
                               ETA: 3.2s

################################################################################
                      [1m Learning iteration 482/500 [0m

                       Computation: 9273 steps/s (collection: 0.136s, learning 0.030s)
               Value function loss: 4.2566
                    Surrogate loss: -0.0061
             Mean action noise std: 1.03
                 Mean total reward: 179.92
               Mean episode length: 623.15
 Mean episode rew_tracking_lin_vel: 0.2115
 Mean episode rew_tracking_ang_vel: 0.0942
        Mean episode rew_lin_vel_z: -0.0276
      Mean episode rew_base_height: -1.4014
      Mean episode rew_action_rate: -0.1055
Mean episode rew_similar_to_default: -0.4926
Mean episode rew_joint_pose_matching: 0.0007
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 10.3933
--------------------------------------------------------------------------------
                   Total timesteps: 741888
                    Iteration time: 0.17s
                        Total time: 80.43s
                               ETA: 3.0s

################################################################################
                      [1m Learning iteration 483/500 [0m

                       Computation: 8648 steps/s (collection: 0.146s, learning 0.031s)
               Value function loss: 10.2664
                    Surrogate loss: 0.0024
             Mean action noise std: 1.03
                 Mean total reward: 180.68
               Mean episode length: 624.45
 Mean episode rew_tracking_lin_vel: 0.2815
 Mean episode rew_tracking_ang_vel: 0.1275
        Mean episode rew_lin_vel_z: -0.0266
      Mean episode rew_base_height: -1.8721
      Mean episode rew_action_rate: -0.1356
Mean episode rew_similar_to_default: -0.6567
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0007
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 13.8260
--------------------------------------------------------------------------------
                   Total timesteps: 743424
                    Iteration time: 0.18s
                        Total time: 80.61s
                               ETA: 2.8s

################################################################################
                      [1m Learning iteration 484/500 [0m

                       Computation: 8168 steps/s (collection: 0.157s, learning 0.031s)
               Value function loss: 4.4943
                    Surrogate loss: -0.0042
             Mean action noise std: 1.03
                 Mean total reward: 180.82
               Mean episode length: 624.64
 Mean episode rew_tracking_lin_vel: 0.1495
 Mean episode rew_tracking_ang_vel: 0.0669
        Mean episode rew_lin_vel_z: -0.0269
      Mean episode rew_base_height: -0.9858
      Mean episode rew_action_rate: -0.0743
Mean episode rew_similar_to_default: -0.3467
Mean episode rew_joint_pose_matching: 0.0002
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 7.2459
--------------------------------------------------------------------------------
                   Total timesteps: 744960
                    Iteration time: 0.19s
                        Total time: 80.80s
                               ETA: 2.7s

################################################################################
                      [1m Learning iteration 485/500 [0m

                       Computation: 8745 steps/s (collection: 0.145s, learning 0.031s)
               Value function loss: 7.4950
                    Surrogate loss: -0.0031
             Mean action noise std: 1.03
                 Mean total reward: 178.54
               Mean episode length: 616.46
 Mean episode rew_tracking_lin_vel: 0.0100
 Mean episode rew_tracking_ang_vel: 0.0044
        Mean episode rew_lin_vel_z: -0.0264
      Mean episode rew_base_height: -0.0447
      Mean episode rew_action_rate: -0.0061
Mean episode rew_similar_to_default: -0.0187
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.5030
--------------------------------------------------------------------------------
                   Total timesteps: 746496
                    Iteration time: 0.18s
                        Total time: 80.97s
                               ETA: 2.5s

################################################################################
                      [1m Learning iteration 486/500 [0m

                       Computation: 9299 steps/s (collection: 0.137s, learning 0.028s)
               Value function loss: 4.0888
                    Surrogate loss: -0.0067
             Mean action noise std: 1.03
                 Mean total reward: 175.76
               Mean episode length: 606.72
 Mean episode rew_tracking_lin_vel: 0.0173
 Mean episode rew_tracking_ang_vel: 0.0073
        Mean episode rew_lin_vel_z: -0.0267
      Mean episode rew_base_height: -0.0905
      Mean episode rew_action_rate: -0.0105
Mean episode rew_similar_to_default: -0.0351
Mean episode rew_joint_pose_matching: 0.0001
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 0.8405
--------------------------------------------------------------------------------
                   Total timesteps: 748032
                    Iteration time: 0.17s
                        Total time: 81.14s
                               ETA: 2.3s

################################################################################
                      [1m Learning iteration 487/500 [0m

                       Computation: 9453 steps/s (collection: 0.135s, learning 0.028s)
               Value function loss: 3.3040
                    Surrogate loss: -0.0096
             Mean action noise std: 1.03
                 Mean total reward: 175.58
               Mean episode length: 605.67
 Mean episode rew_tracking_lin_vel: 0.1790
 Mean episode rew_tracking_ang_vel: 0.0805
        Mean episode rew_lin_vel_z: -0.0270
      Mean episode rew_base_height: -1.1866
      Mean episode rew_action_rate: -0.0913
Mean episode rew_similar_to_default: -0.4169
Mean episode rew_joint_pose_matching: 0.0008
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.7614
--------------------------------------------------------------------------------
                   Total timesteps: 749568
                    Iteration time: 0.16s
                        Total time: 81.30s
                               ETA: 2.2s

################################################################################
                      [1m Learning iteration 488/500 [0m

                       Computation: 9394 steps/s (collection: 0.134s, learning 0.030s)
               Value function loss: 0.1689
                    Surrogate loss: -0.0062
             Mean action noise std: 1.03
                 Mean total reward: 175.66
               Mean episode length: 605.67
 Mean episode rew_tracking_lin_vel: 0.3359
 Mean episode rew_tracking_ang_vel: 0.1514
        Mean episode rew_lin_vel_z: -0.0280
      Mean episode rew_base_height: -2.2391
      Mean episode rew_action_rate: -0.1678
Mean episode rew_similar_to_default: -0.7842
Mean episode rew_joint_pose_matching: 0.0010
Mean episode rew_joint_velocity_matching: 0.0003
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 16.4520
--------------------------------------------------------------------------------
                   Total timesteps: 751104
                    Iteration time: 0.16s
                        Total time: 81.46s
                               ETA: 2.0s

################################################################################
                      [1m Learning iteration 489/500 [0m

                       Computation: 9462 steps/s (collection: 0.133s, learning 0.030s)
               Value function loss: 0.2002
                    Surrogate loss: -0.0009
             Mean action noise std: 1.03
                 Mean total reward: 175.66
               Mean episode length: 605.67
 Mean episode rew_tracking_lin_vel: 0.3615
 Mean episode rew_tracking_ang_vel: 0.1627
        Mean episode rew_lin_vel_z: -0.0294
      Mean episode rew_base_height: -2.4053
      Mean episode rew_action_rate: -0.1754
Mean episode rew_similar_to_default: -0.8428
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 17.6747
--------------------------------------------------------------------------------
                   Total timesteps: 752640
                    Iteration time: 0.16s
                        Total time: 81.63s
                               ETA: 1.8s

################################################################################
                      [1m Learning iteration 490/500 [0m

                       Computation: 9525 steps/s (collection: 0.132s, learning 0.030s)
               Value function loss: 0.1621
                    Surrogate loss: 0.0039
             Mean action noise std: 1.03
                 Mean total reward: 175.66
               Mean episode length: 605.67
 Mean episode rew_tracking_lin_vel: 0.3615
 Mean episode rew_tracking_ang_vel: 0.1627
        Mean episode rew_lin_vel_z: -0.0294
      Mean episode rew_base_height: -2.4053
      Mean episode rew_action_rate: -0.1754
Mean episode rew_similar_to_default: -0.8428
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 17.6747
--------------------------------------------------------------------------------
                   Total timesteps: 754176
                    Iteration time: 0.16s
                        Total time: 81.79s
                               ETA: 1.7s

################################################################################
                      [1m Learning iteration 491/500 [0m

                       Computation: 9344 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 3.9981
                    Surrogate loss: -0.0025
             Mean action noise std: 1.03
                 Mean total reward: 170.90
               Mean episode length: 588.79
 Mean episode rew_tracking_lin_vel: 0.0869
 Mean episode rew_tracking_ang_vel: 0.0372
        Mean episode rew_lin_vel_z: -0.0276
      Mean episode rew_base_height: -0.5637
      Mean episode rew_action_rate: -0.0470
Mean episode rew_similar_to_default: -0.1992
Mean episode rew_joint_pose_matching: 0.0000
Mean episode rew_joint_velocity_matching: 0.0001
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 4.2555
--------------------------------------------------------------------------------
                   Total timesteps: 755712
                    Iteration time: 0.16s
                        Total time: 81.95s
                               ETA: 1.5s

################################################################################
                      [1m Learning iteration 492/500 [0m

                       Computation: 9423 steps/s (collection: 0.134s, learning 0.029s)
               Value function loss: 3.4120
                    Surrogate loss: -0.0065
             Mean action noise std: 1.03
                 Mean total reward: 172.37
               Mean episode length: 593.18
 Mean episode rew_tracking_lin_vel: 0.2013
 Mean episode rew_tracking_ang_vel: 0.0894
        Mean episode rew_lin_vel_z: -0.0276
      Mean episode rew_base_height: -1.3318
      Mean episode rew_action_rate: -0.1042
Mean episode rew_similar_to_default: -0.4691
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 9.9615
--------------------------------------------------------------------------------
                   Total timesteps: 757248
                    Iteration time: 0.16s
                        Total time: 82.11s
                               ETA: 1.3s

################################################################################
                      [1m Learning iteration 493/500 [0m

                       Computation: 9540 steps/s (collection: 0.134s, learning 0.027s)
               Value function loss: 2.8807
                    Surrogate loss: -0.0089
             Mean action noise std: 1.03
                 Mean total reward: 172.57
               Mean episode length: 593.66
 Mean episode rew_tracking_lin_vel: 0.3193
 Mean episode rew_tracking_ang_vel: 0.1426
        Mean episode rew_lin_vel_z: -0.0280
      Mean episode rew_base_height: -2.1173
      Mean episode rew_action_rate: -0.1567
Mean episode rew_similar_to_default: -0.7440
Mean episode rew_joint_pose_matching: 0.0014
Mean episode rew_joint_velocity_matching: 0.0004
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 15.6450
--------------------------------------------------------------------------------
                   Total timesteps: 758784
                    Iteration time: 0.16s
                        Total time: 82.28s
                               ETA: 1.2s

################################################################################
                      [1m Learning iteration 494/500 [0m

                       Computation: 9320 steps/s (collection: 0.135s, learning 0.029s)
               Value function loss: 10.2813
                    Surrogate loss: -0.0020
             Mean action noise std: 1.03
                 Mean total reward: 170.27
               Mean episode length: 584.17
 Mean episode rew_tracking_lin_vel: 0.1780
 Mean episode rew_tracking_ang_vel: 0.0786
        Mean episode rew_lin_vel_z: -0.0271
      Mean episode rew_base_height: -1.1737
      Mean episode rew_action_rate: -0.0925
Mean episode rew_similar_to_default: -0.4137
Mean episode rew_joint_pose_matching: 0.0005
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.8226
--------------------------------------------------------------------------------
                   Total timesteps: 760320
                    Iteration time: 0.16s
                        Total time: 82.44s
                               ETA: 1.0s

################################################################################
                      [1m Learning iteration 495/500 [0m

                       Computation: 8886 steps/s (collection: 0.142s, learning 0.031s)
               Value function loss: 14.3830
                    Surrogate loss: -0.0079
             Mean action noise std: 1.03
                 Mean total reward: 163.76
               Mean episode length: 561.01
 Mean episode rew_tracking_lin_vel: 0.1810
 Mean episode rew_tracking_ang_vel: 0.0777
        Mean episode rew_lin_vel_z: -0.0270
      Mean episode rew_base_height: -1.1898
      Mean episode rew_action_rate: -0.0981
Mean episode rew_similar_to_default: -0.4205
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 8.9515
--------------------------------------------------------------------------------
                   Total timesteps: 761856
                    Iteration time: 0.17s
                        Total time: 82.61s
                               ETA: 0.8s

################################################################################
                      [1m Learning iteration 496/500 [0m

                       Computation: 8456 steps/s (collection: 0.152s, learning 0.030s)
               Value function loss: 11.4682
                    Surrogate loss: 0.0054
             Mean action noise std: 1.03
                 Mean total reward: 160.88
               Mean episode length: 550.36
 Mean episode rew_tracking_lin_vel: 0.0601
 Mean episode rew_tracking_ang_vel: 0.0265
        Mean episode rew_lin_vel_z: -0.0238
      Mean episode rew_base_height: -0.3858
      Mean episode rew_action_rate: -0.0323
Mean episode rew_similar_to_default: -0.1384
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0000
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 3.0506
--------------------------------------------------------------------------------
                   Total timesteps: 763392
                    Iteration time: 0.18s
                        Total time: 82.79s
                               ETA: 0.7s

################################################################################
                      [1m Learning iteration 497/500 [0m

                       Computation: 9348 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 6.6232
                    Surrogate loss: -0.0058
             Mean action noise std: 1.03
                 Mean total reward: 164.17
               Mean episode length: 560.95
 Mean episode rew_tracking_lin_vel: 0.2865
 Mean episode rew_tracking_ang_vel: 0.1257
        Mean episode rew_lin_vel_z: -0.0294
      Mean episode rew_base_height: -1.9057
      Mean episode rew_action_rate: -0.1504
Mean episode rew_similar_to_default: -0.6737
Mean episode rew_joint_pose_matching: 0.0012
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 14.1934
--------------------------------------------------------------------------------
                   Total timesteps: 764928
                    Iteration time: 0.16s
                        Total time: 82.96s
                               ETA: 0.5s

################################################################################
                      [1m Learning iteration 498/500 [0m

                       Computation: 8987 steps/s (collection: 0.140s, learning 0.031s)
               Value function loss: 2.4484
                    Surrogate loss: -0.0074
             Mean action noise std: 1.03
                 Mean total reward: 165.00
               Mean episode length: 563.07
 Mean episode rew_tracking_lin_vel: 0.2568
 Mean episode rew_tracking_ang_vel: 0.1120
        Mean episode rew_lin_vel_z: -0.0300
      Mean episode rew_base_height: -1.6933
      Mean episode rew_action_rate: -0.1381
Mean episode rew_similar_to_default: -0.6033
Mean episode rew_joint_pose_matching: 0.0004
Mean episode rew_joint_velocity_matching: 0.0002
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 12.6785
--------------------------------------------------------------------------------
                   Total timesteps: 766464
                    Iteration time: 0.17s
                        Total time: 83.13s
                               ETA: 0.3s

################################################################################
                      [1m Learning iteration 499/500 [0m

                       Computation: 9285 steps/s (collection: 0.135s, learning 0.030s)
               Value function loss: 0.2061
                    Surrogate loss: -0.0079
             Mean action noise std: 1.03
                 Mean total reward: 167.94
               Mean episode length: 572.74
 Mean episode rew_tracking_lin_vel: 0.3613
 Mean episode rew_tracking_ang_vel: 0.1562
        Mean episode rew_lin_vel_z: -0.0290
      Mean episode rew_base_height: -2.4061
      Mean episode rew_action_rate: -0.1904
Mean episode rew_similar_to_default: -0.8465
Mean episode rew_joint_pose_matching: 0.0011
Mean episode rew_joint_velocity_matching: 0.0005
Mean episode rew_end_effector_matching: 0.0000
 Mean episode rew_forward_velocity: 18.0898
--------------------------------------------------------------------------------
                   Total timesteps: 768000
                    Iteration time: 0.17s
                        Total time: 83.30s
                               ETA: 0.2s
